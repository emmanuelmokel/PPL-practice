{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPw7hS0Dj5v3bmT1EOjtqBw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/emmanuelmokel/PPL-practice/blob/main/NestedRHat_TFP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -Rf probability\n",
        "!rm -Rf fun_mc\n",
        "!rm -Rf inference_gym\n",
        "!git clone https://github.com/tensorflow/probability.git\n",
        "!mv probability/spinoffs/fun_mc/fun_mc .\n",
        "!mv probability/spinoffs/inference_gym/inference_gym .\n",
        "!pip install tf-nightly tfp-nightly jax jaxlib\n",
        "\n",
        "!pip install immutabledict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yVfP9g3Tdncu",
        "outputId": "14c23e9d-115e-43c0-e93e-57d488adbac6"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'probability'...\n",
            "remote: Enumerating objects: 100071, done.\u001b[K\n",
            "remote: Counting objects: 100% (4855/4855), done.\u001b[K\n",
            "remote: Compressing objects: 100% (149/149), done.\u001b[K\n",
            "remote: Total 100071 (delta 4734), reused 4745 (delta 4706), pack-reused 95216\u001b[K\n",
            "Receiving objects: 100% (100071/100071), 136.98 MiB | 9.77 MiB/s, done.\n",
            "Resolving deltas: 100% (81895/81895), done.\n",
            "Collecting tf-nightly\n",
            "  Downloading tf_nightly-2.14.0.dev20230629-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (490.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m490.8/490.8 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tfp-nightly\n",
            "  Downloading tfp_nightly-0.20.0.dev20230629-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m117.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jax in /usr/local/lib/python3.10/dist-packages (0.4.10)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.10/dist-packages (0.4.10+cuda11.cudnn86)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tf-nightly) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tf-nightly) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tf-nightly) (23.5.26)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tf-nightly) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tf-nightly) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tf-nightly) (1.56.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tf-nightly) (3.8.0)\n",
            "Collecting keras-nightly~=2.14.0.dev (from tf-nightly)\n",
            "  Downloading keras_nightly-2.14.0.dev2023062907-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m91.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tf-nightly) (16.0.0)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tf-nightly) (0.2.0)\n",
            "Requirement already satisfied: numpy>=1.22 in /usr/local/lib/python3.10/dist-packages (from tf-nightly) (1.22.4)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tf-nightly) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tf-nightly) (23.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tf-nightly) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tf-nightly) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tf-nightly) (1.16.0)\n",
            "Collecting tb-nightly~=2.14.0.a (from tf-nightly)\n",
            "  Downloading tb_nightly-2.14.0a20230629-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m103.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tf-nightly) (2.3.0)\n",
            "Collecting tf-estimator-nightly~=2.14.0.dev (from tf-nightly)\n",
            "  Downloading tf_estimator_nightly-2.14.0.dev2023062908-py2.py3-none-any.whl (440 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m441.0/441.0 kB\u001b[0m \u001b[31m42.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-extensions<4.6.0,>=3.6.6 (from tf-nightly)\n",
            "  Downloading typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tf-nightly) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tf-nightly) (0.32.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from tfp-nightly) (4.4.2)\n",
            "Requirement already satisfied: cloudpickle>=1.3 in /usr/local/lib/python3.10/dist-packages (from tfp-nightly) (2.2.1)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from tfp-nightly) (0.1.8)\n",
            "Requirement already satisfied: scipy>=1.7 in /usr/local/lib/python3.10/dist-packages (from jax) (1.10.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tf-nightly) (0.40.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tb-nightly~=2.14.0.a->tf-nightly) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tb-nightly~=2.14.0.a->tf-nightly) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tb-nightly~=2.14.0.a->tf-nightly) (3.4.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tb-nightly~=2.14.0.a->tf-nightly) (2.27.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tb-nightly~=2.14.0.a->tf-nightly) (0.7.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tb-nightly~=2.14.0.a->tf-nightly) (2.3.6)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tb-nightly~=2.14.0.a->tf-nightly) (5.3.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tb-nightly~=2.14.0.a->tf-nightly) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tb-nightly~=2.14.0.a->tf-nightly) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tb-nightly~=2.14.0.a->tf-nightly) (1.3.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tb-nightly~=2.14.0.a->tf-nightly) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tb-nightly~=2.14.0.a->tf-nightly) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tb-nightly~=2.14.0.a->tf-nightly) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tb-nightly~=2.14.0.a->tf-nightly) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tb-nightly~=2.14.0.a->tf-nightly) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tb-nightly~=2.14.0.a->tf-nightly) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tb-nightly~=2.14.0.a->tf-nightly) (3.2.2)\n",
            "Installing collected packages: typing-extensions, tf-estimator-nightly, keras-nightly, tfp-nightly, tb-nightly, tf-nightly\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.6.3\n",
            "    Uninstalling typing_extensions-4.6.3:\n",
            "      Successfully uninstalled typing_extensions-4.6.3\n",
            "Successfully installed keras-nightly-2.14.0.dev2023062907 tb-nightly-2.14.0a20230629 tf-estimator-nightly-2.14.0.dev2023062908 tf-nightly-2.14.0.dev20230629 tfp-nightly-0.20.0.dev20230629 typing-extensions-4.5.0\n",
            "Collecting immutabledict\n",
            "  Downloading immutabledict-2.2.4-py3-none-any.whl (4.1 kB)\n",
            "Installing collected packages: immutabledict\n",
            "Successfully installed immutabledict-2.2.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Er7DJXS3Ng3u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d7461eb-b3d8-459b-a7da-6a57ea914a56"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/distributions/distribution.py:259: ReparameterizationType.__init__ (from tensorflow.python.ops.distributions.distribution) is deprecated and will be removed after 2019-01-01.\n",
            "Instructions for updating:\n",
            "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/distributions/bernoulli.py:165: RegisterKL.__init__ (from tensorflow.python.ops.distributions.kullback_leibler) is deprecated and will be removed after 2019-01-01.\n",
            "Instructions for updating:\n",
            "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n"
          ]
        }
      ],
      "source": [
        "from matplotlib.pyplot import *\n",
        "\n",
        "import jax\n",
        "from jax import random\n",
        "from jax import numpy as jnp\n",
        "\n",
        "\n",
        "#!pip install tfp-nightly inference_gym\n",
        "from inference_gym import using_jax as gym\n",
        "\n",
        "#from tensorflow_probability.spinoffs import using_jax as fun_mcmc\n",
        "from fun_mc import using_jax as fun_mcmc\n",
        "\n",
        "from tensorflow_probability.python.internal import prefer_static as ps\n",
        "from tensorflow_probability.python.internal import unnest\n",
        "\n",
        "import tensorflow_probability as _tfp\n",
        "tfp = _tfp.substrates.jax\n",
        "tfd = tfp.distributions\n",
        "tfb = tfp.bijectors\n",
        "\n",
        "tfp_np = _tfp.substrates.numpy\n",
        "tfd_np = tfp_np.distributions\n",
        "\n",
        "import arviz as az\n",
        "from tensorflow_probability.python.internal.unnest import get_innermost"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Working with the 'Banana' Posterior Target Density\n",
        "\n",
        "target = gym.targets.VectorModel(gym.targets.Banana(),\n",
        "                                 flatten_sample_transformations = True)\n",
        "num_dimensions = target.event_shape[0]\n",
        "# Is the heuristic for the initial value of \\epsilon given in the paper used in practice?\n",
        "init_step_size = 1.\n",
        "\n",
        "def target_log_prob_fn(x):\n",
        "   y = target.default_event_space_bijector(x)\n",
        "   fldj = target.default_event_space_bijector.forward_log_det_jacobian(x)\n",
        "   return target.unnormalized_log_prob(y) + fldj\n",
        "\n",
        "offset = 2\n",
        "def bn_initialize(shape, key = random.PRNGKey(3727709)):\n",
        "  return 10 * random.normal(key, shape + (num_dimensions,)) + offset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J_4vsEveoV54",
        "outputId": "e63ccdc1-eb55-44f4-8740-2c94b556fdb7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow_probability/python/internal/backend/jax/ops.py:285: UserWarning: Explicitly requested dtype float64 requested in astype is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
            "  return arr.astype(dtype)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Running default HMC as written in Radford Neal's paper\n",
        "\n",
        "num_chains = 512\n",
        "K = 4\n",
        "num_warmup, num_sampling = 100, 100000\n",
        "total_samples = num_warmup + num_sampling\n",
        "\n",
        "kernel = tfp.mcmc.HamiltonianMonteCarlo(target_log_prob_fn, init_step_size, 1)\n",
        "kernel = tfp.experimental.mcmc.GradientBasedTrajectoryLengthAdaptation(kernel, num_warmup)\n",
        "kernel = tfp.mcmc.DualAveragingStepSizeAdaptation(kernel, num_warmup,\n",
        "                                                  target_accept_prob = 0.75,\n",
        "                                                  reduce_fn = tfp.math.reduce_log_harmonic_mean_exp)\n",
        "\n",
        "# Initializing each chain (in a super chain) at the same location\n",
        "initial_state = bn_initialize((K,))\n",
        "initial_state = jnp.repeat(initial_state, num_chains // K, axis = 0)"
      ],
      "metadata": {
        "id": "FlX9TePtumEF"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%env XLA_PYTHON_CLIENT_ALLOCATOR = platform\n",
        "result = tfp.mcmc.sample_chain(total_samples, initial_state,\n",
        "                               kernel = kernel, seed = random.PRNGKey(1954))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w5p4ybjEvuZs",
        "outputId": "ced7ef22-72f9-447e-e0c2-b814811bd4c1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: XLA_PYTHON_CLIENT_ALLOCATOR=platform\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow_probability/substrates/jax/mcmc/sample.py:339: UserWarning: Tracing all kernel results by default is deprecated. Set the `trace_fn` argument to None (the future default value) or an explicit callback that traces the values you are interested in.\n",
            "  warnings.warn('Tracing all kernel results by default is deprecated. Set '\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This object is of type tfp.mcmc.CheckpointableStatesAndTrace\n",
        "# It contains attributes all_states, trace, and final_kernel_results\n",
        "# https://www.tensorflow.org/probability/api_docs/python/tfp/mcmc/CheckpointableStatesAndTrace\n",
        "\n",
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WH7CNMY1rEeV",
        "outputId": "fb46c5a0-88fa-488c-8e10-22d82ca7aca9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StatesAndTrace(\n",
              "  all_states=Array([[[-14.236393  ,   3.871798  ],\n",
              "            [-13.070528  ,   4.7461495 ],\n",
              "            [-12.489271  ,   4.8525343 ],\n",
              "            ...,\n",
              "            [  0.03275418,  -3.6777086 ],\n",
              "            [ -0.666454  ,  -2.3977256 ],\n",
              "            [ -1.2655139 ,  -4.4068384 ]],\n",
              "    \n",
              "           [[-14.236393  ,   3.871798  ],\n",
              "            [-13.070528  ,   4.7461495 ],\n",
              "            [-12.489271  ,   4.8525343 ],\n",
              "            ...,\n",
              "            [  0.03275418,  -3.6777086 ],\n",
              "            [ -0.666454  ,  -2.3977256 ],\n",
              "            [ -1.2655139 ,  -4.4068384 ]],\n",
              "    \n",
              "           [[-14.236393  ,   3.871798  ],\n",
              "            [-13.070528  ,   4.7461495 ],\n",
              "            [-12.489271  ,   4.8525343 ],\n",
              "            ...,\n",
              "            [  0.03275418,  -3.6777086 ],\n",
              "            [ -0.666454  ,  -2.3977256 ],\n",
              "            [ -1.2655139 ,  -4.4068384 ]],\n",
              "    \n",
              "           ...,\n",
              "    \n",
              "           [[  4.145871  ,  -1.2746216 ],\n",
              "            [ -0.3929863 ,  -3.4548879 ],\n",
              "            [ -0.90132916,  -2.725726  ],\n",
              "            ...,\n",
              "            [ -3.7354243 ,  -0.9461189 ],\n",
              "            [-10.270396  ,  -1.7284454 ],\n",
              "            [ -4.870346  ,  -0.34653684]],\n",
              "    \n",
              "           [[  0.04748204,  -2.265637  ],\n",
              "            [-12.644226  ,   0.9037969 ],\n",
              "            [  1.8853991 ,  -1.4608463 ],\n",
              "            ...,\n",
              "            [ -9.769282  ,   0.4072767 ],\n",
              "            [ -4.460516  ,  -2.7572014 ],\n",
              "            [  4.786127  ,  -1.0467331 ]],\n",
              "    \n",
              "           [[  1.9864928 ,  -1.5603487 ],\n",
              "            [-13.023319  ,   0.9157079 ],\n",
              "            [  0.608681  ,  -2.4411058 ],\n",
              "            ...,\n",
              "            [-10.745838  ,   0.24104914],\n",
              "            [ -5.525684  ,  -3.5680156 ],\n",
              "            [  5.626418  ,  -2.8676763 ]]], dtype=float32),\n",
              "  trace=DualAveragingStepSizeAdaptationResults(\n",
              "      inner_results=GradientBasedTrajectoryLengthAdaptationResults(\n",
              "          inner_results=MetropolisHastingsKernelResults(\n",
              "              accepted_results=UncalibratedHamiltonianMonteCarloKernelResults(\n",
              "                  log_acceptance_correction=Array([[-2.7357298e+01, -2.6816759e+01, -2.6193962e+01, ...,\n",
              "                            -1.1721734e+00, -1.2005522e+00, -5.3387135e-01],\n",
              "                           [-2.7357298e+01, -2.6816759e+01, -2.6193962e+01, ...,\n",
              "                            -1.1721734e+00, -1.2005522e+00, -5.3387135e-01],\n",
              "                           [-2.7357298e+01, -2.6816759e+01, -2.6193962e+01, ...,\n",
              "                            -1.1721734e+00, -1.2005522e+00, -5.3387135e-01],\n",
              "                           ...,\n",
              "                           [ 7.1550751e-01, -8.9093113e-01, -6.2534511e-01, ...,\n",
              "                             1.1541114e+00,  6.3542318e-01,  2.8158534e-01],\n",
              "                           [-5.2687335e-01,  1.0712109e+00,  9.6120477e-01, ...,\n",
              "                            -6.9140404e-01, -2.0608799e+00, -1.0348314e+00],\n",
              "                           [ 5.8920383e-01,  3.1362224e-01, -8.4585905e-01, ...,\n",
              "                            -1.5999407e-02,  1.0360513e+00, -3.9835066e-01]], dtype=float32),\n",
              "                  target_log_prob=Array([[-5.4671135, -8.429447 , -9.954582 , ..., -4.370134 , -4.3161135,\n",
              "                            -5.206814 ],\n",
              "                           [-5.4671135, -8.429447 , -9.954582 , ..., -4.370134 , -4.3161135,\n",
              "                            -5.206814 ],\n",
              "                           [-5.4671135, -8.429447 , -9.954582 , ..., -4.370134 , -4.3161135,\n",
              "                            -5.206814 ],\n",
              "                           ...,\n",
              "                           [-4.958128 , -4.2468143, -4.17575  , ..., -5.5472984, -6.459358 ,\n",
              "                            -6.144464 ],\n",
              "                           [-4.4100685, -5.3381195, -5.1842804, ..., -4.7656846, -4.3026323,\n",
              "                            -5.056447 ],\n",
              "                           [-5.033066 , -5.6758714, -4.292346 , ..., -4.7427235, -5.3942723,\n",
              "                            -4.632795 ]], dtype=float32),\n",
              "                  grads_target_log_prob=[Array([[[-5.3376639e-01, -7.9155159e-01],\n",
              "                            [-1.9247571e+00, -2.6209886e+00],\n",
              "                            [-2.2528729e+00, -3.1730776e+00],\n",
              "                            ...,\n",
              "                            [-1.6594731e-03,  6.7774105e-01],\n",
              "                            [-1.6885923e-02, -5.8894944e-01],\n",
              "                            [ 1.2312572e-01,  1.4548843e+00]],\n",
              "                    \n",
              "                           [[-5.3376639e-01, -7.9155159e-01],\n",
              "                            [-1.9247571e+00, -2.6209886e+00],\n",
              "                            [-2.2528729e+00, -3.1730776e+00],\n",
              "                            ...,\n",
              "                            [-1.6594731e-03,  6.7774105e-01],\n",
              "                            [-1.6885923e-02, -5.8894944e-01],\n",
              "                            [ 1.2312572e-01,  1.4548843e+00]],\n",
              "                    \n",
              "                           [[-5.3376639e-01, -7.9155159e-01],\n",
              "                            [-1.9247571e+00, -2.6209886e+00],\n",
              "                            [-2.2528729e+00, -3.1730776e+00],\n",
              "                            ...,\n",
              "                            [-1.6594731e-03,  6.7774105e-01],\n",
              "                            [-1.6885923e-02, -5.8894944e-01],\n",
              "                            [ 1.2312572e-01,  1.4548843e+00]],\n",
              "                    \n",
              "                           ...,\n",
              "                    \n",
              "                           [[ 2.5946462e-01, -1.2097310e+00],\n",
              "                            [ 1.4764998e-02,  4.5952129e-01],\n",
              "                            [-4.5013586e-03, -2.4990225e-01],\n",
              "                            ...,\n",
              "                            [-3.2915351e-01, -1.6352794e+00],\n",
              "                            [ 1.2691395e+00,  1.8928766e+00],\n",
              "                            [-5.1874685e-01, -1.9418550e+00]],\n",
              "                    \n",
              "                           [[ 1.6171301e-03, -7.3429537e-01],\n",
              "                            [ 8.0353796e-01,  8.9249659e-01],\n",
              "                            [ 1.4319739e-01, -1.4325117e+00],\n",
              "                            ...,\n",
              "                            [-2.2124118e-01, -5.4411024e-01],\n",
              "                            [ 1.3936996e-01,  3.5408759e-01],\n",
              "                            [ 3.1570917e-01, -1.2660565e+00]],\n",
              "                    \n",
              "                           [[ 1.3761626e-01, -1.3212667e+00],\n",
              "                            [ 1.0464215e+00,  1.1724973e+00],\n",
              "                            [ 1.3918561e-02, -5.4777932e-01],\n",
              "                            ...,\n",
              "                            [ 2.5132924e-01,  2.2314197e-01],\n",
              "                            [ 5.4726732e-01,  1.4840109e+00],\n",
              "                            [-3.3219737e-01,  8.1737375e-01]]], dtype=float32)],\n",
              "                  initial_momentum=[Array([[[-0.96332777, -1.1250091 ],\n",
              "                            [ 0.20253749, -0.2506577 ],\n",
              "                            [ 0.78379405, -0.14427261],\n",
              "                            ...,\n",
              "                            [ 0.77145904,  0.24545658],\n",
              "                            [ 0.07225081,  1.5254396 ],\n",
              "                            [-0.526809  , -0.48367321]],\n",
              "                    \n",
              "                           [[-0.96332777, -1.1250091 ],\n",
              "                            [ 0.20253749, -0.2506577 ],\n",
              "                            [ 0.78379405, -0.14427261],\n",
              "                            ...,\n",
              "                            [ 0.77145904,  0.24545658],\n",
              "                            [ 0.07225081,  1.5254396 ],\n",
              "                            [-0.526809  , -0.48367321]],\n",
              "                    \n",
              "                           [[-0.96332777, -1.1250091 ],\n",
              "                            [ 0.20253749, -0.2506577 ],\n",
              "                            [ 0.78379405, -0.14427261],\n",
              "                            ...,\n",
              "                            [ 0.77145904,  0.24545658],\n",
              "                            [ 0.07225081,  1.5254396 ],\n",
              "                            [-0.526809  , -0.48367321]],\n",
              "                    \n",
              "                           ...,\n",
              "                    \n",
              "                           [[ 0.28688002,  1.837185  ],\n",
              "                            [ 1.4591414 ,  0.4844868 ],\n",
              "                            [-1.6968105 , -0.5030895 ],\n",
              "                            ...,\n",
              "                            [ 1.3265201 ,  1.9116114 ],\n",
              "                            [-1.1707239 , -0.4332642 ],\n",
              "                            [ 1.6716737 ,  0.64042985]],\n",
              "                    \n",
              "                           [[-0.4172757 , -0.59887016],\n",
              "                            [-2.1111622 , -0.70637417],\n",
              "                            [ 0.60134757,  2.5669801 ],\n",
              "                            ...,\n",
              "                            [-1.3878356 ,  0.07409135],\n",
              "                            [ 0.6899741 ,  0.29730007],\n",
              "                            [ 1.4096804 , -0.9711944 ]],\n",
              "                    \n",
              "                           [[ 1.426243  ,  1.2602721 ],\n",
              "                            [-1.0530668 , -0.86744857],\n",
              "                            [-1.0293602 ,  0.16205172],\n",
              "                            ...,\n",
              "                            [-0.65862197,  0.11130046],\n",
              "                            [-0.99970907, -1.1749336 ],\n",
              "                            [ 0.5274221 , -0.9005368 ]]], dtype=float32)],\n",
              "                  final_momentum=[Array([[[-4.1482654 , -6.3008046 ],\n",
              "                            [-3.6778955 , -6.3411713 ],\n",
              "                            [-3.2606971 , -6.5108314 ],\n",
              "                            ...,\n",
              "                            [ 0.819041  ,  1.5260788 ],\n",
              "                            [ 0.11221953,  2.1727166 ],\n",
              "                            [-0.41683444,  1.1855206 ]],\n",
              "                    \n",
              "                           [[-4.1482654 , -6.3008046 ],\n",
              "                            [-3.6778955 , -6.3411713 ],\n",
              "                            [-3.2606971 , -6.5108314 ],\n",
              "                            ...,\n",
              "                            [ 0.819041  ,  1.5260788 ],\n",
              "                            [ 0.11221953,  2.1727166 ],\n",
              "                            [-0.41683444,  1.1855206 ]],\n",
              "                    \n",
              "                           [[-4.1482654 , -6.3008046 ],\n",
              "                            [-3.6778955 , -6.3411713 ],\n",
              "                            [-3.2606971 , -6.5108314 ],\n",
              "                            ...,\n",
              "                            [ 0.819041  ,  1.5260788 ],\n",
              "                            [ 0.11221953,  2.1727166 ],\n",
              "                            [-0.41683444,  1.1855206 ]],\n",
              "                    \n",
              "                           ...,\n",
              "                    \n",
              "                           [[ 0.8425054 , -1.1474837 ],\n",
              "                            [ 1.2068404 , -1.639884  ],\n",
              "                            [-1.895594  ,  0.8886386 ],\n",
              "                            ...,\n",
              "                            [ 0.4778764 , -1.696268  ],\n",
              "                            [-0.51329446,  0.15490276],\n",
              "                            [ 1.5143231 , -0.59016776]],\n",
              "                    \n",
              "                           [[-0.76060504, -1.0039877 ],\n",
              "                            [-1.4298329 ,  0.8769986 ],\n",
              "                            [ 0.08391286,  2.2408826 ],\n",
              "                            ...,\n",
              "                            [-1.3960345 , -1.1685346 ],\n",
              "                            [ 1.5875443 ,  1.4717046 ],\n",
              "                            [ 2.0268166 , -0.9445076 ]],\n",
              "                    \n",
              "                           [[ 1.5203359 , -0.36417815],\n",
              "                            [ 0.55306846,  0.96347684],\n",
              "                            [-0.921588  , -1.3886096 ],\n",
              "                            ...,\n",
              "                            [-0.6753871 , -0.14839745],\n",
              "                            [-0.48430806,  0.27061084],\n",
              "                            [ 0.5544716 , -1.2563452 ]]], dtype=float32)],\n",
              "                  step_size=Array([ 1.        , 15.403648  ,  2.9887986 , ...,  0.44453478,\n",
              "                            0.44453478,  0.44453478], dtype=float32),\n",
              "                  num_leapfrog_steps=Array([ 1,  1,  1, ...,  5, 15,  3], dtype=int32),\n",
              "                  seed=[]\n",
              "                ),\n",
              "              is_accepted=Array([[ True,  True,  True, ...,  True,  True,  True],\n",
              "                       [False, False, False, ..., False, False, False],\n",
              "                       [False, False, False, ..., False, False, False],\n",
              "                       ...,\n",
              "                       [ True,  True,  True, ...,  True,  True,  True],\n",
              "                       [ True,  True,  True, ...,  True,  True,  True],\n",
              "                       [ True,  True,  True, ...,  True,  True,  True]], dtype=bool),\n",
              "              log_accept_ratio=Array([[ 1.75493603e+01,  1.51275654e+01,  1.42252274e+01, ...,\n",
              "                         3.75045419e-01,  4.00686979e-01,  1.76667511e-01],\n",
              "                       [-1.17527100e+07, -2.39475937e+10, -8.19983483e+10, ...,\n",
              "                        -5.42999625e+05, -9.68168250e+05, -2.51773725e+06],\n",
              "                       [-6.71432018e+00, -4.85608826e+02, -2.01589966e+03, ...,\n",
              "                        -1.00675030e+01, -7.78724551e-01, -1.44638405e+01],\n",
              "                       ...,\n",
              "                       [-3.63836288e-02,  5.35740852e-02,  1.65358782e-02, ...,\n",
              "                        -7.83715248e-02, -2.96540260e-02, -5.59686422e-02],\n",
              "                       [ 2.11861134e-02, -2.00943947e-02, -4.73258495e-02, ...,\n",
              "                         9.02097821e-02,  9.58459377e-02,  5.31855822e-02],\n",
              "                       [-3.37934494e-02, -2.41296291e-02,  4.60753441e-02, ...,\n",
              "                         6.96173310e-03, -5.55887222e-02,  2.53015161e-02]],      dtype=float32),\n",
              "              proposed_state=Array([[[-1.4236393e+01,  3.8717980e+00],\n",
              "                        [-1.3070528e+01,  4.7461495e+00],\n",
              "                        [-1.2489271e+01,  4.8525343e+00],\n",
              "                        ...,\n",
              "                        [ 3.2754183e-02, -3.6777086e+00],\n",
              "                        [-6.6645402e-01, -2.3977256e+00],\n",
              "                        [-1.2655139e+00, -4.4068384e+00]],\n",
              "                \n",
              "                       [[-5.9417763e+01, -6.6980202e+01],\n",
              "                        [-2.3703517e+02, -3.1037277e+02],\n",
              "                        [-2.9426581e+02, -3.7841876e+02],\n",
              "                        ...,\n",
              "                        [-1.9567417e+01,  9.6279480e+01],\n",
              "                        [ 2.4408974e+01, -8.6945198e+01],\n",
              "                        [ 3.6933937e+01,  1.5784048e+02]],\n",
              "                \n",
              "                       [[-1.4265016e+01,  1.1777053e+00],\n",
              "                        [-1.7726641e+01, -8.0221901e+00],\n",
              "                        [-2.4535332e+01, -9.1505547e+00],\n",
              "                        ...,\n",
              "                        [ 5.2185082e-01,  8.3081245e-02],\n",
              "                        [ 3.0544045e+00, -1.7450385e+00],\n",
              "                        [ 2.4202514e+00,  9.0037251e-01]],\n",
              "                \n",
              "                       ...,\n",
              "                \n",
              "                       [[ 4.1458712e+00, -1.2746216e+00],\n",
              "                        [-3.9298630e-01, -3.4548879e+00],\n",
              "                        [-9.0132916e-01, -2.7257259e+00],\n",
              "                        ...,\n",
              "                        [-3.7354243e+00, -9.4611889e-01],\n",
              "                        [-1.0270396e+01, -1.7284454e+00],\n",
              "                        [-4.8703461e+00, -3.4653684e-01]],\n",
              "                \n",
              "                       [[ 4.7482044e-02, -2.2656369e+00],\n",
              "                        [-1.2644226e+01,  9.0379691e-01],\n",
              "                        [ 1.8853991e+00, -1.4608463e+00],\n",
              "                        ...,\n",
              "                        [-9.7692823e+00,  4.0727669e-01],\n",
              "                        [-4.4605160e+00, -2.7572014e+00],\n",
              "                        [ 4.7861271e+00, -1.0467331e+00]],\n",
              "                \n",
              "                       [[ 1.9864928e+00, -1.5603487e+00],\n",
              "                        [-1.3023319e+01,  9.1570789e-01],\n",
              "                        [ 6.0868102e-01, -2.4411058e+00],\n",
              "                        ...,\n",
              "                        [-1.0745838e+01,  2.4104914e-01],\n",
              "                        [-5.5256839e+00, -3.5680156e+00],\n",
              "                        [ 5.6264181e+00, -2.8676763e+00]]], dtype=float32),\n",
              "              proposed_results=UncalibratedHamiltonianMonteCarloKernelResults(\n",
              "                  log_acceptance_correction=Array([[-2.7357298e+01, -2.6816759e+01, -2.6193962e+01, ...,\n",
              "                            -1.1721734e+00, -1.2005522e+00, -5.3387135e-01],\n",
              "                           [-1.1738262e+07, -2.3945607e+10, -8.1993925e+10, ...,\n",
              "                            -5.3914412e+05, -9.6298188e+05, -2.5105415e+06],\n",
              "                           [-5.1668248e+00, -3.8393689e+02, -1.7256411e+03, ...,\n",
              "                            -5.5682731e+00, -4.3233860e-01, -8.5644169e+00],\n",
              "                           ...,\n",
              "                           [ 7.1550751e-01, -8.9093113e-01, -6.2534511e-01, ...,\n",
              "                             1.1541114e+00,  6.3542318e-01,  2.8158534e-01],\n",
              "                           [-5.2687335e-01,  1.0712109e+00,  9.6120477e-01, ...,\n",
              "                            -6.9140404e-01, -2.0608799e+00, -1.0348314e+00],\n",
              "                           [ 5.8920383e-01,  3.1362224e-01, -8.4585905e-01, ...,\n",
              "                            -1.5999407e-02,  1.0360513e+00, -3.9835066e-01]], dtype=float32),\n",
              "                  target_log_prob=Array([[-5.46711349e+00, -8.42944717e+00, -9.95458221e+00, ...,\n",
              "                            -4.37013388e+00, -4.31611347e+00, -5.20681381e+00],\n",
              "                           [-1.44538330e+04, -1.98619562e+06, -4.42036600e+06, ...,\n",
              "                            -3.85985742e+03, -5.19068799e+03, -7.20100684e+03],\n",
              "                           [-7.01460886e+00, -1.10101364e+02, -3.00213165e+02, ...,\n",
              "                            -8.86936378e+00, -4.66249943e+00, -1.11062374e+01],\n",
              "                           ...,\n",
              "                           [-4.95812798e+00, -4.24681425e+00, -4.17574978e+00, ...,\n",
              "                            -5.54729843e+00, -6.45935822e+00, -6.14446402e+00],\n",
              "                           [-4.41006851e+00, -5.33811951e+00, -5.18428040e+00, ...,\n",
              "                            -4.76568460e+00, -4.30263233e+00, -5.05644703e+00],\n",
              "                           [-5.03306580e+00, -5.67587137e+00, -4.29234600e+00, ...,\n",
              "                            -4.74272346e+00, -5.39427233e+00, -4.63279486e+00]],      dtype=float32),\n",
              "                  grads_target_log_prob=[Array([[[-5.33766389e-01, -7.91551590e-01],\n",
              "                            [-1.92475712e+00, -2.62098861e+00],\n",
              "                            [-2.25287294e+00, -3.17307758e+00],\n",
              "                            ...,\n",
              "                            [-1.65947306e-03,  6.77741051e-01],\n",
              "                            [-1.68859232e-02, -5.88949442e-01],\n",
              "                            [ 1.23125717e-01,  1.45488429e+00]],\n",
              "                    \n",
              "                           [[ 6.06278564e+02,  1.69894318e+02],\n",
              "                            [ 2.83462227e+04,  1.99294287e+03],\n",
              "                            [ 5.24974219e+04,  2.97318970e+03],\n",
              "                            ...,\n",
              "                            [-1.02877228e+02, -8.77929688e+01],\n",
              "                            [-1.49362122e+02,  1.01819138e+02],\n",
              "                            [ 2.65371094e+02, -1.19917015e+02]],\n",
              "                    \n",
              "                           [[ 1.79198408e+00,  1.92701507e+00],\n",
              "                            [ 1.55454159e+01,  1.44492035e+01],\n",
              "                            [ 3.58854218e+01,  2.42100296e+01],\n",
              "                            ...,\n",
              "                            [ 9.10601914e-02, -3.07491136e+00],\n",
              "                            [ 1.48153290e-01, -9.75080013e-01],\n",
              "                            [ 5.16671956e-01, -3.72464395e+00]],\n",
              "                    \n",
              "                           ...,\n",
              "                    \n",
              "                           [[ 2.59464622e-01, -1.20973098e+00],\n",
              "                            [ 1.47649981e-02,  4.59521294e-01],\n",
              "                            [-4.50135861e-03, -2.49902248e-01],\n",
              "                            ...,\n",
              "                            [-3.29153508e-01, -1.63527942e+00],\n",
              "                            [ 1.26913953e+00,  1.89287663e+00],\n",
              "                            [-5.18746853e-01, -1.94185495e+00]],\n",
              "                    \n",
              "                           [[ 1.61713012e-03, -7.34295368e-01],\n",
              "                            [ 8.03537965e-01,  8.92496586e-01],\n",
              "                            [ 1.43197387e-01, -1.43251169e+00],\n",
              "                            ...,\n",
              "                            [-2.21241176e-01, -5.44110239e-01],\n",
              "                            [ 1.39369965e-01,  3.54087591e-01],\n",
              "                            [ 3.15709174e-01, -1.26605654e+00]],\n",
              "                    \n",
              "                           [[ 1.37616262e-01, -1.32126665e+00],\n",
              "                            [ 1.04642153e+00,  1.17249727e+00],\n",
              "                            [ 1.39185609e-02, -5.47779322e-01],\n",
              "                            ...,\n",
              "                            [ 2.51329243e-01,  2.23141968e-01],\n",
              "                            [ 5.47267318e-01,  1.48401093e+00],\n",
              "                            [-3.32197368e-01,  8.17373753e-01]]], dtype=float32)],\n",
              "                  initial_momentum=[Array([[[-0.96332777, -1.1250091 ],\n",
              "                            [ 0.20253749, -0.2506577 ],\n",
              "                            [ 0.78379405, -0.14427261],\n",
              "                            ...,\n",
              "                            [ 0.77145904,  0.24545658],\n",
              "                            [ 0.07225081,  1.5254396 ],\n",
              "                            [-0.526809  , -0.48367321]],\n",
              "                    \n",
              "                           [[ 1.1778145 ,  1.4967018 ],\n",
              "                            [ 0.2844264 , -0.27102908],\n",
              "                            [-0.94161344, -0.443367  ],\n",
              "                            ...,\n",
              "                            [-1.259656  ,  1.2693466 ],\n",
              "                            [ 1.7579414 , -0.95281035],\n",
              "                            [ 1.5316037 , -0.67221695]],\n",
              "                    \n",
              "                           [[ 0.7880836 ,  0.28149754],\n",
              "                            [ 1.3185014 , -0.35526076],\n",
              "                            [-0.66371024,  0.0566555 ],\n",
              "                            ...,\n",
              "                            [ 0.16612312,  0.24547905],\n",
              "                            [ 1.2701689 ,  1.0985034 ],\n",
              "                            [ 1.049194  , -0.3984777 ]],\n",
              "                    \n",
              "                           ...,\n",
              "                    \n",
              "                           [[ 0.28688002,  1.837185  ],\n",
              "                            [ 1.4591414 ,  0.4844868 ],\n",
              "                            [-1.6968105 , -0.5030895 ],\n",
              "                            ...,\n",
              "                            [ 1.3265201 ,  1.9116114 ],\n",
              "                            [-1.1707239 , -0.4332642 ],\n",
              "                            [ 1.6716737 ,  0.64042985]],\n",
              "                    \n",
              "                           [[-0.4172757 , -0.59887016],\n",
              "                            [-2.1111622 , -0.70637417],\n",
              "                            [ 0.60134757,  2.5669801 ],\n",
              "                            ...,\n",
              "                            [-1.3878356 ,  0.07409135],\n",
              "                            [ 0.6899741 ,  0.29730007],\n",
              "                            [ 1.4096804 , -0.9711944 ]],\n",
              "                    \n",
              "                           [[ 1.426243  ,  1.2602721 ],\n",
              "                            [-1.0530668 , -0.86744857],\n",
              "                            [-1.0293602 ,  0.16205172],\n",
              "                            ...,\n",
              "                            [-0.65862197,  0.11130046],\n",
              "                            [-0.99970907, -1.1749336 ],\n",
              "                            [ 0.5274221 , -0.9005368 ]]], dtype=float32)],\n",
              "                  final_momentum=[Array([[[-4.14826536e+00, -6.30080462e+00],\n",
              "                            [-3.67789555e+00, -6.34117126e+00],\n",
              "                            [-3.26069713e+00, -6.51083136e+00],\n",
              "                            ...,\n",
              "                            [ 8.19041014e-01,  1.52607882e+00],\n",
              "                            [ 1.12219535e-01,  2.17271662e+00],\n",
              "                            [-4.16834444e-01,  1.18552065e+00]],\n",
              "                    \n",
              "                           [[ 4.66651709e+03,  1.30389661e+03],\n",
              "                            [ 2.18303094e+05,  1.53288389e+04],\n",
              "                            [ 4.04307594e+05,  2.28741016e+04],\n",
              "                            ...,\n",
              "                            [-7.93614807e+02, -6.69676880e+02],\n",
              "                            [-1.14873291e+03,  7.78704346e+02],\n",
              "                            [ 2.04632153e+03, -9.13046692e+02]],\n",
              "                    \n",
              "                           [[ 2.66836357e+00,  1.97833323e+00],\n",
              "                            [ 2.16732044e+01,  1.73208160e+01],\n",
              "                            [ 4.95967445e+01,  3.14942627e+01],\n",
              "                            ...,\n",
              "                            [ 2.99723506e-01, -3.33685017e+00],\n",
              "                            [ 1.46633470e+00, -1.23878109e+00],\n",
              "                            [ 2.00530720e+00, -3.79040480e+00]],\n",
              "                    \n",
              "                           ...,\n",
              "                    \n",
              "                           [[ 8.42505395e-01, -1.14748371e+00],\n",
              "                            [ 1.20684040e+00, -1.63988400e+00],\n",
              "                            [-1.89559400e+00,  8.88638616e-01],\n",
              "                            ...,\n",
              "                            [ 4.77876395e-01, -1.69626796e+00],\n",
              "                            [-5.13294458e-01,  1.54902756e-01],\n",
              "                            [ 1.51432312e+00, -5.90167761e-01]],\n",
              "                    \n",
              "                           [[-7.60605037e-01, -1.00398767e+00],\n",
              "                            [-1.42983294e+00,  8.76998603e-01],\n",
              "                            [ 8.39128643e-02,  2.24088264e+00],\n",
              "                            ...,\n",
              "                            [-1.39603448e+00, -1.16853464e+00],\n",
              "                            [ 1.58754432e+00,  1.47170460e+00],\n",
              "                            [ 2.02681661e+00, -9.44507599e-01]],\n",
              "                    \n",
              "                           [[ 1.52033591e+00, -3.64178151e-01],\n",
              "                            [ 5.53068459e-01,  9.63476837e-01],\n",
              "                            [-9.21588004e-01, -1.38860965e+00],\n",
              "                            ...,\n",
              "                            [-6.75387084e-01, -1.48397446e-01],\n",
              "                            [-4.84308064e-01,  2.70610839e-01],\n",
              "                            [ 5.54471612e-01, -1.25634515e+00]]], dtype=float32)],\n",
              "                  step_size=Array([ 1.        , 15.403648  ,  2.9887986 , ...,  0.44453478,\n",
              "                            0.44453478,  0.44453478], dtype=float32),\n",
              "                  num_leapfrog_steps=Array([ 1,  1,  1, ...,  5, 15,  3], dtype=int32),\n",
              "                  seed=Array([[4152882100, 1063452627],\n",
              "                           [2344160851,  391550721],\n",
              "                           [1254522445, 1283988004],\n",
              "                           ...,\n",
              "                           [1635269044,  624824847],\n",
              "                           [ 331994813, 4178527252],\n",
              "                           [3354875503,  477759283]], dtype=uint32)\n",
              "                ),\n",
              "              extra=[],\n",
              "              seed=Array([[2257911092, 3587725545],\n",
              "                       [ 866270928, 3880635670],\n",
              "                       [1090025126, 1189820073],\n",
              "                       ...,\n",
              "                       [3149703834, 1613121721],\n",
              "                       [4264675069,  988016054],\n",
              "                       [  88073859, 2982442748]], dtype=uint32)\n",
              "            ),\n",
              "          max_trajectory_length=Array([ 1.0253152,  1.0253152,  1.035436 , ..., 10.121253 , 10.121253 ,\n",
              "                   10.121253 ], dtype=float32),\n",
              "          step=Array([     1,      2,      3, ..., 100098, 100099, 100100], dtype=int32),\n",
              "          adaptation_rate=Array([0.025, 0.025, 0.025, ..., 0.025, 0.025, 0.025], dtype=float32),\n",
              "          jitter_amount=Array([1., 1., 1., ..., 1., 1., 1.], dtype=float32),\n",
              "          averaged_sq_grad=Array([   586.2419 ,    556.9298 ,    559.35443, ..., 177898.3    ,\n",
              "                   177898.3    , 177898.3    ], dtype=float32),\n",
              "          averaged_sq_grad_adaptation_rate=Array([0.05, 0.05, 0.05, ..., 0.05, 0.05, 0.05], dtype=float32),\n",
              "          averaged_max_trajectory_length=Array([1.0253152, 1.0253152, 1.0311464, ..., 8.36582  , 8.36582  ,\n",
              "                   8.36582  ], dtype=float32),\n",
              "          criterion=Array([[1.5648315e-02, 8.7821732e+00, 1.8493975e+01, ..., 2.5311122e+02,\n",
              "                    9.5053162e+02, 5.3091864e+02],\n",
              "                   [1.1638029e+07, 5.4354181e+09, 1.2484309e+10, ..., 2.0506388e+07,\n",
              "                    1.9636064e+07, 1.8157984e+08],\n",
              "                   [1.5316135e+03, 1.0885918e+04, 5.1154133e+04, ..., 3.6899128e+03,\n",
              "                    8.8001501e+02, 1.6627787e+03],\n",
              "                   ...,\n",
              "                   [6.4343393e-01, 1.7906468e+00, 2.6820351e+01, ..., 1.6716200e+02,\n",
              "                    8.6366028e+02, 1.1556255e+03],\n",
              "                   [1.3885426e+01, 6.5083540e+03, 1.0402271e+01, ..., 1.8510382e+03,\n",
              "                    2.0515449e+03, 3.8779392e+01],\n",
              "                   [4.4192630e-01, 2.0896160e+01, 9.6561879e-01, ..., 1.0121708e+02,\n",
              "                    6.4582222e+01, 6.0120510e+01]], dtype=float32),\n",
              "          seed=Array([[0, 0],\n",
              "                   [0, 0],\n",
              "                   [0, 0],\n",
              "                   ...,\n",
              "                   [0, 0],\n",
              "                   [0, 0],\n",
              "                   [0, 0]], dtype=uint32)\n",
              "        ),\n",
              "      target_accept_prob=Array([0.75, 0.75, 0.75, ..., 0.75, 0.75, 0.75], dtype=float32),\n",
              "      log_shrinkage_target=[Array([2.3025851, 2.3025851, 2.3025851, ..., 2.3025851, 2.3025851,\n",
              "               2.3025851], dtype=float32)],\n",
              "      exploration_shrinkage=Array([0.05, 0.05, 0.05, ..., 0.05, 0.05, 0.05], dtype=float32),\n",
              "      step_count_smoothing=Array([10., 10., 10., ..., 10., 10., 10.], dtype=float32),\n",
              "      decay_rate=Array([0.75, 0.75, 0.75, ..., 0.75, 0.75, 0.75], dtype=float32),\n",
              "      error_sum=[Array([-2.3761052e-01,  5.1238948e-01,  1.2623894e+00, ...,\n",
              "               -2.3364576e+04, -2.3364809e+04, -2.3365035e+04], dtype=float32)],\n",
              "      log_averaging_step=[Array([ 2.7346044,  1.7596135,  0.5221052, ..., -0.810727 , -0.810727 ,\n",
              "               -0.810727 ], dtype=float32)],\n",
              "      step=Array([     1,      2,      3, ..., 100098, 100099, 100100], dtype=int32),\n",
              "      num_adaptation_steps=Array([100, 100, 100, ..., 100, 100, 100], dtype=int32),\n",
              "      new_step_size=Array([15.403648  ,  2.9887986 ,  0.3460073 , ...,  0.44453478,\n",
              "                0.44453478,  0.44453478], dtype=float32)\n",
              "    )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "tf.executing_eagerly()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nwoyTCcDv4nT",
        "outputId": "e38e5fb6-05af-4910-935a-ac74954cb579"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.python.ops.linalg_ops import matrix_determinant\n",
        "# This is the implementation from the rhat_locker.ipynb\n",
        "\n",
        "\"\"\"\n",
        "# Inquire about _axis_size as a function, and what it is meant to do\n",
        "\n",
        "#def _axis_size(x, axis = None):\n",
        "#  return\n",
        "\n",
        "# What is Pavel's example? How can this be rewritten without tf (maybe JAX)?\n",
        "# What is the purpose of removing TF\n",
        "def _reduce_variance(x, axis= None, biased = True, keepdims = False):\n",
        "  with tf.name_scope('reduce_variance'):\n",
        "    x = tf.convert_to_tensor(x, name = 'x')\n",
        "    mean = tf.reduce_mean(x, axis=axis, keepdims=True)\n",
        "    biased_var = tf.reduce_mean(\n",
        "        tf.math.squared_difference(x, mean), axis = axis, keepdims = keepdims)\n",
        "    if biased:\n",
        "      return biased_var\n",
        "    n = _axis_size(x, axis)\n",
        "    return (n / (n-1.))*biased_var\n",
        "\n",
        "\n",
        "def nested_rhat(result_state, num_super_chains):\n",
        "  used_samples = result_state.shape[0]\n",
        "  num_sub_chains = result_state.shape[1]\n",
        "  num_dimensions = result_state.shape[2]\n",
        "\n",
        "  chain_states = result_state.reshape(used_samples, -1, num_sub_chains,\n",
        "                                      num_dimensions)\n",
        "  state = tf.convert_to_tensor(chain_states, name = 'state')\n",
        "  mean_chain = tf.reduce_mean(state, axis = 0)\n",
        "  mean_super_chain = tf.reduce_mean(state, axis = [0, 2])\n",
        "  variance_chain = _reduce_variance(state, axis = 0, biased = True)\n",
        "  variance_super_chain = _reduce_variance(state, axis = 0, biased = True) \\\n",
        "     + tf.reduce_mean(variance_chain, axis = -1)\n",
        "\n",
        "  W = tf.reduce_mean(variance_super_chain, axis = 0)\n",
        "  B = _reduce_variance(mean_super_chain, axis = 0, biased = True)\n",
        "\n",
        "  return tf.sqrt((W+B) / W)\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "gzyO-fJbxGZA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "41cc30d3-4ad8-44a3-9901-a7bcacd9d13a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n# Inquire about _axis_size as a function, and what it is meant to do\\n\\n#def _axis_size(x, axis = None):\\n#  return\\n\\n# What is Pavel's example? How can this be rewritten without tf (maybe JAX)?\\n# What is the purpose of removing TF\\ndef _reduce_variance(x, axis= None, biased = True, keepdims = False):\\n  with tf.name_scope('reduce_variance'):\\n    x = tf.convert_to_tensor(x, name = 'x')\\n    mean = tf.reduce_mean(x, axis=axis, keepdims=True)\\n    biased_var = tf.reduce_mean(\\n        tf.math.squared_difference(x, mean), axis = axis, keepdims = keepdims)\\n    if biased:\\n      return biased_var\\n    n = _axis_size(x, axis)\\n    return (n / (n-1.))*biased_var\\n\\n\\ndef nested_rhat(result_state, num_super_chains):\\n  used_samples = result_state.shape[0]\\n  num_sub_chains = result_state.shape[1]\\n  num_dimensions = result_state.shape[2]\\n\\n  chain_states = result_state.reshape(used_samples, -1, num_sub_chains,\\n                                      num_dimensions)\\n  state = tf.convert_to_tensor(chain_states, name = 'state')\\n  mean_chain = tf.reduce_mean(state, axis = 0)\\n  mean_super_chain = tf.reduce_mean(state, axis = [0, 2])\\n  variance_chain = _reduce_variance(state, axis = 0, biased = True)\\n  variance_super_chain = _reduce_variance(state, axis = 0, biased = True)      + tf.reduce_mean(variance_chain, axis = -1)\\n\\n  W = tf.reduce_mean(variance_super_chain, axis = 0)\\n  B = _reduce_variance(mean_super_chain, axis = 0, biased = True)\\n\\n  return tf.sqrt((W+B) / W)\\n\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define nested Rhat for one parameter.\n",
        "# This assumes the indexed parameter is a scalar, hence the result_state\n",
        "# tensor needs to be formatted accordingly.\n",
        "# TODO: deprecate state_is_list argument\n",
        "def nested_rhat_1dim(result_state, num_super_chains, index_param,\n",
        "                     num_samples, warmup_length = 0,\n",
        "                     rank_normalize = False):\n",
        "                     # state_is_list = False, vector_index = None):\n",
        "\n",
        "  # The below code is DEPRECATED\n",
        "  # if state_is_list:\n",
        "  #   if vector_index is not None:\n",
        "  #     state_param = result_state[index_param][\n",
        "  #                 warmup_length:(warmup_length + num_samples), :, vector_index]\n",
        "  #   else:\n",
        "  #     state_param = result_state[index_param][\n",
        "  #                       warmup_length:(warmup_length + num_samples), :]\n",
        "  # else:\n",
        "  #   state_param = result_state[warmup_length:(warmup_length + num_samples),\n",
        "  #                              :, index_param]\n",
        "\n",
        "  state_param = result_state[warmup_length:(warmup_length + num_samples),\n",
        "                             :, index_param]\n",
        "\n",
        "  num_samples = state_param.shape[0]\n",
        "  num_chains = state_param.shape[1]\n",
        "  num_sub_chains = num_chains // num_super_chains\n",
        "  total_samples = num_samples * num_chains\n",
        "\n",
        "  if (rank_normalize):\n",
        "    state_param_flat = jnp.reshape(state_param, (total_samples, ))\n",
        "    temp = state_param_flat.argsort()\n",
        "    ranks = temp.argsort() + 1\n",
        "    z = norm.ppf((ranks - 3 / 8) / (total_samples + 1 / 4))\n",
        "    state_parm = jnp.reshape(z, (num_samples, num_chains))\n",
        "\n",
        "  state_param = state_param.reshape(num_samples, -1, num_sub_chains, 1)\n",
        "\n",
        "  mean_chain = jnp.mean(state_param, axis = (0, 3))\n",
        "  between_chain_var = jnp.var(mean_chain, axis = 1, ddof = 1)\n",
        "  if (num_samples == 1):\n",
        "    mean_within_chain_var = 0\n",
        "  else:\n",
        "    within_chain_var = jnp.var(state_param, axis = (0, 3), ddof = 1)\n",
        "    mean_within_chain_var = jnp.mean(within_chain_var, axis = 1)\n",
        "\n",
        "  total_chain_var = between_chain_var + mean_within_chain_var\n",
        "\n",
        "  mean_super_chain = jnp.mean(state_param, axis = (0, 2, 3))\n",
        "  between_super_chain_var = jnp.var(mean_super_chain, ddof = 1)\n",
        "\n",
        "  return jnp.sqrt(1 + between_super_chain_var / jnp.mean(total_chain_var)),\\\n",
        "    between_super_chain_var, jnp.mean(total_chain_var)\n",
        "\n",
        "\n",
        "def nested_rhat(result_state, num_super_chains, index_param,\n",
        "                num_samples, warmup_length = 0, rank_normalize = False):\n",
        "  nRhat = jnp.array([])\n",
        "  B = jnp.array([])\n",
        "  W = jnp.array([])\n",
        "  for i in range(0, index_param.shape[0]):\n",
        "    nRhat_local, B_local, W_local = nested_rhat_1dim(result_state,\n",
        "                    num_super_chains, index_param[i], num_samples,\n",
        "                    warmup_length, rank_normalize)\n",
        "\n",
        "    nRhat = jnp.append(nRhat, nRhat_local)\n",
        "    B = jnp.append(B, B_local)\n",
        "    W = jnp.append(W, W_local)\n",
        "\n",
        "  return nRhat, B, W"
      ],
      "metadata": {
        "id": "UdjThIa-lxJT"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using ChEES-HMC in order to get the most out of a GPU"
      ],
      "metadata": {
        "id": "Yog1nM3m2_Bd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select HMC Variant from options chees, snaper, or malt\n",
        "\n",
        "def construct_kernel(target_log_prob_fn, init_step_size, num_warmup, transition = 'chees'):\n",
        "  if transition == 'chees':\n",
        "    # Using gradient-based trajectory length adaptation and dual averaging defines ChEES HMC\n",
        "    kernel = tfp.mcmc.HamiltonianMonteCarlo(target_log_prob_fn, init_step_size, 1)\n",
        "    kernel = tfp.experimental.mcmc.GradientBasedTrajectoryLengthAdaptation(kernel, num_warmup)\n",
        "    kernel = tfp.mcmc.DualAveragingStepSizeAdaptation(\n",
        "        kernel, num_warmup, target_accept_prob = 0.75,\n",
        "        reduce_fn = tfp.math.reduce_log_harmonic_mean_exp)\n",
        "\n",
        "  elif transition == 'snaper':\n",
        "    # TO BE IMPLEMENTED\n",
        "    kernel = 'snaper'\n",
        "\n",
        "  elif transition == 'malt':\n",
        "    # TO BE IMPLEMENTED\n",
        "    kernel = 'malt'\n",
        "\n",
        "  else:\n",
        "    raise Exception(\"Not a valid transition kernel. Try one of ['chees', 'snaper', 'malt']\")\n",
        "\n",
        "  return kernel"
      ],
      "metadata": {
        "id": "l4mElY4y3Uyu"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "jnp.array([0, 1]).shape[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k68DP7cKA8ej",
        "outputId": "59c3f54e-65b5-44fb-ab82-3bc7b048325a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def run_fits(num_seed, total_samples, initialize, kernel, num_super_chains,\n",
        "             index_param, num_samples, num_warmup, rank_normalize = False):\n",
        "\n",
        "  num_parameters = index_param.shape[0]\n",
        "\n",
        "  Rhat_list = jnp.zeros((num_seed, num_parameters))\n",
        "  nRhat_list = jnp.zeros((num_seed, num_parameters))\n",
        "  B_list = jnp.zeros((num_seed, num_parameters))\n",
        "  W_list = jnp.zeros((num_seed, num_parameters))\n",
        "  mc_mean_list = jnp.zeros((num_seed, num_parameters))\n",
        "\n",
        "  i = 0\n",
        "  for seed in jax.random.split(jax.random.PRNGKey(1), num_seed):\n",
        "    initial_state = initialize((num_super_chains,), key = seed + 1954)\n",
        "\n",
        "    initial_state = jnp.repeat(initial_state, num_chains // num_super_chains,\n",
        "                              axis = 0)\n",
        "\n",
        "    result = tfp.mcmc.sample_chain(total_samples, initial_state, kernel = kernel, seed = seed)\n",
        "\n",
        "    # Implementation of original R-Hat from Gelman and Rubin (1992)\n",
        "    Rhat_list = Rhat_list.at[i, :].set(tfp.mcmc.potential_scale_reduction(result.all_states[num_warmup:(num_warmup + num_samples), :, index_param]))\n",
        "\n",
        "    nRhat_local, B_local, W_local = nested_rhat(result.all_states,\n",
        "                                                num_super_chains = num_super_chains,\n",
        "                                                index_param = index_param,\n",
        "                                                num_samples = num_samples,\n",
        "                                                warmup_length = num_warmup,\n",
        "                                                rank_normalize = rank_normalize)\n",
        "    nRhat_list = nRhat_list.at[i, :].set(nRhat_local)\n",
        "    B_list = B_list.at[i, :].set(B_local)\n",
        "    W_list = W_list.at[i, :].set(W_local)\n",
        "\n",
        "    mc_mean_list = mc_mean_list.at[i, :].set(jnp.mean(result.all_states[num_warmup + 1, :, index_param], axis = 1))\n",
        "    i += 1\n",
        "\n",
        "  return Rhat_list, nRhat_list, B_list, W_list, mc_mean_list\n"
      ],
      "metadata": {
        "id": "yyDBbuoR3Zq-"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adaptive warmup scheme to produce MCMC samples\n",
        "def forge_chain(kernel_cold, kernel_warm, initial_state, num_super_chains,\n",
        "                num_warmup_array, num_samples, target_rhat, max_num_steps,\n",
        "                index_param, seed, num_nRhat_comp = 1, rank_normalize = False,\n",
        "                alpha_quantile = 1, mean_benchmark = None, var_benchmark = None):\n",
        "  warmup_is_acceptable = False\n",
        "  window_iteration = 0\n",
        "  current_state = initial_state\n",
        "  kernel_args = None\n",
        "\n",
        "  squared_err_list = jnp.array([])\n",
        "  nrhat_list = jnp.array([])\n",
        "\n",
        "  while(not warmup_is_acceptable and window_iteration < max_num_steps):\n",
        "\n",
        "    # Runs MCMC with a warmup window\n",
        "    result_cold, trace, kernel_args = tfp.mcmc.sample_chain(\n",
        "        num_results = num_warmup_array[window_iteration],\n",
        "        current_state = current_state,\n",
        "        kernel = kernel_cold,\n",
        "        previous_kernel_results = kernel_args,\n",
        "        trace_fn = lambda _, pkr: unnest.get_innermost(pkr, 'step_size'),\n",
        "        return_final_kernel_results = True,\n",
        "        seed = seed + window_iteration)\n",
        "\n",
        "    current_state = result_cold[-1]\n",
        "\n",
        "    # Generate candidate samples\n",
        "    result_warm, trace = tfp.mcmc.sample_chain(\n",
        "        num_results = num_samples*num_nRhat_comp,\n",
        "        current_state = current_state,\n",
        "        kernel = kernel_warm,\n",
        "        trace_fn = lambda _, pkr: unnest.get_innermost(pkr, 'step_size'),\n",
        "        previous_kernel_results = kernel_args,\n",
        "\n",
        "        # Why are we just adding numbers to seeds like this? I get it is to randomize but is there a more principled way?\n",
        "        seed = seed + 999999)\n",
        "\n",
        "    # Check if candidate samples are acceptable\n",
        "    nRhat = jnp.zeros((index_param.shape[0], num_nRhat_comp))\n",
        "    for i in range(0, num_nRhat_comp):\n",
        "      nR, _B, _W = nested_rhat(result_warm[i:((i+1)*num_samples)],\n",
        "                                        num_super_chains = num_super_chains,\n",
        "                                        index_param = index_param,\n",
        "                                        num_samples = num_samples,\n",
        "                                        rank_normalize = rank_normalize)\n",
        "      nRhat = nRhat.at[:, i].set(nR)\n",
        "\n",
        "    nRhat_quantile = jnp.quantile(jnp.mean(nRhat, axis = 1), alpha_quantile,\n",
        "                                 interpolation = \"nearest\")\n",
        "    print(\"nRhat_quantile: (\", alpha_quantile, \")\", nRhat_quantile)\n",
        "\n",
        "    if mean_benchmark is not None:\n",
        "      mc_mean = jnp.mean(result_warm[0, :, index_param], axis = 1)\n",
        "      squared_err = jnp.square(mc_mean - mean_benchmark[index_param])\\\n",
        "      / var_benchmark[index_param]\n",
        "\n",
        "      squared_err_list = jnp.append(squared_err_list, squared_err)\n",
        "      nrhat_list = jnp.append(nrhat_list, jnp.mean(nRhat, axis = 1))\n",
        "\n",
        "    if (nRhat_quantile < target_rhat): warmup_is_acceptable = True\n",
        "\n",
        "    window_iteration += 1\n",
        "\n",
        "  return result_warm, window_iteration, squared_err_list, nrhat_list"
      ],
      "metadata": {
        "id": "RggIF9Hqmxh1"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_forge_chain(num_seed, kernel_cold, kernel_warm, initialize, num_super_chains,\n",
        "                    num_warmup, num_samples, target_rhat, max_num_steps,\n",
        "                    index_param, num_nRhat_comp = 1, rank_normalize = False,\n",
        "                    alpha_quantile = 1, mean_benchmark = None,\n",
        "                    var_benchmark = None, initial_seed = 1):\n",
        "  mc_mean_list = jnp.zeros((num_seed, index_param.shape[0]))\n",
        "  warmup_length = jnp.zeros(num_seed)\n",
        "\n",
        "  squared_err_list_all = jnp.array([])\n",
        "  nrhat_list_all = jnp.array([])\n",
        "\n",
        "  i = 0\n",
        "  for seed in jax.random.split(jax.random.PRNGKey(initial_seed), num_seed):\n",
        "    print(\"NEW SEED\")\n",
        "    initial_state = initialize((num_super_chains,), key = seed + 1954)\n",
        "    initial_state = jnp.repeat(initial_state, num_chains // num_super_chains,\n",
        "                              axis = 0)\n",
        "\n",
        "    result, window_iteration, \\\n",
        "    squared_err_list, nrhat_list = forge_chain(kernel_cold, kernel_warm,\n",
        "                                               initial_state, num_super_chains,\n",
        "                                               num_warmup, num_samples,\n",
        "                                               target_rhat, max_num_steps,\n",
        "                                               index_param, seed,\n",
        "                                               num_nRhat_comp, rank_normalize,\n",
        "                                               alpha_quantile, mean_benchmark,\n",
        "                                               var_benchmark)\n",
        "\n",
        "    warmup_length = warmup_length.at[i].set(sum(num_warmup[:window_iteration]))\n",
        "    mc_mean_list = mc_mean_list.at[i, :].set(jnp.mean(result[0, :, index_param],\n",
        "                                 axis = 1))\n",
        "\n",
        "    squared_err_list_all = jnp.append(squared_err_list_all, squared_err_list)\n",
        "    nrhat_list_all = jnp.append(nrhat_list_all, nrhat_list)\n",
        "\n",
        "    i += 1\n",
        "  return mc_mean_list, warmup_length, squared_err_list_all, nrhat_list_all"
      ],
      "metadata": {
        "id": "48aMam844B1f"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_warmup, num_samples = 1000, 5\n",
        "total_samples = num_warmup + num_samples + 1\n",
        "\n",
        "kernel = construct_kernel(target_log_prob_fn = target_log_prob_fn,\n",
        "                          init_step_size = init_step_size, num_warmup = num_warmup,\n",
        "                          transition = 'chees')\n",
        "index_param = jnp.array([0, 1])\n",
        "num_seed = 30\n",
        "rank_normalize = False"
      ],
      "metadata": {
        "id": "T25EaHnhZfmt"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Rhat_list, nRhat_list, B_list, W_list, mc_mean_list = run_fits(\n",
        "           num_seed = num_seed, total_samples = total_samples,\n",
        "           initialize = bn_initialize, kernel = kernel,\n",
        "           num_super_chains = K, index_param = index_param,\n",
        "           num_samples = num_samples, num_warmup = num_warmup,\n",
        "           rank_normalize = rank_normalize)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6DS_pAKjaNEa",
        "outputId": "20b02bb3-3f59-487d-b0b9-f092e0a43595"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow_probability/substrates/jax/mcmc/sample.py:339: UserWarning: Tracing all kernel results by default is deprecated. Set the `trace_fn` argument to None (the future default value) or an explicit callback that traces the values you are interested in.\n",
            "  warnings.warn('Tracing all kernel results by default is deprecated. Set '\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow_probability/substrates/jax/mcmc/sample.py:339: UserWarning: Tracing all kernel results by default is deprecated. Set the `trace_fn` argument to None (the future default value) or an explicit callback that traces the values you are interested in.\n",
            "  warnings.warn('Tracing all kernel results by default is deprecated. Set '\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow_probability/substrates/jax/mcmc/sample.py:339: UserWarning: Tracing all kernel results by default is deprecated. Set the `trace_fn` argument to None (the future default value) or an explicit callback that traces the values you are interested in.\n",
            "  warnings.warn('Tracing all kernel results by default is deprecated. Set '\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow_probability/substrates/jax/mcmc/sample.py:339: UserWarning: Tracing all kernel results by default is deprecated. Set the `trace_fn` argument to None (the future default value) or an explicit callback that traces the values you are interested in.\n",
            "  warnings.warn('Tracing all kernel results by default is deprecated. Set '\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow_probability/substrates/jax/mcmc/sample.py:339: UserWarning: Tracing all kernel results by default is deprecated. Set the `trace_fn` argument to None (the future default value) or an explicit callback that traces the values you are interested in.\n",
            "  warnings.warn('Tracing all kernel results by default is deprecated. Set '\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow_probability/substrates/jax/mcmc/sample.py:339: UserWarning: Tracing all kernel results by default is deprecated. Set the `trace_fn` argument to None (the future default value) or an explicit callback that traces the values you are interested in.\n",
            "  warnings.warn('Tracing all kernel results by default is deprecated. Set '\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow_probability/substrates/jax/mcmc/sample.py:339: UserWarning: Tracing all kernel results by default is deprecated. Set the `trace_fn` argument to None (the future default value) or an explicit callback that traces the values you are interested in.\n",
            "  warnings.warn('Tracing all kernel results by default is deprecated. Set '\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow_probability/substrates/jax/mcmc/sample.py:339: UserWarning: Tracing all kernel results by default is deprecated. Set the `trace_fn` argument to None (the future default value) or an explicit callback that traces the values you are interested in.\n",
            "  warnings.warn('Tracing all kernel results by default is deprecated. Set '\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow_probability/substrates/jax/mcmc/sample.py:339: UserWarning: Tracing all kernel results by default is deprecated. Set the `trace_fn` argument to None (the future default value) or an explicit callback that traces the values you are interested in.\n",
            "  warnings.warn('Tracing all kernel results by default is deprecated. Set '\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow_probability/substrates/jax/mcmc/sample.py:339: UserWarning: Tracing all kernel results by default is deprecated. Set the `trace_fn` argument to None (the future default value) or an explicit callback that traces the values you are interested in.\n",
            "  warnings.warn('Tracing all kernel results by default is deprecated. Set '\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow_probability/substrates/jax/mcmc/sample.py:339: UserWarning: Tracing all kernel results by default is deprecated. Set the `trace_fn` argument to None (the future default value) or an explicit callback that traces the values you are interested in.\n",
            "  warnings.warn('Tracing all kernel results by default is deprecated. Set '\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow_probability/substrates/jax/mcmc/sample.py:339: UserWarning: Tracing all kernel results by default is deprecated. Set the `trace_fn` argument to None (the future default value) or an explicit callback that traces the values you are interested in.\n",
            "  warnings.warn('Tracing all kernel results by default is deprecated. Set '\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow_probability/substrates/jax/mcmc/sample.py:339: UserWarning: Tracing all kernel results by default is deprecated. Set the `trace_fn` argument to None (the future default value) or an explicit callback that traces the values you are interested in.\n",
            "  warnings.warn('Tracing all kernel results by default is deprecated. Set '\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow_probability/substrates/jax/mcmc/sample.py:339: UserWarning: Tracing all kernel results by default is deprecated. Set the `trace_fn` argument to None (the future default value) or an explicit callback that traces the values you are interested in.\n",
            "  warnings.warn('Tracing all kernel results by default is deprecated. Set '\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow_probability/substrates/jax/mcmc/sample.py:339: UserWarning: Tracing all kernel results by default is deprecated. Set the `trace_fn` argument to None (the future default value) or an explicit callback that traces the values you are interested in.\n",
            "  warnings.warn('Tracing all kernel results by default is deprecated. Set '\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow_probability/substrates/jax/mcmc/sample.py:339: UserWarning: Tracing all kernel results by default is deprecated. Set the `trace_fn` argument to None (the future default value) or an explicit callback that traces the values you are interested in.\n",
            "  warnings.warn('Tracing all kernel results by default is deprecated. Set '\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow_probability/substrates/jax/mcmc/sample.py:339: UserWarning: Tracing all kernel results by default is deprecated. Set the `trace_fn` argument to None (the future default value) or an explicit callback that traces the values you are interested in.\n",
            "  warnings.warn('Tracing all kernel results by default is deprecated. Set '\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow_probability/substrates/jax/mcmc/sample.py:339: UserWarning: Tracing all kernel results by default is deprecated. Set the `trace_fn` argument to None (the future default value) or an explicit callback that traces the values you are interested in.\n",
            "  warnings.warn('Tracing all kernel results by default is deprecated. Set '\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow_probability/substrates/jax/mcmc/sample.py:339: UserWarning: Tracing all kernel results by default is deprecated. Set the `trace_fn` argument to None (the future default value) or an explicit callback that traces the values you are interested in.\n",
            "  warnings.warn('Tracing all kernel results by default is deprecated. Set '\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow_probability/substrates/jax/mcmc/sample.py:339: UserWarning: Tracing all kernel results by default is deprecated. Set the `trace_fn` argument to None (the future default value) or an explicit callback that traces the values you are interested in.\n",
            "  warnings.warn('Tracing all kernel results by default is deprecated. Set '\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow_probability/substrates/jax/mcmc/sample.py:339: UserWarning: Tracing all kernel results by default is deprecated. Set the `trace_fn` argument to None (the future default value) or an explicit callback that traces the values you are interested in.\n",
            "  warnings.warn('Tracing all kernel results by default is deprecated. Set '\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow_probability/substrates/jax/mcmc/sample.py:339: UserWarning: Tracing all kernel results by default is deprecated. Set the `trace_fn` argument to None (the future default value) or an explicit callback that traces the values you are interested in.\n",
            "  warnings.warn('Tracing all kernel results by default is deprecated. Set '\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow_probability/substrates/jax/mcmc/sample.py:339: UserWarning: Tracing all kernel results by default is deprecated. Set the `trace_fn` argument to None (the future default value) or an explicit callback that traces the values you are interested in.\n",
            "  warnings.warn('Tracing all kernel results by default is deprecated. Set '\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow_probability/substrates/jax/mcmc/sample.py:339: UserWarning: Tracing all kernel results by default is deprecated. Set the `trace_fn` argument to None (the future default value) or an explicit callback that traces the values you are interested in.\n",
            "  warnings.warn('Tracing all kernel results by default is deprecated. Set '\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow_probability/substrates/jax/mcmc/sample.py:339: UserWarning: Tracing all kernel results by default is deprecated. Set the `trace_fn` argument to None (the future default value) or an explicit callback that traces the values you are interested in.\n",
            "  warnings.warn('Tracing all kernel results by default is deprecated. Set '\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow_probability/substrates/jax/mcmc/sample.py:339: UserWarning: Tracing all kernel results by default is deprecated. Set the `trace_fn` argument to None (the future default value) or an explicit callback that traces the values you are interested in.\n",
            "  warnings.warn('Tracing all kernel results by default is deprecated. Set '\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow_probability/substrates/jax/mcmc/sample.py:339: UserWarning: Tracing all kernel results by default is deprecated. Set the `trace_fn` argument to None (the future default value) or an explicit callback that traces the values you are interested in.\n",
            "  warnings.warn('Tracing all kernel results by default is deprecated. Set '\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow_probability/substrates/jax/mcmc/sample.py:339: UserWarning: Tracing all kernel results by default is deprecated. Set the `trace_fn` argument to None (the future default value) or an explicit callback that traces the values you are interested in.\n",
            "  warnings.warn('Tracing all kernel results by default is deprecated. Set '\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow_probability/substrates/jax/mcmc/sample.py:339: UserWarning: Tracing all kernel results by default is deprecated. Set the `trace_fn` argument to None (the future default value) or an explicit callback that traces the values you are interested in.\n",
            "  warnings.warn('Tracing all kernel results by default is deprecated. Set '\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow_probability/substrates/jax/mcmc/sample.py:339: UserWarning: Tracing all kernel results by default is deprecated. Set the `trace_fn` argument to None (the future default value) or an explicit callback that traces the values you are interested in.\n",
            "  warnings.warn('Tracing all kernel results by default is deprecated. Set '\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# What is the use of a second dimension for computing rHat?\n",
        "nRhat_list.shape\n",
        "jnp.var(nRhat_list[:,1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QaLKGhR9mzjS",
        "outputId": "0a776bff-689b-4e1f-e54a-a7246c89ce89"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Array(1.0652867e-06, dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mc_mean_list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hy6AN-lRpmv7",
        "outputId": "a15e31fa-ed4b-40b7-a539-a456c0e08832"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Array([[ 0.67108625,  0.08250239],\n",
              "       [-0.23767622,  0.07473338],\n",
              "       [ 0.11974052,  0.05402053],\n",
              "       [-0.0779959 , -0.29601008],\n",
              "       [-0.3021367 ,  0.40538344],\n",
              "       [ 0.5211482 , -0.16167125],\n",
              "       [ 0.58794963,  0.0190184 ],\n",
              "       [-0.95380914,  0.40924037],\n",
              "       [ 0.60984075, -0.3701806 ],\n",
              "       [-0.5059649 ,  0.35890698],\n",
              "       [ 0.20344737, -0.23870113],\n",
              "       [ 0.05978912, -0.20745602],\n",
              "       [ 0.11211918, -0.22980669],\n",
              "       [-0.2892716 ,  0.0647719 ],\n",
              "       [ 0.12771514, -0.18332335],\n",
              "       [-0.06098558, -0.3125804 ],\n",
              "       [-0.01340416, -0.12903082],\n",
              "       [ 0.262689  , -0.16189626],\n",
              "       [ 0.5807346 ,  0.13833123],\n",
              "       [ 0.5393245 ,  0.14760461],\n",
              "       [ 0.09519129, -0.0539025 ],\n",
              "       [ 0.23255001, -0.04695915],\n",
              "       [ 0.17679004, -0.36940455],\n",
              "       [-0.17988108,  0.08165627],\n",
              "       [-0.05505823,  0.07657137],\n",
              "       [ 0.2515199 , -0.3048549 ],\n",
              "       [-0.3819338 ,  0.08875138],\n",
              "       [ 0.15690205, -0.46691388],\n",
              "       [ 0.1646577 , -0.34736368],\n",
              "       [-0.45768514,  0.1268898 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Parellelizing the calculations of nRhat instead of sequential running\n",
        "# This involves getting rid of the loop inside of the code for the regular run_fits(...)\n",
        "# Does this change how the seeds are calculated at all?\n",
        "# Removing the num_seed argument if this won't be run sequentially\n",
        "\n",
        "def run_fits_parallel(iterations, total_samples, initialize, kernel, num_super_chains,\n",
        "             index_param, num_samples, num_warmup, rank_normalize = False):\n",
        "\n",
        "  num_parameters = index_param.shape[0]\n",
        "\n",
        "  Rhat_list = jnp.zeros((num_seed, num_parameters))\n",
        "  nRhat_list = jnp.zeros((num_seed, num_parameters))\n",
        "  B_list = jnp.zeros((num_seed, num_parameters))\n",
        "  W_list = jnp.zeros((num_seed, num_parameters))\n",
        "  mc_mean_list = jnp.zeros((num_seed, num_parameters))\n",
        "\n",
        "  # Should this be a more explicit parameter into the method for reproducibility purposes?\n",
        "  seed = jax.random.PRNGKey(1)\n",
        "  initial_state = initialize((num_super_chains*iterations,), key = seed + 1954)\n",
        "\n",
        "  initial_state = jnp.repeat(initial_state, num_chains*iterations // num_super_chains,\n",
        "                              axis = 0)\n",
        "\n",
        "  result = tfp.mcmc.sample_chain(total_samples, initial_state, kernel = kernel, seed = seed)\n",
        "\n",
        "  # Loop over K superchains at a time in order to calculate nRhat statistics\n",
        "  # Investigate how JAX and looping may be impacting the speed of this loop\n",
        "\n",
        "  for i in range(iterations):\n",
        "    # Selecting the subset that corresponds to K superchains of size M\n",
        "    current_result = result.all_states[num_warmup:(num_warmup + num_samples), (i*num_chains):((i+1)*num_chains), index_param]\n",
        "    Rhat_list = Rhat_list.at[i, :].set(tfp.mcmc.potential_scale_reduction)\n",
        "\n",
        "    # Implementation of original R-Hat from Gelman and Rubin (1992)\n",
        "\n",
        "    Rhat_list = Rhat_list.at[i, :].set(tfp.mcmc.potential_scale_reduction(current_result))\n",
        "\n",
        "    nRhat_local, B_local, W_local = nested_rhat(current_result,\n",
        "                                                num_super_chains = num_super_chains,\n",
        "                                                index_param = index_param,\n",
        "                                                num_samples = num_samples,\n",
        "                                                warmup_length = num_warmup,\n",
        "                                                rank_normalize = rank_normalize)\n",
        "    nRhat_list = nRhat_list.at[i, :].set(nRhat_local)\n",
        "    B_list = B_list.at[i, :].set(B_local)\n",
        "    W_list = W_list.at[i, :].set(W_local)\n",
        "\n",
        "    mc_mean_list = mc_mean_list.at[i, :].set(jnp.mean(result.all_states[num_warmup + 1, (i*num_chains):((i+1)*num_chains), index_param], axis = 1))\n",
        "    i += 1\n",
        "\n",
        "  return Rhat_list, nRhat_list, B_list, W_list, mc_mean_list"
      ],
      "metadata": {
        "id": "lX3CPtM2lS0e"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This yields an error; is this just because Colab doesn't have the strongest GPUs?\n",
        "run_fits_parallel(\n",
        "           iterations = num_seed, total_samples = total_samples,\n",
        "           initialize = bn_initialize, kernel = kernel,\n",
        "           num_super_chains = K, index_param = index_param,\n",
        "           num_samples = num_samples, num_warmup = num_warmup,\n",
        "           rank_normalize = rank_normalize)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "u1EsgGMNsWBv",
        "outputId": "e2b454f3-d529-484f-d5ed-d26a86897150"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow_probability/substrates/jax/mcmc/sample.py:339: UserWarning: Tracing all kernel results by default is deprecated. Set the `trace_fn` argument to None (the future default value) or an explicit callback that traces the values you are interested in.\n",
            "  warnings.warn('Tracing all kernel results by default is deprecated. Set '\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "XlaRuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mXlaRuntimeError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-bac22933fcfb>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m run_fits_parallel(\n\u001b[0m\u001b[1;32m      2\u001b[0m            \u001b[0miterations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_seed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotal_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m            \u001b[0minitialize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbn_initialize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m            \u001b[0mnum_super_chains\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_param\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex_param\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m            \u001b[0mnum_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_warmup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_warmup\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-32-1237130f0ac5>\u001b[0m in \u001b[0;36mrun_fits_parallel\u001b[0;34m(iterations, total_samples, initialize, kernel, num_super_chains, index_param, num_samples, num_warmup, rank_normalize)\u001b[0m\n\u001b[1;32m     22\u001b[0m                               axis = 0)\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m   \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmcmc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_chain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m   \u001b[0;31m# Loop over K superchains at a time in order to calculate nRhat statistics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow_probability/substrates/jax/mcmc/sample.py\u001b[0m in \u001b[0;36msample_chain\u001b[0;34m(num_results, current_state, previous_kernel_results, kernel, num_burnin_steps, num_steps_between_results, trace_fn, return_final_kernel_results, parallel_iterations, seed, name)\u001b[0m\n\u001b[1;32m    357\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_kernel_results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m     (_, _, final_kernel_results), (all_states, trace) = loop_util.trace_scan(\n\u001b[0m\u001b[1;32m    360\u001b[0m         \u001b[0mloop_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_trace_scan_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0minitial_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprevious_kernel_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow_probability/substrates/jax/internal/loop_util.py\u001b[0m in \u001b[0;36mtrace_scan\u001b[0;34m(loop_fn, initial_state, elems, trace_fn, trace_criterion_fn, static_trace_allocation_size, condition_fn, parallel_iterations, name)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[0mtrace_arrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mtrace_elt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mflat_initial_trace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m       trace_arrays.append(tensor_array_from_element(\n\u001b[0m\u001b[1;32m    212\u001b[0m           trace_elt, size=initial_size, dynamic_size=dynamic_size))\n\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow_probability/substrates/jax/internal/loop_util.py\u001b[0m in \u001b[0;36mtensor_array_from_element\u001b[0;34m(elem, size, **kwargs)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;31m# So we cheat -- creating an array of similar keys here.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_jax_batched_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m   return tf.TensorArray(\n\u001b[0m\u001b[1;32m     63\u001b[0m       \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m       \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow_probability/python/internal/backend/jax/tensor_array_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dtype, size, dynamic_size, clear_after_read, tensor_array_name, handle, flow, infer_shape, element_shape, colocate_with_first_write_call, data, name)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mJAX_MODE\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msize\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0melement_shape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melement_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m       \u001b[0;31m# Can be useful for finding failure cases in JAX TensorArray-using code.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m       \u001b[0;31m# elif JAX_MODE:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/jax/_src/numpy/lax_numpy.py\u001b[0m in \u001b[0;36mempty\u001b[0;34m(shape, dtype)\u001b[0m\n\u001b[1;32m   2128\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDTypeLike\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mArray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2129\u001b[0m   \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_user_dtype_supported\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"empty\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2130\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/jax/_src/numpy/lax_numpy.py\u001b[0m in \u001b[0;36mzeros\u001b[0;34m(shape, dtype)\u001b[0m\n\u001b[1;32m   2112\u001b[0m   \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_user_dtype_supported\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"zeros\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2113\u001b[0m   \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcanonicalize_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2114\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mlax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_jnp_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2116\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/jax/_src/lax/lax.py\u001b[0m in \u001b[0;36mfull\u001b[0;34m(shape, fill_value, dtype)\u001b[0m\n\u001b[1;32m   1201\u001b[0m   \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanonicalize_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1202\u001b[0m   \u001b[0mfill_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_convert_element_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweak_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1203\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mbroadcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1205\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mzeros_like_shaped_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maval\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mShapedArray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mArray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/jax/_src/lax/lax.py\u001b[0m in \u001b[0;36mbroadcast\u001b[0;34m(operand, sizes)\u001b[0m\n\u001b[1;32m    766\u001b[0m   \"\"\"\n\u001b[1;32m    767\u001b[0m   \u001b[0mdims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msizes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 768\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mbroadcast_in_dim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperand\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msizes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    769\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m def broadcast_in_dim(operand: ArrayLike, shape: Shape,\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/jax/_src/lax/lax.py\u001b[0m in \u001b[0;36mbroadcast_in_dim\u001b[0;34m(operand, shape, broadcast_dimensions)\u001b[0m\n\u001b[1;32m    794\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    795\u001b[0m     \u001b[0mdyn_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatic_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 796\u001b[0;31m   return broadcast_in_dim_p.bind(\n\u001b[0m\u001b[1;32m    797\u001b[0m       \u001b[0moperand\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mdyn_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatic_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    798\u001b[0m       broadcast_dimensions=tuple(broadcast_dimensions))\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/jax/_src/core.py\u001b[0m in \u001b[0;36mbind\u001b[0;34m(self, *args, **params)\u001b[0m\n\u001b[1;32m    378\u001b[0m     assert (not config.jax_enable_checks or\n\u001b[1;32m    379\u001b[0m             all(isinstance(arg, Tracer) or valid_jaxtype(arg) for arg in args)), args\n\u001b[0;32m--> 380\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind_with_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfind_top_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mbind_with_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/jax/_src/core.py\u001b[0m in \u001b[0;36mbind_with_trace\u001b[0;34m(self, trace, args, params)\u001b[0m\n\u001b[1;32m    381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mbind_with_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 383\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_primitive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_raise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    384\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_lower\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiple_results\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mfull_lower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/jax/_src/core.py\u001b[0m in \u001b[0;36mprocess_primitive\u001b[0;34m(self, primitive, tracers, params)\u001b[0m\n\u001b[1;32m    788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mprocess_primitive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprimitive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 790\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mprimitive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimpl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    791\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    792\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mprocess_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprimitive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/jax/_src/dispatch.py\u001b[0m in \u001b[0;36mapply_primitive\u001b[0;34m(prim, *args, **params)\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mcompiled_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/jax/_src/dispatch.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    224\u001b[0m       orig_in_shardings)\n\u001b[1;32m    225\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mprim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiple_results\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcompiled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcompiled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/jax/_src/profiler.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    312\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mTraceAnnotation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mdecorator_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/jax/_src/interpreters/pxla.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1344\u001b[0m           results.consume_token())\n\u001b[1;32m   1345\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1346\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxla_executable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute_sharded\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_bufs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1347\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneeds_check_special\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1348\u001b[0m       \u001b[0mout_arrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisassemble_into_single_device_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mXlaRuntimeError\u001b[0m: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 1854259200 bytes.\nBufferAssignment OOM Debugging.\nBufferAssignment stats:\n             parameter allocation:         4B\n              constant allocation:         0B\n        maybe_live_out allocation:    1.73GiB\n     preallocated temp allocation:         0B\n                 total allocation:    1.73GiB\n              total fragmentation:         0B (0.00%)\nPeak buffers:\n\tBuffer 1:\n\t\tSize: 1.73GiB\n\t\tOperator: op_name=\"jit(broadcast_in_dim)/jit(main)/broadcast_in_dim[shape=(1006, 460800) broadcast_dimensions=()]\" source_file=\"/usr/local/lib/python3.10/dist-packages/tensorflow_probability/python/internal/backend/jax/tensor_array_ops.py\" source_line=57\n\t\tXLA Label: broadcast\n\t\tShape: f32[1006,460800]\n\t\t==========================\n\n\tBuffer 2:\n\t\tSize: 4B\n\t\tEntry Parameter Subshape: f32[]\n\t\t==========================\n\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def adaptive_initialize(target_log_prob_fn, init_step_size, num_warmup, warmup_window):\n",
        "    kernel_cold = construct_kernel(target_log_prob_fn = target_log_prob_fn,\n",
        "                                   init_step_size = init_step_size,\n",
        "                                   num_warmup = num_warmup)\n",
        "    kernel_warm = construct_kernel(target_log_prob_fn = target_log_prob_fn,\n",
        "                                   init_step_size = init_step_size,\n",
        "                                   num_warmup = num_warmup)\n",
        "    window_array = jnp.append(jnp.repeat(10, 10),\n",
        "                              jnp.repeat(warmup_window,\n",
        "                                         num_warmup // warmup_window - 1))\n",
        "    nRhat_upper = 1.05\n",
        "\n",
        "    try:\n",
        "      mean_est = target.sample_transformations['identity'].ground_truth_mean\n",
        "    except:\n",
        "      print('no ground truth mean')\n",
        "      mean_est = (result.all_states[num_warmup:, :]).mean(0).mean(0)\n",
        "    try:\n",
        "      var_est = target.sample_transformations['identity'].ground_truth_standard_deviation**2\n",
        "    except:\n",
        "      print('no ground truth std dev')\n",
        "      var_est = ((result.all_states[num_warmup:, :]**2).mean(0).mean(0) -\n",
        "                mean_est**2)\n",
        "\n",
        "    return kernel_cold, kernel_warm, window_array, nRhat_upper, mean_est, var_est"
      ],
      "metadata": {
        "id": "mOOZ-jXjfjYU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This will need to be written in a way such that it can be integrated into the function below\n",
        "def hmc_bootstrap():\n",
        "  return"
      ],
      "metadata": {
        "id": "KWI8Cr0sm-nJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "We will now focus on variance measurement of nested Rhat, with users having the\n",
        "possibility to choose several parameters such as the number of superchains (K),\n",
        "number of markov chains in each group of superchains (M), and number of draws in\n",
        "the sampling phase (N). We will measure this in both a brute force manner, as\n",
        "well as coming up with a notion of bootstrapping. We also can decide to run this\n",
        "variance estimate across all chains sequentially, or in parallel. Having an\n",
        "adaptive warmup length, or a fixed numbers of warmup iterations is also a\n",
        "potential parameter\n",
        "\n",
        "Using an initial seed value of 1\n",
        "\n",
        "I need to think a bit about parallelization as well as bootstrapping\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# There's 8 possibilities here that come from 2^[boostrap, adaptive, parallel]\n",
        "def variance_estimate(target_log_prob_fn, index_param, num_seed = 10, num_warmup = 1000, num_samples = 5,\n",
        "                      num_super_chains = 4, initialize = bn_initialize, num_chains = 128,\n",
        "                      bootstrap = False, adaptive = False, parallel = False,\n",
        "                      warmup_window = 100, initial_seed = 1):\n",
        "\n",
        "  if adaptive:\n",
        "\n",
        "    kernel_cold, kernel_warm, window_array, \\\n",
        "    nRhat_upper, mean_est, var_est = adaptive_initialize(target_log_prob_fn,\n",
        "                                                         init_step_size,\n",
        "                                                         num_warmup,\n",
        "                                                         warmup_window)\n",
        "\n",
        "    if bootstrap:\n",
        "      if parallel:\n",
        "        # Adpative, Bootstrapped, and Parallel\n",
        "\n",
        "        return\n",
        "\n",
        "      else:\n",
        "        # Adaptive, Bootstrapped, and Sequential\n",
        "        return\n",
        "\n",
        "    else:\n",
        "      if parallel:\n",
        "        # Adpative, Brute-Force, and Parallel\n",
        "        return\n",
        "\n",
        "      else:\n",
        "        # Adaptive, Brute-Force, and Sequential\n",
        "        mc_mean_list, warmup_length, squared_error_list, \\\n",
        "        nRhat_list = run_forge_chain(num_seed = num_seed,\n",
        "                                     kernel_cold = kernel_cold,\n",
        "                                     kernel_warm = kernel_warm,\n",
        "                                     initialize = initialize,\n",
        "                                     num_super_chains = num_super_chains,\n",
        "                                     num_warmup = window_array,\n",
        "                                     num_samples = num_samples,\n",
        "                                     target_rhat = nRhat_upper,\n",
        "                                     max_num_steps = window_array.shape[0],\n",
        "                                     index_param = index_param,\n",
        "                                     rank_normalize = False,\n",
        "                                     alpha_quantile = 1.,\n",
        "                                     mean_benchmark = mean_est,\n",
        "                                     var_benchmark = var_est)\n",
        "\n",
        "  else:\n",
        "\n",
        "    kernel = construct_kernel(target_log_prob_fn = target_log_prob_fn,\n",
        "                              init_step_size = init_step_size,\n",
        "                              num_warmup = num_warmup)\n",
        "    if bootstrap:\n",
        "\n",
        "      if parallel:\n",
        "        # Fixed, Bootstrapped, and Parallel\n",
        "        return\n",
        "\n",
        "      else:\n",
        "        # Fixed, Bootstrapped, and Sequential\n",
        "        return\n",
        "\n",
        "    else:\n",
        "      if parallel:\n",
        "        # Fixed, Brute-Force, and Parallel\n",
        "        return\n",
        "\n",
        "      else:\n",
        "        # Fixed, Brute-Force, and Sequential\n",
        "        # Adress apparent discrepancy in definition of total_samples\n",
        "        Rhat_list, nRhat_list, B_list, W_list, mc_mean_list = run_fits(\n",
        "            num_seed = num_seed, total_samples = num_warmup + num_samples + 1,\n",
        "            initialize = initialize, kernel = kernel,\n",
        "            num_super_chains = num_super_chains,\n",
        "            index_param = index_param, num_samples = num_samples,\n",
        "            num_warmup = num_warmup)\n",
        "\n",
        "  return nRhat_list"
      ],
      "metadata": {
        "id": "33hWczNl4Tmj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# After calculating the variance of nRhat across several runs we can create visualization\n",
        "# Must think about what is a helpful type of visualization in this situation\n",
        "\n",
        "estimates = variance_estimate(target_log_prob_fn, index_param)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WFy20rtL5-AE",
        "outputId": "a6ad168c-bd01-4108-fb09-75e7224b5544"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow_probability/substrates/jax/mcmc/sample.py:339: UserWarning: Tracing all kernel results by default is deprecated. Set the `trace_fn` argument to None (the future default value) or an explicit callback that traces the values you are interested in.\n",
            "  warnings.warn('Tracing all kernel results by default is deprecated. Set '\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow_probability/substrates/jax/mcmc/sample.py:339: UserWarning: Tracing all kernel results by default is deprecated. Set the `trace_fn` argument to None (the future default value) or an explicit callback that traces the values you are interested in.\n",
            "  warnings.warn('Tracing all kernel results by default is deprecated. Set '\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow_probability/substrates/jax/mcmc/sample.py:339: UserWarning: Tracing all kernel results by default is deprecated. Set the `trace_fn` argument to None (the future default value) or an explicit callback that traces the values you are interested in.\n",
            "  warnings.warn('Tracing all kernel results by default is deprecated. Set '\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow_probability/substrates/jax/mcmc/sample.py:339: UserWarning: Tracing all kernel results by default is deprecated. Set the `trace_fn` argument to None (the future default value) or an explicit callback that traces the values you are interested in.\n",
            "  warnings.warn('Tracing all kernel results by default is deprecated. Set '\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow_probability/substrates/jax/mcmc/sample.py:339: UserWarning: Tracing all kernel results by default is deprecated. Set the `trace_fn` argument to None (the future default value) or an explicit callback that traces the values you are interested in.\n",
            "  warnings.warn('Tracing all kernel results by default is deprecated. Set '\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow_probability/substrates/jax/mcmc/sample.py:339: UserWarning: Tracing all kernel results by default is deprecated. Set the `trace_fn` argument to None (the future default value) or an explicit callback that traces the values you are interested in.\n",
            "  warnings.warn('Tracing all kernel results by default is deprecated. Set '\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow_probability/substrates/jax/mcmc/sample.py:339: UserWarning: Tracing all kernel results by default is deprecated. Set the `trace_fn` argument to None (the future default value) or an explicit callback that traces the values you are interested in.\n",
            "  warnings.warn('Tracing all kernel results by default is deprecated. Set '\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow_probability/substrates/jax/mcmc/sample.py:339: UserWarning: Tracing all kernel results by default is deprecated. Set the `trace_fn` argument to None (the future default value) or an explicit callback that traces the values you are interested in.\n",
            "  warnings.warn('Tracing all kernel results by default is deprecated. Set '\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow_probability/substrates/jax/mcmc/sample.py:339: UserWarning: Tracing all kernel results by default is deprecated. Set the `trace_fn` argument to None (the future default value) or an explicit callback that traces the values you are interested in.\n",
            "  warnings.warn('Tracing all kernel results by default is deprecated. Set '\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow_probability/substrates/jax/mcmc/sample.py:339: UserWarning: Tracing all kernel results by default is deprecated. Set the `trace_fn` argument to None (the future default value) or an explicit callback that traces the values you are interested in.\n",
            "  warnings.warn('Tracing all kernel results by default is deprecated. Set '\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "es"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3zrYb24nqz43",
        "outputId": "23c0aa6d-d0f2-43b7-ade9-366d507f0ca1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Array([[1.0007871, 1.0007992],\n",
              "       [1.0009911, 1.0010496],\n",
              "       [1.0003695, 1.0017493],\n",
              "       [1.0003909, 1.0003959],\n",
              "       [1.0007714, 1.0024724],\n",
              "       [1.0007972, 1.0030594],\n",
              "       [1.0016471, 1.0036765],\n",
              "       [1.000586 , 1.0000635],\n",
              "       [1.0010842, 1.0008926],\n",
              "       [1.0008079, 1.0006552]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    }
  ]
}