{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPfC+C6y4RjNg03wLw5LuFA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/emmanuelmokel/PPL-practice/blob/main/NestedRHat_TFP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#tensorflow.__version__\n",
        "!pip show tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rk-kAi6cM7lc",
        "outputId": "38385ffb-5636-42fb-99c1-d9689b096b2d"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: tensorflow\n",
            "Version: 2.12.0\n",
            "Summary: TensorFlow is an open source machine learning framework for everyone.\n",
            "Home-page: https://www.tensorflow.org/\n",
            "Author: Google Inc.\n",
            "Author-email: packages@tensorflow.org\n",
            "License: Apache 2.0\n",
            "Location: /usr/local/lib/python3.10/dist-packages\n",
            "Requires: absl-py, astunparse, flatbuffers, gast, google-pasta, grpcio, h5py, jax, keras, libclang, numpy, opt-einsum, packaging, protobuf, setuptools, six, tensorboard, tensorflow-estimator, tensorflow-io-gcs-filesystem, termcolor, typing-extensions, wrapt\n",
            "Required-by: dopamine-rl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install -U \"numpy~=1.23\"\n",
        "!rm -Rf probability\n",
        "!rm -Rf fun_mc\n",
        "!rm -Rf inference_gym\n",
        "!git clone https://github.com/tensorflow/probability.git\n",
        "!mv probability/spinoffs/fun_mc/fun_mc .\n",
        "!mv probability/spinoffs/inference_gym/inference_gym .\n",
        "#!pip install tf-nightly tfp-nightly jax jaxlib\n",
        "!pip install tensorflow==2.13.0\n",
        "!pip install tfp-nightly jax jaxlib\n",
        "\n",
        "!pip install immutabledict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yVfP9g3Tdncu",
        "outputId": "2cd80134-74bb-481c-929e-6777b6127fd8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'probability'...\n",
            "remote: Enumerating objects: 100124, done.\u001b[K\n",
            "remote: Counting objects: 100% (4950/4950), done.\u001b[K\n",
            "remote: Compressing objects: 100% (183/183), done.\u001b[K\n",
            "remote: Total 100124 (delta 4807), reused 4819 (delta 4767), pack-reused 95174\u001b[K\n",
            "Receiving objects: 100% (100124/100124), 137.03 MiB | 17.18 MiB/s, done.\n",
            "Resolving deltas: 100% (81929/81929), done.\n",
            "Collecting tensorflow==2.13.0\n",
            "  Downloading tensorflow-2.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (524.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m524.1/524.1 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.1.21 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (23.5.26)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (1.56.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (3.8.0)\n",
            "Collecting keras<2.14,>=2.13.1 (from tensorflow==2.13.0)\n",
            "  Downloading keras-2.13.1-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m55.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (16.0.0)\n",
            "Requirement already satisfied: numpy<=1.24.3,>=1.22 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (1.22.4)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (23.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (1.16.0)\n",
            "Collecting tensorboard<2.14,>=2.13 (from tensorflow==2.13.0)\n",
            "  Downloading tensorboard-2.13.0-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m62.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow-estimator<2.14,>=2.13.0 (from tensorflow==2.13.0)\n",
            "  Downloading tensorflow_estimator-2.13.0-py2.py3-none-any.whl (440 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.8/440.8 kB\u001b[0m \u001b[31m31.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (2.3.0)\n",
            "Collecting typing-extensions<4.6.0,>=3.6.6 (from tensorflow==2.13.0)\n",
            "  Downloading typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (0.32.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.13.0) (0.40.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.0) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.0) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.0) (3.4.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.0) (2.27.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.0) (0.7.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.0) (2.3.6)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (5.3.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (1.3.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (3.2.2)\n",
            "Installing collected packages: typing-extensions, tensorflow-estimator, keras, tensorboard, tensorflow\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.6.3\n",
            "    Uninstalling typing_extensions-4.6.3:\n",
            "      Successfully uninstalled typing_extensions-4.6.3\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.12.0\n",
            "    Uninstalling tensorflow-estimator-2.12.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.12.0\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.12.0\n",
            "    Uninstalling keras-2.12.0:\n",
            "      Successfully uninstalled keras-2.12.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.12.3\n",
            "    Uninstalling tensorboard-2.12.3:\n",
            "      Successfully uninstalled tensorboard-2.12.3\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.12.0\n",
            "    Uninstalling tensorflow-2.12.0:\n",
            "      Successfully uninstalled tensorflow-2.12.0\n",
            "Successfully installed keras-2.13.1 tensorboard-2.13.0 tensorflow-2.13.0 tensorflow-estimator-2.13.0 typing-extensions-4.5.0\n",
            "Collecting tfp-nightly\n",
            "  Downloading tfp_nightly-0.20.0.dev20230707-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jax in /usr/local/lib/python3.10/dist-packages (0.4.10)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.10/dist-packages (0.4.10+cuda11.cudnn86)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from tfp-nightly) (1.4.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from tfp-nightly) (1.16.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.10/dist-packages (from tfp-nightly) (1.22.4)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from tfp-nightly) (4.4.2)\n",
            "Requirement already satisfied: cloudpickle>=1.3 in /usr/local/lib/python3.10/dist-packages (from tfp-nightly) (2.2.1)\n",
            "Requirement already satisfied: gast>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from tfp-nightly) (0.4.0)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from tfp-nightly) (0.1.8)\n",
            "Requirement already satisfied: typing-extensions<4.6.0 in /usr/local/lib/python3.10/dist-packages (from tfp-nightly) (4.5.0)\n",
            "Requirement already satisfied: ml-dtypes>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from jax) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from jax) (3.3.0)\n",
            "Requirement already satisfied: scipy>=1.7 in /usr/local/lib/python3.10/dist-packages (from jax) (1.10.1)\n",
            "Installing collected packages: tfp-nightly\n",
            "Successfully installed tfp-nightly-0.20.0.dev20230707\n",
            "Collecting immutabledict\n",
            "  Downloading immutabledict-2.2.5-py3-none-any.whl (4.1 kB)\n",
            "Installing collected packages: immutabledict\n",
            "Successfully installed immutabledict-2.2.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Er7DJXS3Ng3u"
      },
      "outputs": [],
      "source": [
        "from matplotlib.pyplot import *\n",
        "\n",
        "import jax\n",
        "from jax import random\n",
        "from jax import numpy as jnp\n",
        "\n",
        "\n",
        "# INFERENCE GYM ISN'T WORKING RIGHT NOW DUE TO TF UPDATES... TRY LATER\n",
        "#!pip install _U inference_gym tfds_nightly\n",
        "#import inference_gym.using_jax as gym\n",
        "from inference_gym import using_jax as gym\n",
        "\n",
        "#from tensorflow_probability.spinoffs import using_jax as fun_mcmc\n",
        "#from fun_mc import using_jax as fun_mcmc\n",
        "\n",
        "#from tensorflow_probability.python.internal import prefer_static as ps\n",
        "#from tensorflow_probability.python.internal import unnest\n",
        "\n",
        "import tensorflow_probability as _tfp\n",
        "tfp = _tfp.substrates.jax\n",
        "tfd = tfp.distributions\n",
        "tfb = tfp.bijectors\n",
        "\n",
        "tfp_np = _tfp.substrates.numpy\n",
        "tfd_np = tfp_np.distributions\n",
        "\n",
        "#import arviz as az\n",
        "from tensorflow_probability.python.internal.unnest import get_innermost"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Working with the 'Banana' Posterior Target Density\n",
        "\n",
        "target = gym.targets.VectorModel(gym.targets.Banana(),\n",
        "                                 flatten_sample_transformations = True)\n",
        "num_dimensions = target.event_shape[0]\n",
        "# Is the heuristic for the initial value of \\epsilon given in the paper used in practice?\n",
        "init_step_size = 1.\n",
        "\n",
        "#target = tfp.distributions.MultivariateNormalDiag()\n",
        "\n",
        "def target_log_prob_fn(x):\n",
        "   y = target.default_event_space_bijector(x)\n",
        "   fldj = target.default_event_space_bijector.forward_log_det_jacobian(x)\n",
        "   return target.unnormalized_log_prob(y) + fldj\n",
        "   #return x.log_prob\n",
        "\n",
        "offset = 2\n",
        "def bn_initialize(shape, key = random.PRNGKey(3727709)):\n",
        "  return 10 * random.normal(key, shape + (num_dimensions,)) + offset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J_4vsEveoV54",
        "outputId": "bbd25fec-3955-4387-ba53-a0eaa9d8615d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:jax._src.xla_bridge:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow_probability/python/internal/backend/jax/ops.py:285: UserWarning: Explicitly requested dtype float64 requested in astype is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
            "  return arr.astype(dtype)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Running default HMC as written in Radford Neal's paper\n",
        "\n",
        "num_chains = 128\n",
        "num_super_chains = 4\n",
        "num_warmup, num_samples = 10, 10\n",
        "# 1000, 100\n",
        "total_samples = num_warmup + num_samples\n",
        "\n",
        "kernel = tfp.mcmc.HamiltonianMonteCarlo(target_log_prob_fn, init_step_size, 1)\n",
        "kernel = tfp.experimental.mcmc.GradientBasedTrajectoryLengthAdaptation(kernel, num_warmup)\n",
        "kernel = tfp.mcmc.DualAveragingStepSizeAdaptation(kernel, num_warmup,\n",
        "                                                  target_accept_prob = 0.75,\n",
        "                                                  reduce_fn = tfp.math.reduce_log_harmonic_mean_exp)\n",
        "\n",
        "# Initializing each chain (in a super chain) at the same location\n",
        "initial_state = bn_initialize((num_super_chains,))\n",
        "initial_state = jnp.repeat(initial_state, num_chains // num_super_chains, axis = 0)"
      ],
      "metadata": {
        "id": "FlX9TePtumEF"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = tfp.mcmc.sample_chain(total_samples, initial_state,\n",
        "                               kernel = kernel, seed = random.PRNGKey(1954),\n",
        "                               trace_fn = None)"
      ],
      "metadata": {
        "id": "w5p4ybjEvuZs"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "psbsofolgqvX",
        "outputId": "caa6a1d6-20a9-4e71-e85c-ce4103827364"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20, 128, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "tf.executing_eagerly()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "id": "nwoyTCcDv4nT",
        "outputId": "f33571b7-0615-4d90-8217-59d75c0ed3b7"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-59fb998e27f7>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_typing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodule_util\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_module_util\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlazy_loader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLazyLoader\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_LazyLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_pywrap_tensorflow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meager\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;31m# pylint: enable=wildcard-import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpywrap_tf_session\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meager\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meager\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mexecute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meager\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mexecutor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meager\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmonitoring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpywrap_tfe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meager\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensor_conversion_registry\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensor_shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/dtypes.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_dtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtypes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdoc_typealias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_pywrap_custom_casts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_pywrap_float8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_export\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtf_export\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: /usr/local/lib/python3.10/dist-packages/tensorflow/python/lib/core/_pywrap_custom_casts.so: undefined symbol: _ZN3tsl19RegisterCustomCastsEv, version tensorflow",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test = jnp.arange(8)\n",
        "test = test.reshape((2, 2, 2))\n",
        "test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ai8z6f4zgpSf",
        "outputId": "376b3c65-9292-4818-ab27-1b111ccc9e12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Array([[[0, 1],\n",
              "        [2, 3]],\n",
              "\n",
              "       [[4, 5],\n",
              "        [6, 7]]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(result.shape)\n",
        "result[:, :, 0].reshape(20, -1, 32, 1).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dca2UDSejPhB",
        "outputId": "fb70123f-6d53-4485-8bd8-06134e804a3f"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(20, 128, 2)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20, 4, 32, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#jnp.mean(test, axis = (0, 3))"
      ],
      "metadata": {
        "id": "STDX7D6jgwBt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define nested Rhat for one parameter.\n",
        "# This assumes the indexed parameter is a scalar, hence the result_state\n",
        "# tensor needs to be formatted accordingly.\n",
        "# TODO: deprecate state_is_list argument\n",
        "def nested_rhat_1dim(result_state, num_super_chains, index_param,\n",
        "                     num_samples, warmup_length = 0,\n",
        "                     rank_normalize = False):\n",
        "\n",
        "  state_param = result_state[warmup_length:(warmup_length + num_samples),\n",
        "                             :, index_param]\n",
        "\n",
        "  num_samples = state_param.shape[0]\n",
        "  num_chains = state_param.shape[1]\n",
        "  num_sub_chains = num_chains // num_super_chains\n",
        "  total_samples = num_samples * num_chains\n",
        "\n",
        "  if (rank_normalize):\n",
        "    state_param_flat = jnp.reshape(state_param, (total_samples, ))\n",
        "    temp = state_param_flat.argsort()\n",
        "    ranks = temp.argsort() + 1\n",
        "    z = norm.ppf((ranks - 3 / 8) / (total_samples + 1 / 4))\n",
        "    # This is misspelled in the original code\n",
        "    state_param = jnp.reshape(z, (num_samples, num_chains))\n",
        "\n",
        "  # The below operations work with the assumption that each of the superchains will have the same size\n",
        "  # Reshaping the array to account for that may not work in this case where M will change\n",
        "\n",
        "  # Reshaping to account for superchains\n",
        "  state_param = state_param.reshape(num_samples, -1, num_sub_chains, 1)\n",
        "\n",
        "  # Equation 14 in the paper\n",
        "  mean_chain = jnp.mean(state_param, axis = (0, 3))\n",
        "\n",
        "  # Piecewise equations in paper\n",
        "  between_chain_var = jnp.var(mean_chain, axis = 1, ddof = 1)\n",
        "  if (num_samples == 1):\n",
        "    mean_within_chain_var = 0\n",
        "  else:\n",
        "    within_chain_var = jnp.var(state_param, axis = (0, 3), ddof = 1)\n",
        "    mean_within_chain_var = jnp.mean(within_chain_var, axis = 1)\n",
        "\n",
        "  # Equation 17 in the paper\n",
        "  total_chain_var = between_chain_var + mean_within_chain_var\n",
        "\n",
        "  # Equation 16 in the paper\n",
        "  mean_super_chain = jnp.mean(state_param, axis = (0, 2, 3))\n",
        "  between_super_chain_var = jnp.var(mean_super_chain, ddof = 1)\n",
        "\n",
        "  # Equation 18 in the paper\n",
        "  return jnp.sqrt(1 + between_super_chain_var / jnp.mean(total_chain_var)),\\\n",
        "    between_super_chain_var, jnp.mean(total_chain_var)\n",
        "\n",
        "\n",
        "def nested_rhat(result_state, num_super_chains, index_param,\n",
        "                num_samples, warmup_length = 0, rank_normalize = False):\n",
        "  nRhat = jnp.array([])\n",
        "  B = jnp.array([])\n",
        "  W = jnp.array([])\n",
        "  for i in range(0, index_param.shape[0]):\n",
        "    nRhat_local, B_local, W_local = nested_rhat_1dim(result_state,\n",
        "                    num_super_chains, index_param[i], num_samples,\n",
        "                    warmup_length, rank_normalize)\n",
        "\n",
        "    nRhat = jnp.append(nRhat, nRhat_local)\n",
        "    B = jnp.append(B, B_local)\n",
        "    W = jnp.append(W, W_local)\n",
        "\n",
        "  return nRhat, B, W"
      ],
      "metadata": {
        "id": "UdjThIa-lxJT"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using ChEES-HMC in order to get the most out of a GPU"
      ],
      "metadata": {
        "id": "Yog1nM3m2_Bd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select HMC Variant from options chees, snaper, or malt\n",
        "\n",
        "def construct_kernel(target_log_prob_fn, init_step_size, num_warmup, transition = 'chees'):\n",
        "  if transition == 'chees':\n",
        "    # Using gradient-based trajectory length adaptation and dual averaging defines ChEES HMC\n",
        "    kernel = tfp.mcmc.HamiltonianMonteCarlo(target_log_prob_fn, init_step_size, 1)\n",
        "    kernel = tfp.experimental.mcmc.GradientBasedTrajectoryLengthAdaptation(kernel, num_warmup)\n",
        "    kernel = tfp.mcmc.DualAveragingStepSizeAdaptation(\n",
        "        kernel, num_warmup, target_accept_prob = 0.75,\n",
        "        reduce_fn = tfp.math.reduce_log_harmonic_mean_exp)\n",
        "\n",
        "  elif transition == 'snaper':\n",
        "    # TO BE IMPLEMENTED\n",
        "    kernel = 'snaper'\n",
        "\n",
        "  elif transition == 'malt':\n",
        "    # TO BE IMPLEMENTED\n",
        "    kernel = 'malt'\n",
        "\n",
        "  else:\n",
        "    raise Exception(\"Not a valid transition kernel. Try one of ['chees', 'snaper', 'malt']\")\n",
        "\n",
        "  return kernel"
      ],
      "metadata": {
        "id": "l4mElY4y3Uyu"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_fits(num_seed, total_samples, initialize, kernel, num_super_chains,\n",
        "             index_param, num_samples, num_warmup, rank_normalize = False):\n",
        "\n",
        "  num_parameters = index_param.shape[0]\n",
        "\n",
        "  Rhat_list = jnp.zeros((num_seed, num_parameters))\n",
        "  nRhat_list = jnp.zeros((num_seed, num_parameters))\n",
        "  B_list = jnp.zeros((num_seed, num_parameters))\n",
        "  W_list = jnp.zeros((num_seed, num_parameters))\n",
        "  mc_mean_list = jnp.zeros((num_seed, num_parameters))\n",
        "\n",
        "  i = 0\n",
        "  for seed in jax.random.split(jax.random.PRNGKey(1), num_seed):\n",
        "    initial_state = initialize((num_super_chains,), key = seed + 1954)\n",
        "\n",
        "    initial_state = jnp.repeat(initial_state, num_chains // num_super_chains,\n",
        "                              axis = 0)\n",
        "\n",
        "    result = tfp.mcmc.sample_chain(total_samples, initial_state, kernel = kernel, seed = seed, trace_fn = None)\n",
        "\n",
        "    # Implementation of original R-Hat from Gelman and Rubin (1992)\n",
        "    Rhat_list = Rhat_list.at[i, :].set(tfp.mcmc.potential_scale_reduction(result[num_warmup:(num_warmup + num_samples), :, index_param]))\n",
        "\n",
        "    nRhat_local, B_local, W_local = nested_rhat(result,\n",
        "                                                num_super_chains = num_super_chains,\n",
        "                                                index_param = index_param,\n",
        "                                                num_samples = num_samples,\n",
        "                                                warmup_length = num_warmup,\n",
        "                                                rank_normalize = rank_normalize)\n",
        "    nRhat_list = nRhat_list.at[i, :].set(nRhat_local)\n",
        "    B_list = B_list.at[i, :].set(B_local)\n",
        "    W_list = W_list.at[i, :].set(W_local)\n",
        "\n",
        "    mc_mean_list = mc_mean_list.at[i, :].set(jnp.mean(result[num_warmup + 1, :, index_param], axis = 1))\n",
        "    i += 1\n",
        "\n",
        "  return Rhat_list, nRhat_list, B_list, W_list, mc_mean_list\n"
      ],
      "metadata": {
        "id": "yyDBbuoR3Zq-"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adaptive warmup scheme to produce MCMC samples\n",
        "def forge_chain(kernel_cold, kernel_warm, initial_state, num_super_chains,\n",
        "                num_warmup_array, num_samples, target_rhat, max_num_steps,\n",
        "                index_param, seed, num_nRhat_comp = 1, rank_normalize = False,\n",
        "                alpha_quantile = 1, mean_benchmark = None, var_benchmark = None):\n",
        "  warmup_is_acceptable = False\n",
        "  window_iteration = 0\n",
        "  current_state = initial_state\n",
        "  kernel_args = None\n",
        "\n",
        "  squared_err_list = jnp.array([])\n",
        "  nrhat_list = jnp.array([])\n",
        "\n",
        "  while(not warmup_is_acceptable and window_iteration < max_num_steps):\n",
        "\n",
        "    # Runs MCMC with a warmup window\n",
        "    result_cold, trace, kernel_args = tfp.mcmc.sample_chain(\n",
        "        num_results = num_warmup_array[window_iteration],\n",
        "        current_state = current_state,\n",
        "        kernel = kernel_cold,\n",
        "        previous_kernel_results = kernel_args,\n",
        "        trace_fn = lambda _, pkr: unnest.get_innermost(pkr, 'step_size'),\n",
        "        return_final_kernel_results = True,\n",
        "        seed = seed + window_iteration)\n",
        "\n",
        "    current_state = result_cold[-1]\n",
        "\n",
        "    # Generate candidate samples\n",
        "    result_warm, trace = tfp.mcmc.sample_chain(\n",
        "        num_results = num_samples*num_nRhat_comp,\n",
        "        current_state = current_state,\n",
        "        kernel = kernel_warm,\n",
        "        trace_fn = lambda _, pkr: unnest.get_innermost(pkr, 'step_size'),\n",
        "        previous_kernel_results = kernel_args,\n",
        "\n",
        "        # Why are we just adding numbers to seeds like this? I get it is to randomize but is there a more principled way?\n",
        "        seed = seed + 999999)\n",
        "\n",
        "    # Check if candidate samples are acceptable\n",
        "    nRhat = jnp.zeros((index_param.shape[0], num_nRhat_comp))\n",
        "    for i in range(0, num_nRhat_comp):\n",
        "      nR, _B, _W = nested_rhat(result_warm[i:((i+1)*num_samples)],\n",
        "                                        num_super_chains = num_super_chains,\n",
        "                                        index_param = index_param,\n",
        "                                        num_samples = num_samples,\n",
        "                                        rank_normalize = rank_normalize)\n",
        "      nRhat = nRhat.at[:, i].set(nR)\n",
        "\n",
        "    nRhat_quantile = jnp.quantile(jnp.mean(nRhat, axis = 1), alpha_quantile,\n",
        "                                 interpolation = \"nearest\")\n",
        "    print(\"nRhat_quantile: (\", alpha_quantile, \")\", nRhat_quantile)\n",
        "\n",
        "    if mean_benchmark is not None:\n",
        "      mc_mean = jnp.mean(result_warm[0, :, index_param], axis = 1)\n",
        "      squared_err = jnp.square(mc_mean - mean_benchmark[index_param])\\\n",
        "      / var_benchmark[index_param]\n",
        "\n",
        "      squared_err_list = jnp.append(squared_err_list, squared_err)\n",
        "      nrhat_list = jnp.append(nrhat_list, jnp.mean(nRhat, axis = 1))\n",
        "\n",
        "    if (nRhat_quantile < target_rhat): warmup_is_acceptable = True\n",
        "\n",
        "    window_iteration += 1\n",
        "\n",
        "  return result_warm, window_iteration, squared_err_list, nrhat_list"
      ],
      "metadata": {
        "id": "RggIF9Hqmxh1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_forge_chain(num_seed, kernel_cold, kernel_warm, initialize, num_super_chains,\n",
        "                    num_warmup, num_samples, target_rhat, max_num_steps,\n",
        "                    index_param, num_nRhat_comp = 1, rank_normalize = False,\n",
        "                    alpha_quantile = 1, mean_benchmark = None,\n",
        "                    var_benchmark = None, initial_seed = 1):\n",
        "  mc_mean_list = jnp.zeros((num_seed, index_param.shape[0]))\n",
        "  warmup_length = jnp.zeros(num_seed)\n",
        "\n",
        "  squared_err_list_all = jnp.array([])\n",
        "  nrhat_list_all = jnp.array([])\n",
        "\n",
        "  i = 0\n",
        "  for seed in jax.random.split(jax.random.PRNGKey(initial_seed), num_seed):\n",
        "    print(\"NEW SEED\")\n",
        "    initial_state = initialize((num_super_chains,), key = seed + 1954)\n",
        "    initial_state = jnp.repeat(initial_state, num_chains // num_super_chains,\n",
        "                              axis = 0)\n",
        "\n",
        "    result, window_iteration, \\\n",
        "    squared_err_list, nrhat_list = forge_chain(kernel_cold, kernel_warm,\n",
        "                                               initial_state, num_super_chains,\n",
        "                                               num_warmup, num_samples,\n",
        "                                               target_rhat, max_num_steps,\n",
        "                                               index_param, seed,\n",
        "                                               num_nRhat_comp, rank_normalize,\n",
        "                                               alpha_quantile, mean_benchmark,\n",
        "                                               var_benchmark)\n",
        "\n",
        "    warmup_length = warmup_length.at[i].set(sum(num_warmup[:window_iteration]))\n",
        "    mc_mean_list = mc_mean_list.at[i, :].set(jnp.mean(result[0, :, index_param],\n",
        "                                 axis = 1))\n",
        "\n",
        "    squared_err_list_all = jnp.append(squared_err_list_all, squared_err_list)\n",
        "    nrhat_list_all = jnp.append(nrhat_list_all, nrhat_list)\n",
        "\n",
        "    i += 1\n",
        "  return mc_mean_list, warmup_length, squared_err_list_all, nrhat_list_all"
      ],
      "metadata": {
        "id": "48aMam844B1f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#num_warmup, num_samples = 1000, 100\n",
        "total_samples = num_warmup + num_samples + 1\n",
        "\n",
        "kernel = construct_kernel(target_log_prob_fn = target_log_prob_fn,\n",
        "                          init_step_size = init_step_size, num_warmup = num_warmup,\n",
        "                          transition = 'chees')\n",
        "index_param = jnp.array([0, 1])\n",
        "num_seed = 30\n",
        "rank_normalize = False"
      ],
      "metadata": {
        "id": "T25EaHnhZfmt"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Rhat_list, nRhat_list, B_list, W_list, mc_mean_list = run_fits(\n",
        "           num_seed = num_seed, total_samples = total_samples,\n",
        "           initialize = bn_initialize, kernel = kernel,\n",
        "           num_super_chains = K, index_param = index_param,\n",
        "           num_samples = num_samples, num_warmup = num_warmup,\n",
        "           rank_normalize = rank_normalize)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6DS_pAKjaNEa",
        "outputId": "c64e7ecd-154e-4df0-f1bb-d3b79a80c469"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow_probability/substrates/jax/mcmc/sample.py:339: UserWarning: Tracing all kernel results by default is deprecated. Set the `trace_fn` argument to None (the future default value) or an explicit callback that traces the values you are interested in.\n",
            "  warnings.warn('Tracing all kernel results by default is deprecated. Set '\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow_probability/substrates/jax/mcmc/sample.py:339: UserWarning: Tracing all kernel results by default is deprecated. Set the `trace_fn` argument to None (the future default value) or an explicit callback that traces the values you are interested in.\n",
            "  warnings.warn('Tracing all kernel results by default is deprecated. Set '\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow_probability/substrates/jax/mcmc/sample.py:339: UserWarning: Tracing all kernel results by default is deprecated. Set the `trace_fn` argument to None (the future default value) or an explicit callback that traces the values you are interested in.\n",
            "  warnings.warn('Tracing all kernel results by default is deprecated. Set '\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow_probability/substrates/jax/mcmc/sample.py:339: UserWarning: Tracing all kernel results by default is deprecated. Set the `trace_fn` argument to None (the future default value) or an explicit callback that traces the values you are interested in.\n",
            "  warnings.warn('Tracing all kernel results by default is deprecated. Set '\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow_probability/substrates/jax/mcmc/sample.py:339: UserWarning: Tracing all kernel results by default is deprecated. Set the `trace_fn` argument to None (the future default value) or an explicit callback that traces the values you are interested in.\n",
            "  warnings.warn('Tracing all kernel results by default is deprecated. Set '\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow_probability/substrates/jax/mcmc/sample.py:339: UserWarning: Tracing all kernel results by default is deprecated. Set the `trace_fn` argument to None (the future default value) or an explicit callback that traces the values you are interested in.\n",
            "  warnings.warn('Tracing all kernel results by default is deprecated. Set '\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow_probability/substrates/jax/mcmc/sample.py:339: UserWarning: Tracing all kernel results by default is deprecated. Set the `trace_fn` argument to None (the future default value) or an explicit callback that traces the values you are interested in.\n",
            "  warnings.warn('Tracing all kernel results by default is deprecated. Set '\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow_probability/substrates/jax/mcmc/sample.py:339: UserWarning: Tracing all kernel results by default is deprecated. Set the `trace_fn` argument to None (the future default value) or an explicit callback that traces the values you are interested in.\n",
            "  warnings.warn('Tracing all kernel results by default is deprecated. Set '\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow_probability/substrates/jax/mcmc/sample.py:339: UserWarning: Tracing all kernel results by default is deprecated. Set the `trace_fn` argument to None (the future default value) or an explicit callback that traces the values you are interested in.\n",
            "  warnings.warn('Tracing all kernel results by default is deprecated. Set '\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow_probability/substrates/jax/mcmc/sample.py:339: UserWarning: Tracing all kernel results by default is deprecated. Set the `trace_fn` argument to None (the future default value) or an explicit callback that traces the values you are interested in.\n",
            "  warnings.warn('Tracing all kernel results by default is deprecated. Set '\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow_probability/substrates/jax/mcmc/sample.py:339: UserWarning: Tracing all kernel results by default is deprecated. Set the `trace_fn` argument to None (the future default value) or an explicit callback that traces the values you are interested in.\n",
            "  warnings.warn('Tracing all kernel results by default is deprecated. Set '\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow_probability/substrates/jax/mcmc/sample.py:339: UserWarning: Tracing all kernel results by default is deprecated. Set the `trace_fn` argument to None (the future default value) or an explicit callback that traces the values you are interested in.\n",
            "  warnings.warn('Tracing all kernel results by default is deprecated. Set '\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow_probability/substrates/jax/mcmc/sample.py:339: UserWarning: Tracing all kernel results by default is deprecated. Set the `trace_fn` argument to None (the future default value) or an explicit callback that traces the values you are interested in.\n",
            "  warnings.warn('Tracing all kernel results by default is deprecated. Set '\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow_probability/substrates/jax/mcmc/sample.py:339: UserWarning: Tracing all kernel results by default is deprecated. Set the `trace_fn` argument to None (the future default value) or an explicit callback that traces the values you are interested in.\n",
            "  warnings.warn('Tracing all kernel results by default is deprecated. Set '\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow_probability/substrates/jax/mcmc/sample.py:339: UserWarning: Tracing all kernel results by default is deprecated. Set the `trace_fn` argument to None (the future default value) or an explicit callback that traces the values you are interested in.\n",
            "  warnings.warn('Tracing all kernel results by default is deprecated. Set '\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow_probability/substrates/jax/mcmc/sample.py:339: UserWarning: Tracing all kernel results by default is deprecated. Set the `trace_fn` argument to None (the future default value) or an explicit callback that traces the values you are interested in.\n",
            "  warnings.warn('Tracing all kernel results by default is deprecated. Set '\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow_probability/substrates/jax/mcmc/sample.py:339: UserWarning: Tracing all kernel results by default is deprecated. Set the `trace_fn` argument to None (the future default value) or an explicit callback that traces the values you are interested in.\n",
            "  warnings.warn('Tracing all kernel results by default is deprecated. Set '\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow_probability/substrates/jax/mcmc/sample.py:339: UserWarning: Tracing all kernel results by default is deprecated. Set the `trace_fn` argument to None (the future default value) or an explicit callback that traces the values you are interested in.\n",
            "  warnings.warn('Tracing all kernel results by default is deprecated. Set '\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow_probability/substrates/jax/mcmc/sample.py:339: UserWarning: Tracing all kernel results by default is deprecated. Set the `trace_fn` argument to None (the future default value) or an explicit callback that traces the values you are interested in.\n",
            "  warnings.warn('Tracing all kernel results by default is deprecated. Set '\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow_probability/substrates/jax/mcmc/sample.py:339: UserWarning: Tracing all kernel results by default is deprecated. Set the `trace_fn` argument to None (the future default value) or an explicit callback that traces the values you are interested in.\n",
            "  warnings.warn('Tracing all kernel results by default is deprecated. Set '\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow_probability/substrates/jax/mcmc/sample.py:339: UserWarning: Tracing all kernel results by default is deprecated. Set the `trace_fn` argument to None (the future default value) or an explicit callback that traces the values you are interested in.\n",
            "  warnings.warn('Tracing all kernel results by default is deprecated. Set '\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow_probability/substrates/jax/mcmc/sample.py:339: UserWarning: Tracing all kernel results by default is deprecated. Set the `trace_fn` argument to None (the future default value) or an explicit callback that traces the values you are interested in.\n",
            "  warnings.warn('Tracing all kernel results by default is deprecated. Set '\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow_probability/substrates/jax/mcmc/sample.py:339: UserWarning: Tracing all kernel results by default is deprecated. Set the `trace_fn` argument to None (the future default value) or an explicit callback that traces the values you are interested in.\n",
            "  warnings.warn('Tracing all kernel results by default is deprecated. Set '\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow_probability/substrates/jax/mcmc/sample.py:339: UserWarning: Tracing all kernel results by default is deprecated. Set the `trace_fn` argument to None (the future default value) or an explicit callback that traces the values you are interested in.\n",
            "  warnings.warn('Tracing all kernel results by default is deprecated. Set '\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow_probability/substrates/jax/mcmc/sample.py:339: UserWarning: Tracing all kernel results by default is deprecated. Set the `trace_fn` argument to None (the future default value) or an explicit callback that traces the values you are interested in.\n",
            "  warnings.warn('Tracing all kernel results by default is deprecated. Set '\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow_probability/substrates/jax/mcmc/sample.py:339: UserWarning: Tracing all kernel results by default is deprecated. Set the `trace_fn` argument to None (the future default value) or an explicit callback that traces the values you are interested in.\n",
            "  warnings.warn('Tracing all kernel results by default is deprecated. Set '\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow_probability/substrates/jax/mcmc/sample.py:339: UserWarning: Tracing all kernel results by default is deprecated. Set the `trace_fn` argument to None (the future default value) or an explicit callback that traces the values you are interested in.\n",
            "  warnings.warn('Tracing all kernel results by default is deprecated. Set '\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow_probability/substrates/jax/mcmc/sample.py:339: UserWarning: Tracing all kernel results by default is deprecated. Set the `trace_fn` argument to None (the future default value) or an explicit callback that traces the values you are interested in.\n",
            "  warnings.warn('Tracing all kernel results by default is deprecated. Set '\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow_probability/substrates/jax/mcmc/sample.py:339: UserWarning: Tracing all kernel results by default is deprecated. Set the `trace_fn` argument to None (the future default value) or an explicit callback that traces the values you are interested in.\n",
            "  warnings.warn('Tracing all kernel results by default is deprecated. Set '\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow_probability/substrates/jax/mcmc/sample.py:339: UserWarning: Tracing all kernel results by default is deprecated. Set the `trace_fn` argument to None (the future default value) or an explicit callback that traces the values you are interested in.\n",
            "  warnings.warn('Tracing all kernel results by default is deprecated. Set '\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Parellelizing the calculations of nRhat instead of sequential running\n",
        "# This involves getting rid of the loop inside of the code for the regular run_fits(...)\n",
        "# Does this change how the seeds are calculated at all?\n",
        "# Removing the num_seed argument if this won't be run sequentially\n",
        "\n",
        "# TURN THIS INTO A FUNCTION THAT IS VMAPPED\n",
        "def run_fits_parallel(iterations, total_samples, initialize, kernel, num_super_chains,\n",
        "             index_param, num_samples, num_warmup, rank_normalize = False):\n",
        "\n",
        "  num_parameters = index_param.shape[0]\n",
        "\n",
        "  Rhat_list = jnp.zeros((num_seed, num_parameters))\n",
        "  nRhat_list = jnp.zeros((num_seed, num_parameters))\n",
        "  B_list = jnp.zeros((num_seed, num_parameters))\n",
        "  W_list = jnp.zeros((num_seed, num_parameters))\n",
        "  mc_mean_list = jnp.zeros((num_seed, num_parameters))\n",
        "\n",
        "  # Should this be a more explicit parameter into the method for reproducibility purposes?\n",
        "  seed = jax.random.PRNGKey(1)\n",
        "  initial_state = initialize((num_super_chains*iterations,), key = seed + 1954)\n",
        "\n",
        "  initial_state = jnp.repeat(initial_state, num_chains*iterations // num_super_chains,\n",
        "                              axis = 0)\n",
        "\n",
        "  result = tfp.mcmc.sample_chain(total_samples, initial_state, kernel = kernel,\n",
        "                                 seed = seed, trace_fn = None)\n",
        "\n",
        "  # Loop over K superchains at a time in order to calculate nRhat statistics\n",
        "  # Investigate how JAX and looping may be impacting the speed of this loop\n",
        "\n",
        "  for i in range(iterations):\n",
        "    # Selecting the subset that corresponds to K superchains of size M\n",
        "    current_result = result[:, (i*num_chains):((i+1)*num_chains), :]\n",
        "    print(current_result.shape)\n",
        "    # The Rhat_list argument probably should take some type of tensor object as an argument, and this is what is yielding an error right now\n",
        "    #Rhat_list = Rhat_list.at[i, :].set(tfp.mcmc.potential_scale_reduction)\n",
        "\n",
        "    # Implementation of original R-Hat from Gelman and Rubin (1992)\n",
        "\n",
        "    #Rhat_list = Rhat_list.at[i, :].set(tfp.mcmc.potential_scale_reduction(current_result))\n",
        "\n",
        "    nRhat_local, B_local, W_local = nested_rhat(current_result,\n",
        "                                                num_super_chains = num_super_chains,\n",
        "                                                index_param = index_param,\n",
        "                                                num_samples = num_samples,\n",
        "                                                warmup_length = num_warmup,\n",
        "                                                rank_normalize = rank_normalize)\n",
        "    nRhat_list = nRhat_list.at[i, :].set(nRhat_local)\n",
        "    B_list = B_list.at[i, :].set(B_local)\n",
        "    W_list = W_list.at[i, :].set(W_local)\n",
        "\n",
        "    mc_mean_list = mc_mean_list.at[i, :].set(jnp.mean(result[num_warmup + 1, (i*num_chains):((i+1)*num_chains), index_param], axis = 1))\n",
        "    i += 1\n",
        "\n",
        "  return Rhat_list, nRhat_list, B_list, W_list, mc_mean_list"
      ],
      "metadata": {
        "id": "lX3CPtM2lS0e"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(num_samples)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O0XfOdeaR0Hj",
        "outputId": "1a883ed5-83ef-4793-a618-fbaeac843b56"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# FIx came from slicing the result matrix too early\n",
        "run_fits_parallel(\n",
        "           iterations = num_seed, total_samples = total_samples,\n",
        "           initialize = bn_initialize, kernel = kernel,\n",
        "           num_super_chains = num_super_chains, index_param = index_param,\n",
        "           num_samples = num_samples, num_warmup = num_warmup,\n",
        "           rank_normalize = rank_normalize)"
      ],
      "metadata": {
        "id": "u1EsgGMNsWBv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b33d5935-4ff2-4424-94c3-2fdae5cbc429"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(20, 128, 2)\n",
            "(20, 128, 2)\n",
            "(20, 128, 2)\n",
            "(20, 128, 2)\n",
            "(20, 128, 2)\n",
            "(20, 128, 2)\n",
            "(20, 128, 2)\n",
            "(20, 128, 2)\n",
            "(20, 128, 2)\n",
            "(20, 128, 2)\n",
            "(20, 128, 2)\n",
            "(20, 128, 2)\n",
            "(20, 128, 2)\n",
            "(20, 128, 2)\n",
            "(20, 128, 2)\n",
            "(20, 128, 2)\n",
            "(20, 128, 2)\n",
            "(20, 128, 2)\n",
            "(20, 128, 2)\n",
            "(20, 128, 2)\n",
            "(20, 128, 2)\n",
            "(20, 128, 2)\n",
            "(20, 128, 2)\n",
            "(20, 128, 2)\n",
            "(20, 128, 2)\n",
            "(20, 128, 2)\n",
            "(20, 128, 2)\n",
            "(20, 128, 2)\n",
            "(20, 128, 2)\n",
            "(20, 128, 2)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Array([[0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.]], dtype=float32),\n",
              " Array([[1.0285623, 1.0247593],\n",
              "        [1.0094608, 1.0032146],\n",
              "        [1.0180252, 1.0238867],\n",
              "        [1.0052211, 1.0078243],\n",
              "        [1.0055795, 1.008085 ],\n",
              "        [1.0061798, 1.0029197],\n",
              "        [1.00782  , 1.0021373],\n",
              "        [1.5657486, 1.447989 ],\n",
              "        [1.0055479, 1.0044115],\n",
              "        [1.0461769, 1.0343755],\n",
              "        [1.0008137, 1.0008119],\n",
              "        [1.0179238, 1.0077662],\n",
              "        [1.0293115, 1.0334105],\n",
              "        [1.0228231, 1.0201579],\n",
              "        [1.0086216, 1.0067111],\n",
              "        [1.0248461, 1.0082228],\n",
              "        [1.0060686, 1.0062075],\n",
              "        [1.0092676, 1.0105215],\n",
              "        [1.0086318, 1.0030895],\n",
              "        [1.0168439, 1.0057997],\n",
              "        [1.0013419, 1.0031674],\n",
              "        [1.0035803, 1.0047197],\n",
              "        [1.2588136, 1.0613686],\n",
              "        [1.0024343, 1.0029067],\n",
              "        [1.0028772, 1.0048635],\n",
              "        [1.0070322, 1.0004194],\n",
              "        [1.0229496, 1.0166727],\n",
              "        [1.0179317, 1.0091151],\n",
              "        [1.0018419, 1.003239 ],\n",
              "        [1.0083369, 1.0015477]], dtype=float32),\n",
              " Array([[5.15912056e-01, 1.21861950e-01],\n",
              "        [1.71067238e-01, 1.97646189e-02],\n",
              "        [4.33540642e-01, 1.55356660e-01],\n",
              "        [1.07838571e-01, 4.10461277e-02],\n",
              "        [1.02342509e-01, 3.88531499e-02],\n",
              "        [1.29918709e-01, 1.56217059e-02],\n",
              "        [1.48962677e-01, 1.17694475e-02],\n",
              "        [1.08147840e+01, 3.32825994e+00],\n",
              "        [7.86152184e-02, 3.64703275e-02],\n",
              "        [5.05843759e-01, 2.31623769e-01],\n",
              "        [1.06711565e-02, 6.67255744e-03],\n",
              "        [2.53070951e-01, 6.98459148e-02],\n",
              "        [4.70009655e-01, 3.51563871e-01],\n",
              "        [3.93948287e-01, 2.21984953e-01],\n",
              "        [1.42573833e-01, 7.32433945e-02],\n",
              "        [5.75147510e-01, 2.15728991e-02],\n",
              "        [1.32971272e-01, 1.44271692e-02],\n",
              "        [2.42043257e-01, 2.68401429e-02],\n",
              "        [1.89141780e-01, 7.75281666e-03],\n",
              "        [4.19634044e-01, 1.62857212e-02],\n",
              "        [2.65040658e-02, 8.03663768e-03],\n",
              "        [6.81272894e-02, 1.14655076e-02],\n",
              "        [5.30270386e+00, 1.65966064e-01],\n",
              "        [4.61807624e-02, 1.10461153e-02],\n",
              "        [5.52542210e-02, 1.74064413e-02],\n",
              "        [1.08541191e-01, 1.51697383e-03],\n",
              "        [4.21207279e-01, 6.95944279e-02],\n",
              "        [3.32318485e-01, 3.14390808e-02],\n",
              "        [3.03450823e-02, 1.27280038e-02],\n",
              "        [1.21117465e-01, 5.55503275e-03]], dtype=float32),\n",
              " Array([[ 8.904181 ,  2.4308286],\n",
              "        [ 8.9982395,  3.0692227],\n",
              "        [11.91857  ,  3.213565 ],\n",
              "        [10.300213 ,  2.6127586],\n",
              "        [ 9.145892 ,  2.393098 ],\n",
              "        [10.479169 ,  2.6712852],\n",
              "        [ 9.487305 ,  2.7503524],\n",
              "        [ 7.450411 ,  3.034873 ],\n",
              "        [ 7.0655246,  4.1245327],\n",
              "        [ 5.3536296,  3.3120828],\n",
              "        [ 6.553786 ,  4.1072726],\n",
              "        [ 6.996901 ,  4.4793386],\n",
              "        [ 7.901664 ,  5.1748114],\n",
              "        [ 8.533087 ,  5.4512024],\n",
              "        [ 8.232944 ,  5.43859  ],\n",
              "        [11.43214  ,  1.3063921],\n",
              "        [10.922581 ,  1.1584885],\n",
              "        [12.998367 ,  1.2688036],\n",
              "        [10.908939 ,  1.2527549],\n",
              "        [12.35248  ,  1.399967 ],\n",
              "        [ 9.868309 ,  1.2666173],\n",
              "        [ 9.49683  ,  1.2117689],\n",
              "        [ 9.070471 ,  1.3119512],\n",
              "        [ 9.473893 ,  1.8973134],\n",
              "        [ 9.587879 ,  1.7851655],\n",
              "        [ 7.690397 ,  1.8079424],\n",
              "        [ 9.072681 ,  2.069808 ],\n",
              "        [ 9.1838665,  1.7167374],\n",
              "        [ 8.22966  ,  1.9615847],\n",
              "        [ 7.2337623,  1.7931371]], dtype=float32),\n",
              " Array([[ 7.4007835 , -1.1151698 ],\n",
              "        [ 7.9368734 , -0.9561883 ],\n",
              "        [ 7.4494767 , -1.0574512 ],\n",
              "        [ 7.5932837 , -1.1401863 ],\n",
              "        [ 7.3353095 , -1.1261566 ],\n",
              "        [ 7.350517  , -1.2819097 ],\n",
              "        [ 7.9252853 , -0.7999593 ],\n",
              "        [ 9.955547  ,  0.42227858],\n",
              "        [13.075788  ,  2.2423341 ],\n",
              "        [12.890938  ,  2.1730695 ],\n",
              "        [13.015266  ,  2.2618532 ],\n",
              "        [12.919496  ,  2.2859397 ],\n",
              "        [13.280338  ,  2.4787822 ],\n",
              "        [12.921207  ,  2.0876224 ],\n",
              "        [12.89541   ,  2.2969685 ],\n",
              "        [ 1.1529673 , -2.6354065 ],\n",
              "        [ 1.0250206 , -2.8066802 ],\n",
              "        [ 0.9803442 , -2.7164955 ],\n",
              "        [ 1.2414188 , -2.7320979 ],\n",
              "        [ 0.87135565, -2.5498579 ],\n",
              "        [ 0.7944244 , -2.9388561 ],\n",
              "        [ 1.3073535 , -2.80442   ],\n",
              "        [ 3.3010876 , -2.298512  ],\n",
              "        [ 5.0585265 , -1.9697676 ],\n",
              "        [ 5.305467  , -1.8894415 ],\n",
              "        [ 5.410674  , -1.9106367 ],\n",
              "        [ 5.7279334 , -1.8445013 ],\n",
              "        [ 5.463623  , -1.8836787 ],\n",
              "        [ 5.463175  , -1.8285928 ],\n",
              "        [ 5.1224375 , -2.0656495 ]], dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def superchain_bootstrap(seed, result_state, num_chains, num_super_chains, index_param,\n",
        "                num_samples, warmup_length = 0, rank_normalize = False):\n",
        "\n",
        "  # Resampling from the available superchains to calculate a bootstrap sample\n",
        "  sc_selections = jax.random.choice(key = seed, a = num_super_chains,\n",
        "                                      shape = (num_super_chains,),\n",
        "                                            replace = True)\n",
        "\n",
        "  M = num_chains//num_super_chains\n",
        "\n",
        "  # Assigning first resampled superchain due to JAX array immutability\n",
        "  sc_bootstrapped = jax.lax.dynamic_slice_in_dim(result_state, sc_selections[0]*M, M, axis = 1)\n",
        "  for index in sc_selections[1:]:\n",
        "    # Creating a new sample using bootstrapped superchains, and computing Nested Rhat\n",
        "    sc_bootstrapped = jnp.concatenate((sc_bootstrapped, jax.lax.dynamic_slice_in_dim(result_state, index*M, M, axis = 1)), axis = 1)\n",
        "  return nested_rhat(sc_bootstrapped, num_super_chains, index_param, num_samples, warmup_length, rank_normalize)[0]\n",
        "\n",
        "superchain_bootstrap = jax.vmap(superchain_bootstrap, in_axes = (0, None, None, None, None, None), out_axes = 0)\n"
      ],
      "metadata": {
        "id": "SuUZrfkN_tG6"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seed = jax.random.PRNGKey(17)\n",
        "keys = jax.random.split(seed, 3)\n",
        "#superchain_bootstrap(keys, result, num_chains, num_super_chains, index_param, num_samples)"
      ],
      "metadata": {
        "id": "IK331mLGDMS1"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p3IrYMAmghG3",
        "outputId": "d87d21dd-cbf8-45eb-9269-d850f4e2edea"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Array([[[-1.3588713e+01,  5.7870488e+00],\n",
              "        [-1.3062107e+01,  4.8002548e+00],\n",
              "        [-1.4049887e+01,  4.9101820e+00],\n",
              "        ...,\n",
              "        [-1.3397634e-02, -3.7039132e+00],\n",
              "        [ 3.2161176e-02, -3.4378133e+00],\n",
              "        [ 2.0687485e-01, -5.6175876e+00]],\n",
              "\n",
              "       [[-1.3588713e+01,  5.7870488e+00],\n",
              "        [-1.3062107e+01,  4.8002548e+00],\n",
              "        [-1.4049887e+01,  4.9101820e+00],\n",
              "        ...,\n",
              "        [-1.3397634e-02, -3.7039132e+00],\n",
              "        [ 3.2161176e-02, -3.4378133e+00],\n",
              "        [ 2.0687485e-01, -5.6175876e+00]],\n",
              "\n",
              "       [[-1.3588713e+01,  5.7870488e+00],\n",
              "        [-1.3062107e+01,  4.8002548e+00],\n",
              "        [-1.4049887e+01,  4.9101820e+00],\n",
              "        ...,\n",
              "        [-1.3397634e-02, -3.7039132e+00],\n",
              "        [-1.7051940e+00, -2.2336993e+00],\n",
              "        [ 2.0687485e-01, -5.6175876e+00]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[-1.3778205e+01,  3.6130025e+00],\n",
              "        [-1.1565995e+01, -3.1337008e-01],\n",
              "        [-1.7491156e+01,  6.9300065e+00],\n",
              "        ...,\n",
              "        [-5.1843560e-01, -2.2952733e+00],\n",
              "        [-9.8615539e-01, -5.3210559e+00],\n",
              "        [ 2.2783992e+00, -3.5192456e+00]],\n",
              "\n",
              "       [[-1.4068560e+01,  2.1354301e+00],\n",
              "        [-1.0964580e+01,  7.3828769e-01],\n",
              "        [-1.8536743e+01,  6.7848649e+00],\n",
              "        ...,\n",
              "        [-1.4881599e-01, -3.9542654e+00],\n",
              "        [-1.1490175e+00, -3.8592393e+00],\n",
              "        [ 2.6416163e+00, -3.8677788e+00]],\n",
              "\n",
              "       [[-1.2912323e+01,  3.2895913e+00],\n",
              "        [-1.0413697e+01,  1.0547349e+00],\n",
              "        [-1.8328741e+01,  6.7143621e+00],\n",
              "        ...,\n",
              "        [-1.0962288e+00, -3.4684088e+00],\n",
              "        [-5.3754193e-01, -2.9805703e+00],\n",
              "        [ 3.1180198e+00, -4.4188962e+00]]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(result.shape)\n",
        "jnp.take(result, jnp.array(jnp.where(groups == 0)), axis = 1).shape"
      ],
      "metadata": {
        "id": "mViw22d-Vyic",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a8584fb-d39e-4599-9273-01940162c643"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(20, 128, 2)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20, 1, 38, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = jnp.array([1, 2, 3, 4, 1])\n",
        "jnp.unique(x, return_counts = True)"
      ],
      "metadata": {
        "id": "p3kuahkwX5aM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0ff79ae-4cc0-413a-ec65-f65ecca723e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Array([1, 2, 3, 4], dtype=int32), Array([2, 1, 1, 1], dtype=int32))"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Nested Rhat needs to be rewritten for the possibility where we resample individual chains\n",
        "def nested_rhat_1dim_bootstrap(result_state, super_chain_groups, index_param,\n",
        "                     num_samples, warmup_length = 0,\n",
        "                     rank_normalize = False):\n",
        "\n",
        "  # Selecting only samples after burn-in\n",
        "  initial_state_param = result_state[warmup_length:(warmup_length + num_samples),\n",
        "                             :, index_param]\n",
        "  num_chains = initial_state_param.shape[0]\n",
        "  # Setting variables for size of stored markov chains\n",
        "  num_samples = initial_state_param.shape[0]\n",
        "  num_chains = initial_state_param.shape[1]\n",
        "  super_chains, chain_lengths = jnp.unique(super_chain_groups, size = num_chains, return_counts = True)\n",
        "  total_samples = num_samples * num_chains\n",
        "\n",
        "\n",
        "  # Reshaping array to format new superchains of varying length\n",
        "  state_param = jnp.take(initial_state_param, jnp.array(jnp.where(super_chain_groups == 0)), axis = 1)\n",
        "  for sc in super_chains[1:]:\n",
        "    new_super_chain = jnp.take(initial_state_param, jnp.array(jnp.where(super_chain_groups == sc)), axis = 1)\n",
        "    state_param = jnp.concatenate((state_param, new_super_chain), axis = 2)\n",
        "\n",
        "  # \\tilde{B}_k in the paper, which goes into equation 17\n",
        "  between_chain_var = jnp.zeros(len(super_chains))\n",
        "  start = 0\n",
        "  for super in range(len(super_chains)):\n",
        "    #print(state_param[:, :, start:(start+chain_lengths[super])].shape)\n",
        "    subchain_means = jnp.mean(state_param[:, :, start:(start+chain_lengths[super])], axis = (0,1))\n",
        "    between_chain_var = between_chain_var.at[super].set(jnp.var(subchain_means, ddof = 1))\n",
        "    start += chain_lengths[super]\n",
        "\n",
        "  # \\tilde{W}_k in the paper, which goes into equation 17\n",
        "  if (num_samples == 1):\n",
        "    mean_within_chain_var = 0\n",
        "  else:\n",
        "    mean_within_chain_var = jnp.zeros(len(super_chains))\n",
        "    start = 0\n",
        "    for super in range(len(super_chains)):\n",
        "      within_chain_var = jnp.var(state_param[:, :, start:(start + chain_lengths[super])], axis = (0,1), ddof = 1)\n",
        "      mean_within_chain_var = mean_within_chain_var.at[super].set(jnp.mean(within_chain_var))\n",
        "      start += chain_lengths[super]\n",
        "\n",
        "  # Equation 17 in the paper\n",
        "  # This part should remain the same\n",
        "  total_chain_var = between_chain_var + mean_within_chain_var\n",
        "\n",
        "  # Equation 14 in the paper\n",
        "  mean_super_chain = jnp.zeros(len(super_chains))\n",
        "  start = 0\n",
        "  for super in range(len(super_chains)):\n",
        "    # This is for creating the mean chain\n",
        "    # An axis shouldn't need to be specified here, since we are working within each superchain\n",
        "    mean_super_chain = mean_super_chain.at[super].set(jnp.mean(state_param[:, :,start:(start+chain_lengths[super])]))\n",
        "    start += chain_lengths[super]\n",
        "\n",
        "  # Equation 16 in the paper\n",
        "  between_super_chain_var = jnp.var(mean_super_chain, ddof = 1)\n",
        "\n",
        "  # Equation 18 in the paper\n",
        "  # This equation should be the same\n",
        "  return jnp.sqrt(1 + between_super_chain_var / jnp.mean(total_chain_var)),\\\n",
        "    between_super_chain_var, jnp.mean(total_chain_var)\n",
        "  #return between_chain_var, mean_within_chain_var\n",
        "\n",
        "\n",
        "def nested_rhat_bootstrap(result_state, super_chain_groups, index_param,\n",
        "                num_samples, warmup_length = 0, rank_normalize = False):\n",
        "  nRhat = jnp.array([])\n",
        "  B = jnp.array([])\n",
        "  W = jnp.array([])\n",
        "  for i in range(0, index_param.shape[0]):\n",
        "    nRhat_local, B_local, W_local = nested_rhat_1dim_bootstrap(result_state,\n",
        "                    super_chain_groups, index_param[i], num_samples,\n",
        "                    warmup_length, rank_normalize)\n",
        "\n",
        "    nRhat = jnp.append(nRhat, nRhat_local)\n",
        "    B = jnp.append(B, B_local)\n",
        "    W = jnp.append(W, W_local)\n",
        "\n",
        "  return nRhat, B, W"
      ],
      "metadata": {
        "id": "2jx6uWD7qtKZ"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a list of superchain indices for each markov chain\n",
        "g = jnp.concatenate((jnp.repeat(0, 32), jnp.repeat(1, 32), jnp.repeat(2, 32), jnp.repeat(3, 32)))"
      ],
      "metadata": {
        "id": "_4oXHpffuF0j"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nested_rhat(result, num_super_chains, index_param, num_samples, warmup_length = 10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GDg5iDvDtag3",
        "outputId": "185477a8-efbf-478a-9bd8-819b5962edb1"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Array([3.1204205, 2.9483204], dtype=float32),\n",
              " Array([77.256744, 34.424988], dtype=float32),\n",
              " Array([8.842455 , 4.4750824], dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The between chain variance is the exact same, so the error lies in the within chain variances\n",
        "nested_rhat_bootstrap(result, g, index_param, num_samples, warmup_length = 10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xnOSTn6Rt6K1",
        "outputId": "6ba8ee69-8721-4c2f-a9c3-9dc251036284"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Array([nan, nan], dtype=float32),\n",
              " Array([nan, nan], dtype=float32),\n",
              " Array([nan, nan], dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "jnp.mean(result[:, 0, 0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GOQw3g1Q4lrz",
        "outputId": "2e2e6d1c-e200-4458-b099-3c59dcafad5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Array(-0.15447582, dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a second bootstrapped variance estimator\n",
        "# This should be \"naive\" as well, where each Markov Chain is bootstrapped\n",
        "# It is important to keep track of which superchain each chain belongs to\n",
        "# The number of chains within each superchain will not necessarily be the same size anymore\n",
        "from jax import jit\n",
        "\n",
        "def individual_bootstrap(seed, result_state, num_chains, num_super_chains, index_param,\n",
        "                num_samples, warmup_length = 0, rank_normalize = False):\n",
        "\n",
        "  M = num_chains // num_super_chains\n",
        "\n",
        "  # Selecting indices of bootstrap to compute\n",
        "  bootstraps = jax.random.choice(key = seed, a = num_chains,\n",
        "                                      shape = (num_chains,),\n",
        "                                            replace = True)\n",
        "\n",
        "  # Tracking which superchain each sample is associated with\n",
        "  superchains = bootstraps // M\n",
        "\n",
        "  bootstrapped_chains = jnp.reshape(result_state[:, bootstraps[0], :], (result_state.shape[0], -1, result_state.shape[2]))\n",
        "  for chain in bootstraps[1:]:\n",
        "    new_sample = jnp.reshape(result_state[:, chain, :], (result_state.shape[0], -1, result_state.shape[2]))\n",
        "    bootstrapped_chains = jnp.concatenate((bootstrapped_chains, new_sample), axis = 1)\n",
        "  return nested_rhat_bootstrap(bootstrapped_chains, superchains, index_param, num_samples, warmup_length)\n",
        "\n",
        "#individual_bootstrap = jax.(individual_bootstrap, in_axes = (0, None, None, None, None, None), out_axes = 0)\n",
        "individual_bootstrap = jax.jit(individual_bootstrap, static_argnums = (2, 3, 5, 6))"
      ],
      "metadata": {
        "id": "LSMUCFUtSWk0"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keys"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gi-VTRq29i3s",
        "outputId": "aaab22c2-64ad-4759-a72e-670472fc38e6"
      },
      "execution_count": 253,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Array([[ 460981195, 2866455954],\n",
              "       [ 243324181, 1144372815],\n",
              "       [2591048017, 3303511741]], dtype=uint32)"
            ]
          },
          "metadata": {},
          "execution_count": 253
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#individual_bootstrap(keys, result, 128, 4, index_param, 10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        },
        "id": "cTlJ1J7T8tXM",
        "outputId": "daf66da9-9311-467e-a133-6398ef53fe74"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-ebc07adffb51>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mindividual_bootstrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_param\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-22-6c1844727a54>\u001b[0m in \u001b[0;36mindividual_bootstrap\u001b[0;34m(seed, result_state, num_chains, num_super_chains, index_param, num_samples, warmup_length, rank_normalize)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0;31m# Selecting indices of bootstrap to compute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m   bootstraps = jax.random.choice(key = seed, a = num_chains,\n\u001b[0m\u001b[1;32m     14\u001b[0m                                       \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnum_chains\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                                             replace = True)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/jax/_src/random.py\u001b[0m in \u001b[0;36mchoice\u001b[0;34m(key, a, shape, replace, p, axis)\u001b[0m\n\u001b[1;32m    555\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m       \u001b[0mind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    558\u001b[0m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mind\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/jax/_src/random.py\u001b[0m in \u001b[0;36mrandint\u001b[0;34m(key, shape, minval, maxval, dtype)\u001b[0m\n\u001b[1;32m    360\u001b[0m   \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanonicalize_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m   \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanonicalize_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_randint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatic_argnums\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "    \u001b[0;31m[... skipping hidden 12 frame]\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/jax/_src/random.py\u001b[0m in \u001b[0;36m_randint\u001b[0;34m(key, shape, minval, maxval, dtype)\u001b[0m\n\u001b[1;32m    393\u001b[0m   \u001b[0;31m# We generate double the number of random bits required by the dtype so as to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m   \u001b[0;31m# reduce that bias.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m   \u001b[0mk1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    396\u001b[0m   \u001b[0mrbits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_random_bits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m   \u001b[0mhigher_bits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlower_bits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrbits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrbits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/jax/_src/random.py\u001b[0m in \u001b[0;36m_split\u001b[0;34m(key, num)\u001b[0m\n\u001b[1;32m    200\u001b[0m   \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprng\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPRNGKeyArray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m     raise TypeError(\"split accepts a single key, but was given a key array of\"\n\u001b[0m\u001b[1;32m    203\u001b[0m                     f\"shape {key.shape} != (). Use jax.vmap for batching.\")\n\u001b[1;32m    204\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mprng\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: split accepts a single key, but was given a key array ofshape (3,) != (). Use jax.vmap for batching."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "index_param = jnp.array([0,1])\n",
        "\n",
        "individual_bootstrap(seed, result, 128, 4, index_param, 10, warmup_length = 10)"
      ],
      "metadata": {
        "id": "EySyNd90vHWP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "764abcfe-0d1f-49e0-9e05-31cf22326ae0"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ConcretizationTypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mConcretizationTypeError\u001b[0m                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-a2f9d047bca1>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mindex_param\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mindividual_bootstrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_param\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarmup_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "    \u001b[0;31m[... skipping hidden 12 frame]\u001b[0m\n",
            "\u001b[0;32m<ipython-input-30-d2631ed46a29>\u001b[0m in \u001b[0;36mindividual_bootstrap\u001b[0;34m(seed, result_state, num_chains, num_super_chains, index_param, num_samples, warmup_length, rank_normalize)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mnew_sample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mresult_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mbootstrapped_chains\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbootstrapped_chains\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mnested_rhat_bootstrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbootstrapped_chains\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuperchains\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_param\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarmup_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m#individual_bootstrap = jax.(individual_bootstrap, in_axes = (0, None, None, None, None, None), out_axes = 0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-9c47e4d4ff25>\u001b[0m in \u001b[0;36mnested_rhat_bootstrap\u001b[0;34m(result_state, super_chain_groups, index_param, num_samples, warmup_length, rank_normalize)\u001b[0m\n\u001b[1;32m     70\u001b[0m   \u001b[0mW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_param\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m     nRhat_local, B_local, W_local = nested_rhat_1dim_bootstrap(result_state,\n\u001b[0m\u001b[1;32m     73\u001b[0m                     \u001b[0msuper_chain_groups\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_param\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m                     warmup_length, rank_normalize)\n",
            "\u001b[0;32m<ipython-input-12-9c47e4d4ff25>\u001b[0m in \u001b[0;36mnested_rhat_1dim_bootstrap\u001b[0;34m(result_state, super_chain_groups, index_param, num_samples, warmup_length, rank_normalize)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m   \u001b[0;31m# Reshaping array to format new superchains of varying length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m   \u001b[0mstate_param\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitial_state_param\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msuper_chain_groups\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0msc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msuper_chains\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mnew_super_chain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitial_state_param\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msuper_chain_groups\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/jax/_src/numpy/lax_numpy.py\u001b[0m in \u001b[0;36mwhere\u001b[0;34m(condition, x, y, size, fill_value)\u001b[0m\n\u001b[1;32m   1061\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m     \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_arraylike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"where\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcondition\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1063\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcondition\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1064\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1065\u001b[0m     \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_arraylike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"where\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcondition\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/jax/_src/numpy/lax_numpy.py\u001b[0m in \u001b[0;36mnonzero\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1328\u001b[0m     \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_special_dim_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1330\u001b[0;31m     size = core.concrete_or_error(operator.index, size,\n\u001b[0m\u001b[1;32m   1331\u001b[0m       \u001b[0;34m\"The size argument of jnp.nonzero must be statically specified \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1332\u001b[0m       \"to use jnp.nonzero within JAX transformations.\")\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/jax/_src/core.py\u001b[0m in \u001b[0;36mconcrete_or_error\u001b[0;34m(force, val, context)\u001b[0m\n\u001b[1;32m   1354\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mforce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1355\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1356\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mConcretizationTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1357\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mforce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mConcretizationTypeError\u001b[0m: Abstract tracer value encountered where concrete value is expected: Traced<ShapedArray(int32[])>with<DynamicJaxprTrace(level=1/0)>\nThe size argument of jnp.nonzero must be statically specified to use jnp.nonzero within JAX transformations.\nThe error occurred while tracing the function individual_bootstrap at <ipython-input-30-d2631ed46a29>:7 for jit. This value became a tracer due to JAX operations on these lines:\n\n  operation a:i32[] = pjit[\n  jaxpr={ lambda ; b:i32[] c:i32[] d:i32[]. let\n      e:i32[] = max c b\n      f:i32[] = min d e\n    in (f,) }\n  name=clip\n] g h i\n    from line <ipython-input-30-d2631ed46a29>:13 (individual_bootstrap)\n\n  operation a:bool[] = gt b c\n    from line <ipython-input-30-d2631ed46a29>:13 (individual_bootstrap)\n\n  operation a:i32[] = pjit[\n  jaxpr={ lambda ; b:i32[] c:i32[] d:i32[]. let\n      e:i32[] = max c b\n      f:i32[] = min d e\n    in (f,) }\n  name=clip\n] g h i\n    from line <ipython-input-30-d2631ed46a29>:13 (individual_bootstrap)\n\n  operation a:i32[] = pjit[\n  jaxpr={ lambda ; b:i32[] c:i32[] d:i32[]. let\n      e:i32[] = max c b\n      f:i32[] = min d e\n    in (f,) }\n  name=clip\n] g h i\n    from line <ipython-input-30-d2631ed46a29>:13 (individual_bootstrap)\n\n  operation a:u32[1] = broadcast_in_dim[broadcast_dimensions=() shape=(1,)] b\n    from line <ipython-input-30-d2631ed46a29>:13 (individual_bootstrap)\n\n(Additional originating lines are not shown.)\n\nSee https://jax.readthedocs.io/en/latest/errors.html#jax.errors.ConcretizationTypeError"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def adaptive_initialize(target_log_prob_fn, init_step_size, num_warmup, warmup_window):\n",
        "    kernel_cold = construct_kernel(target_log_prob_fn = target_log_prob_fn,\n",
        "                                   init_step_size = init_step_size,\n",
        "                                   num_warmup = num_warmup)\n",
        "    kernel_warm = construct_kernel(target_log_prob_fn = target_log_prob_fn,\n",
        "                                   init_step_size = init_step_size,\n",
        "                                   num_warmup = num_warmup)\n",
        "    window_array = jnp.append(jnp.repeat(10, 10),\n",
        "                              jnp.repeat(warmup_window,\n",
        "                                         num_warmup // warmup_window - 1))\n",
        "    nRhat_upper = 1.05\n",
        "\n",
        "    try:\n",
        "      mean_est = target.sample_transformations['identity'].ground_truth_mean\n",
        "    except:\n",
        "      print('no ground truth mean')\n",
        "      mean_est = (result[num_warmup:, :]).mean(0).mean(0)\n",
        "    try:\n",
        "      var_est = target.sample_transformations['identity'].ground_truth_standard_deviation**2\n",
        "    except:\n",
        "      print('no ground truth std dev')\n",
        "      var_est = ((result[num_warmup:, :]**2).mean(0).mean(0) -\n",
        "                mean_est**2)\n",
        "\n",
        "    return kernel_cold, kernel_warm, window_array, nRhat_upper, mean_est, var_est"
      ],
      "metadata": {
        "id": "mOOZ-jXjfjYU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We will look into doing different runs across different GPUs to compute what nRhat should be\n",
        "# Also think about ESS and what it would look like in this scenario"
      ],
      "metadata": {
        "id": "jK39_3OTTdqB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "We will now focus on variance measurement of nested Rhat, with users having the\n",
        "possibility to choose several parameters such as the number of superchains (K),\n",
        "number of markov chains in each group of superchains (M), and number of draws in\n",
        "the sampling phase (N). We will measure this in both a brute force manner, as\n",
        "well as coming up with a notion of bootstrapping. We also can decide to run this\n",
        "variance estimate across all chains sequentially, or in parallel. Having an\n",
        "adaptive warmup length, or a fixed numbers of warmup iterations is also a\n",
        "potential parameter\n",
        "\n",
        "Using an initial seed value of 1\n",
        "\n",
        "I need to think a bit about parallelization as well as bootstrapping\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# There's 8 possibilities here that come from 2^[boostrap, adaptive, parallel]\n",
        "def variance_estimate(target_log_prob_fn, index_param, num_seed = 10, num_warmup = 1000, num_samples = 5,\n",
        "                      num_super_chains = 4, initialize = bn_initialize, num_chains = 128,\n",
        "                      bootstrap = False, adaptive = False, parallel = False,\n",
        "                      warmup_window = 100, initial_seed = 1):\n",
        "\n",
        "  if adaptive:\n",
        "\n",
        "    kernel_cold, kernel_warm, window_array, \\\n",
        "    nRhat_upper, mean_est, var_est = adaptive_initialize(target_log_prob_fn,\n",
        "                                                         init_step_size,\n",
        "                                                         num_warmup,\n",
        "                                                         warmup_window)\n",
        "\n",
        "    if bootstrap:\n",
        "      if parallel:\n",
        "        # Adpative, Bootstrapped, and Parallel\n",
        "\n",
        "        return\n",
        "\n",
        "      else:\n",
        "        # Adaptive, Bootstrapped, and Sequential\n",
        "        return\n",
        "\n",
        "    else:\n",
        "      if parallel:\n",
        "        # Adpative, Brute-Force, and Parallel\n",
        "        return\n",
        "\n",
        "      else:\n",
        "        # Adaptive, Brute-Force, and Sequential\n",
        "        mc_mean_list, warmup_length, squared_error_list, \\\n",
        "        nRhat_list = run_forge_chain(num_seed = num_seed,\n",
        "                                     kernel_cold = kernel_cold,\n",
        "                                     kernel_warm = kernel_warm,\n",
        "                                     initialize = initialize,\n",
        "                                     num_super_chains = num_super_chains,\n",
        "                                     num_warmup = window_array,\n",
        "                                     num_samples = num_samples,\n",
        "                                     target_rhat = nRhat_upper,\n",
        "                                     max_num_steps = window_array.shape[0],\n",
        "                                     index_param = index_param,\n",
        "                                     rank_normalize = False,\n",
        "                                     alpha_quantile = 1.,\n",
        "                                     mean_benchmark = mean_est,\n",
        "                                     var_benchmark = var_est)\n",
        "\n",
        "  else:\n",
        "\n",
        "    kernel = construct_kernel(target_log_prob_fn = target_log_prob_fn,\n",
        "                              init_step_size = init_step_size,\n",
        "                              num_warmup = num_warmup)\n",
        "    if bootstrap:\n",
        "\n",
        "      if parallel:\n",
        "        # Fixed, Bootstrapped, and Parallel\n",
        "        return\n",
        "\n",
        "      else:\n",
        "        # Fixed, Bootstrapped, and Sequential\n",
        "        return\n",
        "\n",
        "    else:\n",
        "      if parallel:\n",
        "        # Fixed, Brute-Force, and Parallel\n",
        "        return\n",
        "\n",
        "      else:\n",
        "        # Fixed, Brute-Force, and Sequential\n",
        "        # Adress apparent discrepancy in definition of total_samples\n",
        "        Rhat_list, nRhat_list, B_list, W_list, mc_mean_list = run_fits(\n",
        "            num_seed = num_seed, total_samples = num_warmup + num_samples + 1,\n",
        "            initialize = initialize, kernel = kernel,\n",
        "            num_super_chains = num_super_chains,\n",
        "            index_param = index_param, num_samples = num_samples,\n",
        "            num_warmup = num_warmup)\n",
        "\n",
        "  return nRhat_list"
      ],
      "metadata": {
        "id": "33hWczNl4Tmj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}