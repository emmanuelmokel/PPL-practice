{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPoIjlyx1oLekFIXvZfgzH3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/emmanuelmokel/PPL-practice/blob/main/NestedRHat_TFP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -Rf probability\n",
        "!rm -Rf fun_mc\n",
        "!rm -Rf inference_gym\n",
        "!git clone https://github.com/tensorflow/probability.git\n",
        "!mv probability/spinoffs/fun_mc/fun_mc .\n",
        "!mv probability/spinoffs/inference_gym/inference_gym .\n",
        "!pip install tf-nightly tfp-nightly jax jaxlib\n",
        "\n",
        "!pip install immutabledict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yVfP9g3Tdncu",
        "outputId": "0c0a1f07-653e-4b55-a2e2-e86b63dfc49a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'probability'...\n",
            "remote: Enumerating objects: 100109, done.\u001b[K\n",
            "remote: Counting objects: 100% (4892/4892), done.\u001b[K\n",
            "remote: Compressing objects: 100% (171/171), done.\u001b[K\n",
            "remote: Total 100109 (delta 4756), reused 4771 (delta 4721), pack-reused 95217\u001b[K\n",
            "Receiving objects: 100% (100109/100109), 137.03 MiB | 13.85 MiB/s, done.\n",
            "Resolving deltas: 100% (81917/81917), done.\n",
            "Collecting tf-nightly\n",
            "  Downloading tf_nightly-2.14.0.dev20230706-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (491.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.1/491.1 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tfp-nightly\n",
            "  Downloading tfp_nightly-0.20.0.dev20230706-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m93.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jax in /usr/local/lib/python3.10/dist-packages (0.4.10)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.10/dist-packages (0.4.10+cuda11.cudnn86)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tf-nightly) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tf-nightly) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tf-nightly) (23.5.26)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tf-nightly) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tf-nightly) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tf-nightly) (1.56.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tf-nightly) (3.8.0)\n",
            "Collecting keras-nightly~=2.14.0.dev (from tf-nightly)\n",
            "  Downloading keras_nightly-2.14.0.dev2023070607-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m75.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tf-nightly) (16.0.0)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tf-nightly) (0.2.0)\n",
            "Requirement already satisfied: numpy>=1.22 in /usr/local/lib/python3.10/dist-packages (from tf-nightly) (1.22.4)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tf-nightly) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tf-nightly) (23.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tf-nightly) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tf-nightly) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tf-nightly) (1.16.0)\n",
            "Collecting tb-nightly~=2.14.0.a (from tf-nightly)\n",
            "  Downloading tb_nightly-2.14.0a20230706-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m99.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tf-nightly) (2.3.0)\n",
            "Collecting tf-estimator-nightly~=2.14.0.dev (from tf-nightly)\n",
            "  Downloading tf_estimator_nightly-2.14.0.dev2023070608-py2.py3-none-any.whl (440 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m441.0/441.0 kB\u001b[0m \u001b[31m36.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tf-nightly) (4.6.3)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tf-nightly) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tf-nightly) (0.32.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from tfp-nightly) (4.4.2)\n",
            "Requirement already satisfied: cloudpickle>=1.3 in /usr/local/lib/python3.10/dist-packages (from tfp-nightly) (2.2.1)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from tfp-nightly) (0.1.8)\n",
            "Collecting typing-extensions>=3.6.6 (from tf-nightly)\n",
            "  Downloading typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: scipy>=1.7 in /usr/local/lib/python3.10/dist-packages (from jax) (1.10.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tf-nightly) (0.40.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tb-nightly~=2.14.0.a->tf-nightly) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tb-nightly~=2.14.0.a->tf-nightly) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tb-nightly~=2.14.0.a->tf-nightly) (3.4.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tb-nightly~=2.14.0.a->tf-nightly) (2.27.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tb-nightly~=2.14.0.a->tf-nightly) (0.7.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tb-nightly~=2.14.0.a->tf-nightly) (2.3.6)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tb-nightly~=2.14.0.a->tf-nightly) (5.3.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tb-nightly~=2.14.0.a->tf-nightly) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tb-nightly~=2.14.0.a->tf-nightly) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tb-nightly~=2.14.0.a->tf-nightly) (1.3.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tb-nightly~=2.14.0.a->tf-nightly) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tb-nightly~=2.14.0.a->tf-nightly) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tb-nightly~=2.14.0.a->tf-nightly) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tb-nightly~=2.14.0.a->tf-nightly) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tb-nightly~=2.14.0.a->tf-nightly) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tb-nightly~=2.14.0.a->tf-nightly) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tb-nightly~=2.14.0.a->tf-nightly) (3.2.2)\n",
            "Installing collected packages: typing-extensions, tf-estimator-nightly, keras-nightly, tfp-nightly, tb-nightly, tf-nightly\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.6.3\n",
            "    Uninstalling typing_extensions-4.6.3:\n",
            "      Successfully uninstalled typing_extensions-4.6.3\n",
            "Successfully installed keras-nightly-2.14.0.dev2023070607 tb-nightly-2.14.0a20230706 tf-estimator-nightly-2.14.0.dev2023070608 tf-nightly-2.14.0.dev20230706 tfp-nightly-0.20.0.dev20230706 typing-extensions-4.5.0\n",
            "Collecting immutabledict\n",
            "  Downloading immutabledict-2.2.5-py3-none-any.whl (4.1 kB)\n",
            "Installing collected packages: immutabledict\n",
            "Successfully installed immutabledict-2.2.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Er7DJXS3Ng3u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40f749e1-4f35-4466-c4a6-d450a032b775"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/distributions/distribution.py:259: ReparameterizationType.__init__ (from tensorflow.python.ops.distributions.distribution) is deprecated and will be removed after 2019-01-01.\n",
            "Instructions for updating:\n",
            "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/distributions/bernoulli.py:165: RegisterKL.__init__ (from tensorflow.python.ops.distributions.kullback_leibler) is deprecated and will be removed after 2019-01-01.\n",
            "Instructions for updating:\n",
            "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n"
          ]
        }
      ],
      "source": [
        "from matplotlib.pyplot import *\n",
        "\n",
        "import jax\n",
        "from jax import random\n",
        "from jax import numpy as jnp\n",
        "\n",
        "\n",
        "#!pip install tfp-nightly inference_gym\n",
        "from inference_gym import using_jax as gym\n",
        "\n",
        "#from tensorflow_probability.spinoffs import using_jax as fun_mcmc\n",
        "from fun_mc import using_jax as fun_mcmc\n",
        "\n",
        "from tensorflow_probability.python.internal import prefer_static as ps\n",
        "from tensorflow_probability.python.internal import unnest\n",
        "\n",
        "import tensorflow_probability as _tfp\n",
        "tfp = _tfp.substrates.jax\n",
        "tfd = tfp.distributions\n",
        "tfb = tfp.bijectors\n",
        "\n",
        "tfp_np = _tfp.substrates.numpy\n",
        "tfd_np = tfp_np.distributions\n",
        "\n",
        "import arviz as az\n",
        "from tensorflow_probability.python.internal.unnest import get_innermost"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Working with the 'Banana' Posterior Target Density\n",
        "\n",
        "target = gym.targets.VectorModel(gym.targets.Banana(),\n",
        "                                 flatten_sample_transformations = True)\n",
        "num_dimensions = target.event_shape[0]\n",
        "# Is the heuristic for the initial value of \\epsilon given in the paper used in practice?\n",
        "init_step_size = 1.\n",
        "\n",
        "def target_log_prob_fn(x):\n",
        "   y = target.default_event_space_bijector(x)\n",
        "   fldj = target.default_event_space_bijector.forward_log_det_jacobian(x)\n",
        "   return target.unnormalized_log_prob(y) + fldj\n",
        "\n",
        "offset = 2\n",
        "def bn_initialize(shape, key = random.PRNGKey(3727709)):\n",
        "  return 10 * random.normal(key, shape + (num_dimensions,)) + offset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J_4vsEveoV54",
        "outputId": "0250b299-27bd-49bf-bea3-2351d592377a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:jax._src.xla_bridge:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow_probability/python/internal/backend/jax/ops.py:285: UserWarning: Explicitly requested dtype float64 requested in astype is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
            "  return arr.astype(dtype)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Running default HMC as written in Radford Neal's paper\n",
        "\n",
        "num_chains = 128\n",
        "K = 4\n",
        "num_warmup, num_sampling = 1000, 100\n",
        "total_samples = num_warmup + num_sampling\n",
        "\n",
        "kernel = tfp.mcmc.HamiltonianMonteCarlo(target_log_prob_fn, init_step_size, 1)\n",
        "kernel = tfp.experimental.mcmc.GradientBasedTrajectoryLengthAdaptation(kernel, num_warmup)\n",
        "kernel = tfp.mcmc.DualAveragingStepSizeAdaptation(kernel, num_warmup,\n",
        "                                                  target_accept_prob = 0.75,\n",
        "                                                  reduce_fn = tfp.math.reduce_log_harmonic_mean_exp)\n",
        "\n",
        "# Initializing each chain (in a super chain) at the same location\n",
        "initial_state = bn_initialize((K,))\n",
        "initial_state = jnp.repeat(initial_state, num_chains // K, axis = 0)"
      ],
      "metadata": {
        "id": "FlX9TePtumEF"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = tfp.mcmc.sample_chain(total_samples, initial_state,\n",
        "                               kernel = kernel, seed = random.PRNGKey(1954))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w5p4ybjEvuZs",
        "outputId": "26e74297-84ac-415b-b410-fbcb76519a44"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow_probability/substrates/jax/mcmc/sample.py:339: UserWarning: Tracing all kernel results by default is deprecated. Set the `trace_fn` argument to None (the future default value) or an explicit callback that traces the values you are interested in.\n",
            "  warnings.warn('Tracing all kernel results by default is deprecated. Set '\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This object is of type tfp.mcmc.CheckpointableStatesAndTrace\n",
        "# It contains attributes all_states, trace, and final_kernel_results\n",
        "# https://www.tensorflow.org/probability/api_docs/python/tfp/mcmc/CheckpointableStatesAndTrace\n",
        "\n",
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WH7CNMY1rEeV",
        "outputId": "f48504d2-6711-41fe-bfb3-a966f5a25396"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StatesAndTrace(\n",
              "  all_states=Array([[[-1.3588713e+01,  5.7870488e+00],\n",
              "            [-1.3062107e+01,  4.8002548e+00],\n",
              "            [-1.4049887e+01,  4.9101820e+00],\n",
              "            ...,\n",
              "            [-1.3397634e-02, -3.7039132e+00],\n",
              "            [ 3.2161176e-02, -3.4378133e+00],\n",
              "            [ 2.0687485e-01, -5.6175876e+00]],\n",
              "    \n",
              "           [[-1.3588713e+01,  5.7870488e+00],\n",
              "            [-1.3062107e+01,  4.8002548e+00],\n",
              "            [-1.4049887e+01,  4.9101820e+00],\n",
              "            ...,\n",
              "            [-1.3397634e-02, -3.7039132e+00],\n",
              "            [ 3.2161176e-02, -3.4378133e+00],\n",
              "            [ 2.0687485e-01, -5.6175876e+00]],\n",
              "    \n",
              "           [[-1.3588713e+01,  5.7870488e+00],\n",
              "            [-1.3062107e+01,  4.8002548e+00],\n",
              "            [-1.4049887e+01,  4.9101820e+00],\n",
              "            ...,\n",
              "            [-1.3397634e-02, -3.7039132e+00],\n",
              "            [-1.7051939e+00, -2.2337000e+00],\n",
              "            [ 2.0687485e-01, -5.6175876e+00]],\n",
              "    \n",
              "           ...,\n",
              "    \n",
              "           [[-1.8550961e-01, -3.6304955e+00],\n",
              "            [ 8.9693642e+00, -1.1451519e+00],\n",
              "            [-1.1394805e+01, -2.1488002e-01],\n",
              "            ...,\n",
              "            [-7.2327800e+00, -3.1437416e+00],\n",
              "            [ 2.1520815e+01,  1.2149755e+01],\n",
              "            [-5.9924250e+00, -3.1476281e+00]],\n",
              "    \n",
              "           [[ 3.7088811e+00, -1.4155706e+00],\n",
              "            [-9.4291506e+00, -1.1097646e+00],\n",
              "            [-5.6026964e+00, -1.1220536e+00],\n",
              "            ...,\n",
              "            [ 9.5001183e+00, -1.5190432e+00],\n",
              "            [-5.5610151e+00, -1.7744447e+00],\n",
              "            [ 5.3064675e+00, -1.2284098e+00]],\n",
              "    \n",
              "           [[ 1.6359069e+00, -1.0604185e+00],\n",
              "            [-1.2648458e+01,  1.5836626e+00],\n",
              "            [-1.6926466e+00, -2.4022393e+00],\n",
              "            ...,\n",
              "            [ 1.4672077e+01,  4.3037291e+00],\n",
              "            [ 5.6924224e+00, -1.9853426e+00],\n",
              "            [ 2.1248803e+00, -1.9051087e+00]]], dtype=float32),\n",
              "  trace=DualAveragingStepSizeAdaptationResults(\n",
              "      inner_results=GradientBasedTrajectoryLengthAdaptationResults(\n",
              "          inner_results=MetropolisHastingsKernelResults(\n",
              "              accepted_results=UncalibratedHamiltonianMonteCarloKernelResults(\n",
              "                  log_acceptance_correction=Array([[-25.47201   , -26.731134  , -26.826305  , ...,  -1.1570487 ,\n",
              "                             -1.2749305 ,   1.2506258 ],\n",
              "                           [-25.47201   , -26.731134  , -26.826305  , ...,  -1.1570487 ,\n",
              "                             -1.2749305 ,   1.2506258 ],\n",
              "                           [-25.47201   , -26.731134  , -26.826305  , ...,  -1.1570487 ,\n",
              "                             -0.17945337,   1.2506258 ],\n",
              "                           ...,\n",
              "                           [ -2.4276276 ,   0.14828105,   0.85070837, ...,   0.73547566,\n",
              "                              1.5085241 ,  -0.8288188 ],\n",
              "                           [  0.46972138,   0.15989089,  -0.65572864, ...,  -0.2823372 ,\n",
              "                             -2.7691064 ,  -0.30076164],\n",
              "                           [  0.79811627,   0.14897916,  -0.4059763 , ...,   0.3562851 ,\n",
              "                             -0.02781487,  -0.09805143]], dtype=float32),\n",
              "                  target_log_prob=Array([[-10.336712 ,  -8.5893   ,  -7.103934 , ...,  -4.388214 ,\n",
              "                             -4.2363214,  -7.569921 ],\n",
              "                           [-10.336712 ,  -8.5893   ,  -7.103934 , ...,  -4.388214 ,\n",
              "                             -4.2363214,  -7.569921 ],\n",
              "                           [-10.336712 ,  -8.5893   ,  -7.103934 , ...,  -4.388214 ,\n",
              "                             -4.385568 ,  -7.569921 ],\n",
              "                           ...,\n",
              "                           [ -4.340048 ,  -4.698747 ,  -5.4058614, ...,  -5.869443 ,\n",
              "                             -7.244192 ,  -5.0702014],\n",
              "                           [ -4.8957467,  -4.886895 ,  -4.7356863, ...,  -5.3440104,\n",
              "                             -4.339432 ,  -4.710764 ],\n",
              "                           [ -5.882333 ,  -4.9636736,  -4.285762 , ...,  -5.57436  ,\n",
              "                             -4.3033857,  -4.623298 ]], dtype=float32),\n",
              "                  grads_target_log_prob=[Array([[[-2.5118370e+00, -3.2474554e+00],\n",
              "                            [-1.9710945e+00, -2.6816955e+00],\n",
              "                            [-1.5355424e+00, -1.9882026e+00],\n",
              "                            ...,\n",
              "                            [ 6.9982710e-04,  7.0391876e-01],\n",
              "                            [-1.1665074e-03,  4.3784449e-01],\n",
              "                            [-3.4575466e-02,  2.6188717e+00]],\n",
              "                    \n",
              "                           [[-2.5118370e+00, -3.2474554e+00],\n",
              "                            [-1.9710945e+00, -2.6816955e+00],\n",
              "                            [-1.5355424e+00, -1.9882026e+00],\n",
              "                            ...,\n",
              "                            [ 6.9982710e-04,  7.0391876e-01],\n",
              "                            [-1.1665074e-03,  4.3784449e-01],\n",
              "                            [-3.4575466e-02,  2.6188717e+00]],\n",
              "                    \n",
              "                           [[-2.5118370e+00, -3.2474554e+00],\n",
              "                            [-1.9710945e+00, -2.6816955e+00],\n",
              "                            [-1.5355424e+00, -1.9882026e+00],\n",
              "                            ...,\n",
              "                            [ 6.9982710e-04,  7.0391876e-01],\n",
              "                            [-5.2424755e-02, -6.7906934e-01],\n",
              "                            [-3.4575466e-02,  2.6188717e+00]],\n",
              "                    \n",
              "                           ...,\n",
              "                    \n",
              "                           [[ 8.8843675e-03,  6.3152808e-01],\n",
              "                            [-3.9033058e-01,  5.5863667e-01],\n",
              "                            [ 8.7292910e-01,  1.1101273e+00],\n",
              "                            ...,\n",
              "                            [ 8.1577146e-01,  1.7131349e+00],\n",
              "                            [ 1.4058133e+00, -1.2553904e+00],\n",
              "                            [ 5.0033259e-01,  1.2249029e+00]],\n",
              "                    \n",
              "                           [[ 2.2366528e-01, -1.1717554e+00],\n",
              "                            [ 5.3389603e-01,  7.7703100e-01],\n",
              "                            [-2.5870121e-01, -9.3624020e-01],\n",
              "                            ...,\n",
              "                            [-7.9417795e-01,  1.2266107e+00],\n",
              "                            [-4.3756932e-02, -2.9780859e-01],\n",
              "                            [ 2.4202761e-01, -9.2683220e-01]],\n",
              "                    \n",
              "                           [[ 1.6613901e-01, -1.8592956e+00],\n",
              "                            [ 2.9028842e-01,  2.1584168e-01],\n",
              "                            [-3.5052244e-02, -5.1180905e-01],\n",
              "                            ...,\n",
              "                            [ 5.9771127e-01, -8.4563357e-01],\n",
              "                            [-4.2392429e-02, -4.2547196e-02],\n",
              "                            [ 1.0107263e-01, -9.5943785e-01]]], dtype=float32)],\n",
              "                  initial_momentum=[Array([[[-0.31564724,  0.7902418 ],\n",
              "                            [ 0.21095897, -0.19655246],\n",
              "                            [-0.7768212 , -0.08662506],\n",
              "                            ...,\n",
              "                            [ 0.7253072 ,  0.21925187],\n",
              "                            [ 0.77086604,  0.4853519 ],\n",
              "                            [ 0.9455797 , -1.6944226 ]],\n",
              "                    \n",
              "                           [[-0.31564724,  0.7902418 ],\n",
              "                            [ 0.21095897, -0.19655246],\n",
              "                            [-0.7768212 , -0.08662506],\n",
              "                            ...,\n",
              "                            [ 0.7253072 ,  0.21925187],\n",
              "                            [ 0.77086604,  0.4853519 ],\n",
              "                            [ 0.9455797 , -1.6944226 ]],\n",
              "                    \n",
              "                           [[-0.31564724,  0.7902418 ],\n",
              "                            [ 0.21095897, -0.19655246],\n",
              "                            [-0.7768212 , -0.08662506],\n",
              "                            ...,\n",
              "                            [ 0.7253072 ,  0.21925187],\n",
              "                            [-0.6059671 , -0.20480955],\n",
              "                            [ 0.9455797 , -1.6944226 ]],\n",
              "                    \n",
              "                           ...,\n",
              "                    \n",
              "                           [[ 0.74908876, -0.05640514],\n",
              "                            [ 0.3009699 ,  0.6228602 ],\n",
              "                            [-2.1046638 , -0.09424964],\n",
              "                            ...,\n",
              "                            [ 0.8136257 ,  1.8466041 ],\n",
              "                            [ 1.9160715 ,  0.29572326],\n",
              "                            [-0.8857924 , -0.38785768]],\n",
              "                    \n",
              "                           [[ 0.99403965,  1.1899048 ],\n",
              "                            [ 0.32273594, -1.2633713 ],\n",
              "                            [-0.8996232 ,  0.97487783],\n",
              "                            ...,\n",
              "                            [-0.4195793 ,  2.7289662 ],\n",
              "                            [ 0.36993018,  0.03760025],\n",
              "                            [ 0.4446919 ,  1.3309208 ]],\n",
              "                    \n",
              "                           [[-0.5723142 ,  1.7980622 ],\n",
              "                            [-0.9963563 ,  0.13651267],\n",
              "                            [ 0.3388756 , -0.56936985],\n",
              "                            ...,\n",
              "                            [ 1.241279  ,  0.8045798 ],\n",
              "                            [ 1.5725906 , -0.9562603 ],\n",
              "                            [-0.48666552,  0.2501972 ]]], dtype=float32)],\n",
              "                  final_momentum=[Array([[[-4.48962   , -5.6135054 ],\n",
              "                            [-3.692643  , -6.31742   ],\n",
              "                            [-4.462647  , -5.8607464 ],\n",
              "                            ...,\n",
              "                            [ 0.7740688 ,  1.5129629 ],\n",
              "                            [ 0.8186944 ,  1.6460259 ],\n",
              "                            [ 0.97670364,  0.55676496]],\n",
              "                    \n",
              "                           [[-4.48962   , -5.6135054 ],\n",
              "                            [-3.692643  , -6.31742   ],\n",
              "                            [-4.462647  , -5.8607464 ],\n",
              "                            ...,\n",
              "                            [ 0.7740688 ,  1.5129629 ],\n",
              "                            [ 0.8186944 ,  1.6460259 ],\n",
              "                            [ 0.97670364,  0.55676496]],\n",
              "                    \n",
              "                           [[-4.48962   , -5.6135054 ],\n",
              "                            [-3.692643  , -6.31742   ],\n",
              "                            [-4.462647  , -5.8607464 ],\n",
              "                            ...,\n",
              "                            [ 0.7740688 ,  1.5129629 ],\n",
              "                            [-0.68258137, -0.5496658 ],\n",
              "                            [ 0.97670364,  0.55676496]],\n",
              "                    \n",
              "                           ...,\n",
              "                    \n",
              "                           [[ 1.537978  , -1.7476252 ],\n",
              "                            [-0.04261062, -0.4244525 ],\n",
              "                            [-1.2092952 ,  1.1290178 ],\n",
              "                            ...,\n",
              "                            [ 1.4102366 ,  0.78244144],\n",
              "                            [-0.6130294 ,  0.60492086],\n",
              "                            [ 0.35939914,  1.5695641 ]],\n",
              "                    \n",
              "                           [[-0.7679731 , -0.9352876 ],\n",
              "                            [ 0.45549557,  1.0830548 ],\n",
              "                            [ 1.7092553 , -0.3867973 ],\n",
              "                            ...,\n",
              "                            [ 2.33301   , -1.6568168 ],\n",
              "                            [-1.9053539 ,  1.43042   ],\n",
              "                            [-0.46828103,  1.5334071 ]],\n",
              "                    \n",
              "                           [[-0.71021724,  1.2082757 ],\n",
              "                            [ 0.23058109,  0.8125489 ],\n",
              "                            [ 0.71867263, -0.85701865],\n",
              "                            ...,\n",
              "                            [-0.01331711,  1.21465   ],\n",
              "                            [ 1.8499821 ,  0.14377263],\n",
              "                            [-0.6840187 , -0.16632284]]], dtype=float32)],\n",
              "                  step_size=Array([ 1.        , 14.885853  ,  2.8592095 , ...,  0.79912025,\n",
              "                            0.79912025,  0.79912025], dtype=float32),\n",
              "                  num_leapfrog_steps=Array([ 1,  1,  1, ..., 12, 31,  8], dtype=int32),\n",
              "                  seed=[]\n",
              "                ),\n",
              "              is_accepted=Array([[ True,  True,  True, ...,  True,  True,  True],\n",
              "                       [False, False, False, ..., False, False, False],\n",
              "                       [False, False, False, ..., False,  True, False],\n",
              "                       ...,\n",
              "                       [ True,  True,  True, ...,  True,  True,  True],\n",
              "                       [ True,  True,  True, ...,  True,  True,  True],\n",
              "                       [ True,  True,  True, ...,  True,  True,  True]], dtype=bool),\n",
              "              log_accept_ratio=Array([[ 1.4565050e+01,  1.5053335e+01,  1.6443531e+01, ...,\n",
              "                         3.7208986e-01,  4.0610075e-01, -4.0194249e-01],\n",
              "                       [-4.8846598e+10, -1.7153123e+10, -6.4085299e+09, ...,\n",
              "                        -1.6318177e+05, -1.3100898e+04, -2.1904722e+06],\n",
              "                       [-1.8873101e+03, -5.0100488e+02, -1.5457543e+03, ...,\n",
              "                        -9.4437561e+00, -3.2870007e-01, -7.6698334e+01],\n",
              "                       ...,\n",
              "                       [ 3.7459517e-01, -9.0442151e-03, -6.7323804e-02, ...,\n",
              "                        -3.0041492e-01, -1.6050947e-01,  2.3929834e-01],\n",
              "                       [-8.5977495e-02, -2.8257132e-02,  1.4446437e-02, ...,\n",
              "                         2.4309540e-01,  1.3565397e-01,  5.8675826e-02],\n",
              "                       [-1.8846983e-01,  7.2200745e-02,  4.3948174e-02, ...,\n",
              "                         1.2593555e-01,  8.2311630e-03, -1.0585666e-02]], dtype=float32),\n",
              "              proposed_state=Array([[[-1.3588713e+01,  5.7870488e+00],\n",
              "                        [-1.3062107e+01,  4.8002548e+00],\n",
              "                        [-1.4049887e+01,  4.9101820e+00],\n",
              "                        ...,\n",
              "                        [-1.3397634e-02, -3.7039132e+00],\n",
              "                        [ 3.2161176e-02, -3.4378133e+00],\n",
              "                        [ 2.0687485e-01, -5.6175876e+00]],\n",
              "                \n",
              "                       [[-2.7182349e+02, -3.5627475e+02],\n",
              "                        [-2.2591640e+02, -3.0265689e+02],\n",
              "                        [-1.9205251e+02, -2.1144748e+02],\n",
              "                        ...,\n",
              "                        [-1.3513131e+01,  6.2137161e+01],\n",
              "                        [ 2.7035595e+01,  3.0406361e+01],\n",
              "                        [-3.8340547e+00,  2.7151505e+02]],\n",
              "                \n",
              "                       [[-2.5121653e+01, -8.1571312e+00],\n",
              "                        [-2.1624081e+01, -2.7757454e+00],\n",
              "                        [-2.7386528e+01, -1.0272636e+00],\n",
              "                        ...,\n",
              "                        [ 1.7418139e+00,  1.6890979e-01],\n",
              "                        [-1.7051939e+00, -2.2337000e+00],\n",
              "                        [ 3.5009117e+00,  6.1335025e+00]],\n",
              "                \n",
              "                       ...,\n",
              "                \n",
              "                       [[-1.8550961e-01, -3.6304955e+00],\n",
              "                        [ 8.9693642e+00, -1.1451519e+00],\n",
              "                        [-1.1394805e+01, -2.1488002e-01],\n",
              "                        ...,\n",
              "                        [-7.2327800e+00, -3.1437416e+00],\n",
              "                        [ 2.1520815e+01,  1.2149755e+01],\n",
              "                        [-5.9924250e+00, -3.1476281e+00]],\n",
              "                \n",
              "                       [[ 3.7088811e+00, -1.4155706e+00],\n",
              "                        [-9.4291506e+00, -1.1097646e+00],\n",
              "                        [-5.6026964e+00, -1.1220536e+00],\n",
              "                        ...,\n",
              "                        [ 9.5001183e+00, -1.5190432e+00],\n",
              "                        [-5.5610151e+00, -1.7744447e+00],\n",
              "                        [ 5.3064675e+00, -1.2284098e+00]],\n",
              "                \n",
              "                       [[ 1.6359069e+00, -1.0604185e+00],\n",
              "                        [-1.2648458e+01,  1.5836626e+00],\n",
              "                        [-1.6926466e+00, -2.4022393e+00],\n",
              "                        ...,\n",
              "                        [ 1.4672077e+01,  4.3037291e+00],\n",
              "                        [ 5.6924224e+00, -1.9853426e+00],\n",
              "                        [ 2.1248803e+00, -1.9051087e+00]]], dtype=float32),\n",
              "              proposed_results=UncalibratedHamiltonianMonteCarloKernelResults(\n",
              "                  log_acceptance_correction=Array([[-2.5472010e+01, -2.6731134e+01, -2.6826305e+01, ...,\n",
              "                            -1.1570487e+00, -1.2749305e+00,  1.2506258e+00],\n",
              "                           [-4.8843297e+10, -1.7151447e+10, -6.4076652e+09, ...,\n",
              "                            -1.6140150e+05, -1.3031460e+04, -2.1529172e+06],\n",
              "                           [-1.6001854e+03, -4.0784366e+02, -1.3342699e+03, ...,\n",
              "                            -4.9396276e+00, -1.7945337e-01, -4.1646786e+01],\n",
              "                           ...,\n",
              "                           [-2.4276276e+00,  1.4828105e-01,  8.5070837e-01, ...,\n",
              "                             7.3547566e-01,  1.5085241e+00, -8.2881880e-01],\n",
              "                           [ 4.6972138e-01,  1.5989089e-01, -6.5572864e-01, ...,\n",
              "                            -2.8233719e-01, -2.7691064e+00, -3.0076164e-01],\n",
              "                           [ 7.9811627e-01,  1.4897916e-01, -4.0597630e-01, ...,\n",
              "                             3.5628510e-01, -2.7814865e-02, -9.8051429e-02]], dtype=float32),\n",
              "                  target_log_prob=Array([[-1.0336712e+01, -8.5893002e+00, -7.1039338e+00, ...,\n",
              "                            -4.3882141e+00, -4.2363214e+00, -7.5699210e+00],\n",
              "                           [-3.3026052e+06, -1.6761799e+06, -8.6476481e+05, ...,\n",
              "                            -1.7846527e+03, -7.3674873e+01, -3.7562500e+04],\n",
              "                           [-2.9746130e+02, -1.0175051e+02, -2.1858832e+02, ...,\n",
              "                            -8.8923426e+00, -4.3855681e+00, -4.2621464e+01],\n",
              "                           ...,\n",
              "                           [-4.3400478e+00, -4.6987472e+00, -5.4058614e+00, ...,\n",
              "                            -5.8694429e+00, -7.2441921e+00, -5.0702014e+00],\n",
              "                           [-4.8957467e+00, -4.8868952e+00, -4.7356863e+00, ...,\n",
              "                            -5.3440104e+00, -4.3394318e+00, -4.7107639e+00],\n",
              "                           [-5.8823328e+00, -4.9636736e+00, -4.2857618e+00, ...,\n",
              "                            -5.5743599e+00, -4.3033857e+00, -4.6232982e+00]], dtype=float32),\n",
              "                  grads_target_log_prob=[Array([[[-2.5118370e+00, -3.2474554e+00],\n",
              "                            [-1.9710945e+00, -2.6816955e+00],\n",
              "                            [-1.5355424e+00, -1.9882026e+00],\n",
              "                            ...,\n",
              "                            [ 6.9982710e-04,  7.0391876e-01],\n",
              "                            [-1.1665074e-03,  4.3784449e-01],\n",
              "                            [-3.4575466e-02,  2.6188717e+00]],\n",
              "                    \n",
              "                           [[ 4.1916512e+04,  2.5699150e+03],\n",
              "                            [ 2.4818770e+04,  1.8308035e+03],\n",
              "                            [ 1.5154546e+04,  1.3149724e+03],\n",
              "                            ...,\n",
              "                            [-4.8235680e+01, -5.9659019e+01],\n",
              "                            [ 1.8349586e+01, -1.1478659e+01],\n",
              "                            [-6.3010544e+01, -2.7407404e+02]],\n",
              "                    \n",
              "                           [[ 3.6562134e+01,  2.4090054e+01],\n",
              "                            [ 1.8125872e+01,  1.3803771e+01],\n",
              "                            [ 3.4005173e+01,  2.0527920e+01],\n",
              "                            ...,\n",
              "                            [ 3.0424878e-01, -3.0778923e+00],\n",
              "                            [-5.2424755e-02, -6.7906934e-01],\n",
              "                            [ 1.8062906e+00, -8.7658110e+00]],\n",
              "                    \n",
              "                           ...,\n",
              "                    \n",
              "                           [[ 8.8843675e-03,  6.3152808e-01],\n",
              "                            [-3.9033058e-01,  5.5863667e-01],\n",
              "                            [ 8.7292910e-01,  1.1101273e+00],\n",
              "                            ...,\n",
              "                            [ 8.1577146e-01,  1.7131349e+00],\n",
              "                            [ 1.4058133e+00, -1.2553904e+00],\n",
              "                            [ 5.0033259e-01,  1.2249029e+00]],\n",
              "                    \n",
              "                           [[ 2.2366528e-01, -1.1717554e+00],\n",
              "                            [ 5.3389603e-01,  7.7703100e-01],\n",
              "                            [-2.5870121e-01, -9.3624020e-01],\n",
              "                            ...,\n",
              "                            [-7.9417795e-01,  1.2266107e+00],\n",
              "                            [-4.3756932e-02, -2.9780859e-01],\n",
              "                            [ 2.4202761e-01, -9.2683220e-01]],\n",
              "                    \n",
              "                           [[ 1.6613901e-01, -1.8592956e+00],\n",
              "                            [ 2.9028842e-01,  2.1584168e-01],\n",
              "                            [-3.5052244e-02, -5.1180905e-01],\n",
              "                            ...,\n",
              "                            [ 5.9771127e-01, -8.4563357e-01],\n",
              "                            [-4.2392429e-02, -4.2547196e-02],\n",
              "                            [ 1.0107263e-01, -9.5943785e-01]]], dtype=float32)],\n",
              "                  initial_momentum=[Array([[[-0.31564724,  0.7902418 ],\n",
              "                            [ 0.21095897, -0.19655246],\n",
              "                            [-0.7768212 , -0.08662506],\n",
              "                            ...,\n",
              "                            [ 0.7253072 ,  0.21925187],\n",
              "                            [ 0.77086604,  0.4853519 ],\n",
              "                            [ 0.9455797 , -1.6944226 ]],\n",
              "                    \n",
              "                           [[ 1.3477544 , -0.1519728 ],\n",
              "                            [ 0.37161154, -0.69465524],\n",
              "                            [-0.5289094 ,  0.26359653],\n",
              "                            ...,\n",
              "                            [-0.91209227, -0.81615186],\n",
              "                            [ 1.8227156 , -0.98526436],\n",
              "                            [-0.01411843, -0.87488806]],\n",
              "                    \n",
              "                           [[-0.4426771 , -0.23435766],\n",
              "                            [-0.17663857,  1.1840811 ],\n",
              "                            [-2.469232  ,  0.7657401 ],\n",
              "                            ...,\n",
              "                            [ 0.6128795 ,  0.34818265],\n",
              "                            [-0.6059671 , -0.20480955],\n",
              "                            [ 1.2015089 ,  0.36595708]],\n",
              "                    \n",
              "                           ...,\n",
              "                    \n",
              "                           [[ 0.74908876, -0.05640514],\n",
              "                            [ 0.3009699 ,  0.6228602 ],\n",
              "                            [-2.1046638 , -0.09424964],\n",
              "                            ...,\n",
              "                            [ 0.8136257 ,  1.8466041 ],\n",
              "                            [ 1.9160715 ,  0.29572326],\n",
              "                            [-0.8857924 , -0.38785768]],\n",
              "                    \n",
              "                           [[ 0.99403965,  1.1899048 ],\n",
              "                            [ 0.32273594, -1.2633713 ],\n",
              "                            [-0.8996232 ,  0.97487783],\n",
              "                            ...,\n",
              "                            [-0.4195793 ,  2.7289662 ],\n",
              "                            [ 0.36993018,  0.03760025],\n",
              "                            [ 0.4446919 ,  1.3309208 ]],\n",
              "                    \n",
              "                           [[-0.5723142 ,  1.7980622 ],\n",
              "                            [-0.9963563 ,  0.13651267],\n",
              "                            [ 0.3388756 , -0.56936985],\n",
              "                            ...,\n",
              "                            [ 1.241279  ,  0.8045798 ],\n",
              "                            [ 1.5725906 , -0.9562603 ],\n",
              "                            [-0.48666552,  0.2501972 ]]], dtype=float32)],\n",
              "                  final_momentum=[Array([[[-4.4896202e+00, -5.6135054e+00],\n",
              "                            [-3.6926429e+00, -6.3174200e+00],\n",
              "                            [-4.4626470e+00, -5.8607464e+00],\n",
              "                            ...,\n",
              "                            [ 7.7406877e-01,  1.5129629e+00],\n",
              "                            [ 8.1869441e-01,  1.6460259e+00],\n",
              "                            [ 9.7670364e-01,  5.5676496e-01]],\n",
              "                    \n",
              "                           [[ 3.1196419e+05,  1.9103365e+04],\n",
              "                            [ 1.8470997e+05,  1.3605881e+04],\n",
              "                            [ 1.1278220e+05,  9.7727080e+03],\n",
              "                            ...,\n",
              "                            [-3.5992148e+02, -4.3961465e+02],\n",
              "                            [ 1.3838867e+02, -8.3161224e+01],\n",
              "                            [-4.6925427e+02, -2.0212957e+03]],\n",
              "                    \n",
              "                           [[ 4.8235786e+01,  2.9562317e+01],\n",
              "                            [ 2.2918306e+01,  1.7084255e+01],\n",
              "                            [ 4.3949505e+01,  2.7270208e+01],\n",
              "                            ...,\n",
              "                            [ 1.0488355e+00, -3.0456612e+00],\n",
              "                            [-6.8258137e-01, -5.4966581e-01],\n",
              "                            [ 3.7343612e+00, -8.4217377e+00]],\n",
              "                    \n",
              "                           ...,\n",
              "                    \n",
              "                           [[ 1.5379781e+00, -1.7476252e+00],\n",
              "                            [-4.2610623e-02, -4.2445251e-01],\n",
              "                            [-1.2092952e+00,  1.1290178e+00],\n",
              "                            ...,\n",
              "                            [ 1.4102366e+00,  7.8244144e-01],\n",
              "                            [-6.1302942e-01,  6.0492086e-01],\n",
              "                            [ 3.5939914e-01,  1.5695641e+00]],\n",
              "                    \n",
              "                           [[-7.6797312e-01, -9.3528759e-01],\n",
              "                            [ 4.5549557e-01,  1.0830548e+00],\n",
              "                            [ 1.7092553e+00, -3.8679731e-01],\n",
              "                            ...,\n",
              "                            [ 2.3330100e+00, -1.6568168e+00],\n",
              "                            [-1.9053539e+00,  1.4304200e+00],\n",
              "                            [-4.6828103e-01,  1.5334071e+00]],\n",
              "                    \n",
              "                           [[-7.1021724e-01,  1.2082757e+00],\n",
              "                            [ 2.3058109e-01,  8.1254888e-01],\n",
              "                            [ 7.1867263e-01, -8.5701865e-01],\n",
              "                            ...,\n",
              "                            [-1.3317114e-02,  1.2146500e+00],\n",
              "                            [ 1.8499821e+00,  1.4377263e-01],\n",
              "                            [-6.8401867e-01, -1.6632284e-01]]], dtype=float32)],\n",
              "                  step_size=Array([ 1.        , 14.885853  ,  2.8592095 , ...,  0.79912025,\n",
              "                            0.79912025,  0.79912025], dtype=float32),\n",
              "                  num_leapfrog_steps=Array([ 1,  1,  1, ..., 12, 31,  8], dtype=int32),\n",
              "                  seed=Array([[4152882100, 1063452627],\n",
              "                           [2344160851,  391550721],\n",
              "                           [1254522445, 1283988004],\n",
              "                           ...,\n",
              "                           [1924792522, 2968332447],\n",
              "                           [2253476743, 1987620193],\n",
              "                           [1746921571, 3958613647]], dtype=uint32)\n",
              "                ),\n",
              "              extra=[],\n",
              "              seed=Array([[2257911092, 3587725545],\n",
              "                       [ 866270928, 3880635670],\n",
              "                       [1090025126, 1189820073],\n",
              "                       ...,\n",
              "                       [4152514390, 1107898055],\n",
              "                       [3356993487, 2782297156],\n",
              "                       [ 366664480, 2294449227]], dtype=uint32)\n",
              "            ),\n",
              "          max_trajectory_length=Array([ 1.0253152,  1.0253152,  1.0089525, ..., 28.151611 , 28.151611 ,\n",
              "                   28.151611 ], dtype=float32),\n",
              "          step=Array([   1,    2,    3, ..., 1098, 1099, 1100], dtype=int32),\n",
              "          adaptation_rate=Array([0.025, 0.025, 0.025, ..., 0.025, 0.025, 0.025], dtype=float32),\n",
              "          jitter_amount=Array([1., 1., 1., ..., 1., 1., 1.], dtype=float32),\n",
              "          averaged_sq_grad=Array([   168.57814,    160.14923,    177.97807, ..., 103213.53   ,\n",
              "                   103213.53   , 103213.53   ], dtype=float32),\n",
              "          averaged_sq_grad_adaptation_rate=Array([0.05, 0.05, 0.05, ..., 0.05, 0.05, 0.05], dtype=float32),\n",
              "          averaged_max_trajectory_length=Array([ 1.0253152,  1.0253152,  1.0158361, ..., 29.540289 , 29.540289 ,\n",
              "                   29.540289 ], dtype=float32),\n",
              "          criterion=Array([[9.4396043e-01, 7.5596247e+00, 6.4722002e-01, ..., 2.8036145e+02,\n",
              "                    3.2722760e+02, 3.5696504e-01],\n",
              "                   [9.6181146e+09, 4.8140093e+09, 1.5337663e+09, ..., 3.5638502e+06,\n",
              "                    1.0509501e+06, 1.3580959e+09],\n",
              "                   [4.6550367e+04, 1.6898777e+04, 5.5129000e+04, ..., 2.2671843e+03,\n",
              "                    4.0166265e+03, 8.1830676e+02],\n",
              "                   ...,\n",
              "                   [6.0772310e+03, 7.7686096e+01, 2.2825754e+03, ..., 3.1847900e+02,\n",
              "                    2.0767160e+04, 5.8111353e+02],\n",
              "                   [1.2085944e+00, 9.6768295e+01, 2.7307451e+03, ..., 7.0145798e+01,\n",
              "                    7.6160102e+04, 1.7209471e+02],\n",
              "                   [2.2538992e+01, 1.0489965e+03, 2.1362914e+02, ..., 5.7701348e+03,\n",
              "                    7.1621001e-01, 8.3375359e+01]], dtype=float32),\n",
              "          seed=Array([[0, 0],\n",
              "                   [0, 0],\n",
              "                   [0, 0],\n",
              "                   ...,\n",
              "                   [0, 0],\n",
              "                   [0, 0],\n",
              "                   [0, 0]], dtype=uint32)\n",
              "        ),\n",
              "      target_accept_prob=Array([0.75, 0.75, 0.75, ..., 0.75, 0.75, 0.75], dtype=float32),\n",
              "      log_shrinkage_target=[Array([2.3025851, 2.3025851, 2.3025851, ..., 2.3025851, 2.3025851,\n",
              "               2.3025851], dtype=float32)],\n",
              "      exploration_shrinkage=Array([0.05, 0.05, 0.05, ..., 0.05, 0.05, 0.05], dtype=float32),\n",
              "      step_count_smoothing=Array([10., 10., 10., ..., 10., 10., 10.], dtype=float32),\n",
              "      decay_rate=Array([0.75, 0.75, 0.75, ..., 0.75, 0.75, 0.75], dtype=float32),\n",
              "      error_sum=[Array([-0.21880442,  0.5311956 ,  1.2811956 , ..., -8.723358  ,\n",
              "               -8.894026  , -9.060043  ], dtype=float32)],\n",
              "      log_averaging_step=[Array([ 2.7004113 ,  1.719395  ,  0.47754598, ..., -0.22424386,\n",
              "               -0.22424386, -0.22424386], dtype=float32)],\n",
              "      step=Array([   1,    2,    3, ..., 1098, 1099, 1100], dtype=int32),\n",
              "      num_adaptation_steps=Array([1000, 1000, 1000, ..., 1000, 1000, 1000], dtype=int32),\n",
              "      new_step_size=Array([14.885853  ,  2.8592095 ,  0.32909513, ...,  0.79912025,\n",
              "                0.79912025,  0.79912025], dtype=float32)\n",
              "    )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "tf.executing_eagerly()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nwoyTCcDv4nT",
        "outputId": "af7863ef-d344-4eff-8c11-998984e43dee"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test = jnp.arange(8)\n",
        "test = test.reshape((2, 2, 2))\n",
        "test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ai8z6f4zgpSf",
        "outputId": "e395c46d-ca36-44a5-8015-0f0ae9d800f8"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Array([[[0, 1],\n",
              "        [2, 3]],\n",
              "\n",
              "       [[4, 5],\n",
              "        [6, 7]]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(result.all_states.shape)\n",
        "result.all_states[:, :, 0].reshape(1100, -1, 32, 1).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dca2UDSejPhB",
        "outputId": "e676ac96-0f6b-458f-af9c-2a69cfb71ad0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1100, 128, 2)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1100, 4, 32, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#jnp.mean(test, axis = (0, 3))"
      ],
      "metadata": {
        "id": "STDX7D6jgwBt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define nested Rhat for one parameter.\n",
        "# This assumes the indexed parameter is a scalar, hence the result_state\n",
        "# tensor needs to be formatted accordingly.\n",
        "# TODO: deprecate state_is_list argument\n",
        "def nested_rhat_1dim(result_state, num_super_chains, index_param,\n",
        "                     num_samples, warmup_length = 0,\n",
        "                     rank_normalize = False):\n",
        "\n",
        "  state_param = result_state[warmup_length:(warmup_length + num_samples),\n",
        "                             :, index_param]\n",
        "\n",
        "  num_samples = state_param.shape[0]\n",
        "  num_chains = state_param.shape[1]\n",
        "  num_sub_chains = num_chains // num_super_chains\n",
        "  total_samples = num_samples * num_chains\n",
        "\n",
        "  if (rank_normalize):\n",
        "    state_param_flat = jnp.reshape(state_param, (total_samples, ))\n",
        "    temp = state_param_flat.argsort()\n",
        "    ranks = temp.argsort() + 1\n",
        "    z = norm.ppf((ranks - 3 / 8) / (total_samples + 1 / 4))\n",
        "    state_parm = jnp.reshape(z, (num_samples, num_chains))\n",
        "\n",
        "  # The below operations work with the assumption that each of the superchains will have the same size\n",
        "  # Reshaping the array to account for that may not work in this case where M will change\n",
        "\n",
        "  # Reshaping to account for superchains\n",
        "  state_param = state_param.reshape(num_samples, -1, num_sub_chains, 1)\n",
        "\n",
        "  # This will need to be edited to account for superchains of varying sizes\n",
        "\n",
        "  # Equation 14 in the paper\n",
        "  mean_chain = jnp.mean(state_param, axis = (0, 3))\n",
        "\n",
        "  # Piecewise equations in paper\n",
        "  between_chain_var = jnp.var(mean_chain, axis = 1, ddof = 1)\n",
        "  if (num_samples == 1):\n",
        "    mean_within_chain_var = 0\n",
        "  else:\n",
        "    within_chain_var = jnp.var(state_param, axis = (0, 3), ddof = 1)\n",
        "    mean_within_chain_var = jnp.mean(within_chain_var, axis = 1)\n",
        "\n",
        "  # Equation 17 in the paper\n",
        "  total_chain_var = between_chain_var + mean_within_chain_var\n",
        "\n",
        "  # Equation 16 in the paper\n",
        "  mean_super_chain = jnp.mean(state_param, axis = (0, 2, 3))\n",
        "  between_super_chain_var = jnp.var(mean_super_chain, ddof = 1)\n",
        "\n",
        "  # Equation 18 in the paper\n",
        "  return jnp.sqrt(1 + between_super_chain_var / jnp.mean(total_chain_var)),\\\n",
        "    between_super_chain_var, jnp.mean(total_chain_var)\n",
        "\n",
        "\n",
        "def nested_rhat(result_state, num_super_chains, index_param,\n",
        "                num_samples, warmup_length = 0, rank_normalize = False):\n",
        "  nRhat = jnp.array([])\n",
        "  B = jnp.array([])\n",
        "  W = jnp.array([])\n",
        "  for i in range(0, index_param.shape[0]):\n",
        "    nRhat_local, B_local, W_local = nested_rhat_1dim(result_state,\n",
        "                    num_super_chains, index_param[i], num_samples,\n",
        "                    warmup_length, rank_normalize)\n",
        "\n",
        "    nRhat = jnp.append(nRhat, nRhat_local)\n",
        "    B = jnp.append(B, B_local)\n",
        "    W = jnp.append(W, W_local)\n",
        "\n",
        "  return nRhat, B, W"
      ],
      "metadata": {
        "id": "UdjThIa-lxJT"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using ChEES-HMC in order to get the most out of a GPU"
      ],
      "metadata": {
        "id": "Yog1nM3m2_Bd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select HMC Variant from options chees, snaper, or malt\n",
        "\n",
        "def construct_kernel(target_log_prob_fn, init_step_size, num_warmup, transition = 'chees'):\n",
        "  if transition == 'chees':\n",
        "    # Using gradient-based trajectory length adaptation and dual averaging defines ChEES HMC\n",
        "    kernel = tfp.mcmc.HamiltonianMonteCarlo(target_log_prob_fn, init_step_size, 1)\n",
        "    kernel = tfp.experimental.mcmc.GradientBasedTrajectoryLengthAdaptation(kernel, num_warmup)\n",
        "    kernel = tfp.mcmc.DualAveragingStepSizeAdaptation(\n",
        "        kernel, num_warmup, target_accept_prob = 0.75,\n",
        "        reduce_fn = tfp.math.reduce_log_harmonic_mean_exp)\n",
        "\n",
        "  elif transition == 'snaper':\n",
        "    # TO BE IMPLEMENTED\n",
        "    kernel = 'snaper'\n",
        "\n",
        "  elif transition == 'malt':\n",
        "    # TO BE IMPLEMENTED\n",
        "    kernel = 'malt'\n",
        "\n",
        "  else:\n",
        "    raise Exception(\"Not a valid transition kernel. Try one of ['chees', 'snaper', 'malt']\")\n",
        "\n",
        "  return kernel"
      ],
      "metadata": {
        "id": "l4mElY4y3Uyu"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_fits(num_seed, total_samples, initialize, kernel, num_super_chains,\n",
        "             index_param, num_samples, num_warmup, rank_normalize = False):\n",
        "\n",
        "  num_parameters = index_param.shape[0]\n",
        "\n",
        "  Rhat_list = jnp.zeros((num_seed, num_parameters))\n",
        "  nRhat_list = jnp.zeros((num_seed, num_parameters))\n",
        "  B_list = jnp.zeros((num_seed, num_parameters))\n",
        "  W_list = jnp.zeros((num_seed, num_parameters))\n",
        "  mc_mean_list = jnp.zeros((num_seed, num_parameters))\n",
        "\n",
        "  i = 0\n",
        "  for seed in jax.random.split(jax.random.PRNGKey(1), num_seed):\n",
        "    initial_state = initialize((num_super_chains,), key = seed + 1954)\n",
        "\n",
        "    initial_state = jnp.repeat(initial_state, num_chains // num_super_chains,\n",
        "                              axis = 0)\n",
        "\n",
        "    result = tfp.mcmc.sample_chain(total_samples, initial_state, kernel = kernel, seed = seed)\n",
        "\n",
        "    # Implementation of original R-Hat from Gelman and Rubin (1992)\n",
        "    Rhat_list = Rhat_list.at[i, :].set(tfp.mcmc.potential_scale_reduction(result.all_states[num_warmup:(num_warmup + num_samples), :, index_param]))\n",
        "\n",
        "    nRhat_local, B_local, W_local = nested_rhat(result.all_states,\n",
        "                                                num_super_chains = num_super_chains,\n",
        "                                                index_param = index_param,\n",
        "                                                num_samples = num_samples,\n",
        "                                                warmup_length = num_warmup,\n",
        "                                                rank_normalize = rank_normalize)\n",
        "    nRhat_list = nRhat_list.at[i, :].set(nRhat_local)\n",
        "    B_list = B_list.at[i, :].set(B_local)\n",
        "    W_list = W_list.at[i, :].set(W_local)\n",
        "\n",
        "    mc_mean_list = mc_mean_list.at[i, :].set(jnp.mean(result.all_states[num_warmup + 1, :, index_param], axis = 1))\n",
        "    i += 1\n",
        "\n",
        "  return Rhat_list, nRhat_list, B_list, W_list, mc_mean_list\n"
      ],
      "metadata": {
        "id": "yyDBbuoR3Zq-"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adaptive warmup scheme to produce MCMC samples\n",
        "def forge_chain(kernel_cold, kernel_warm, initial_state, num_super_chains,\n",
        "                num_warmup_array, num_samples, target_rhat, max_num_steps,\n",
        "                index_param, seed, num_nRhat_comp = 1, rank_normalize = False,\n",
        "                alpha_quantile = 1, mean_benchmark = None, var_benchmark = None):\n",
        "  warmup_is_acceptable = False\n",
        "  window_iteration = 0\n",
        "  current_state = initial_state\n",
        "  kernel_args = None\n",
        "\n",
        "  squared_err_list = jnp.array([])\n",
        "  nrhat_list = jnp.array([])\n",
        "\n",
        "  while(not warmup_is_acceptable and window_iteration < max_num_steps):\n",
        "\n",
        "    # Runs MCMC with a warmup window\n",
        "    result_cold, trace, kernel_args = tfp.mcmc.sample_chain(\n",
        "        num_results = num_warmup_array[window_iteration],\n",
        "        current_state = current_state,\n",
        "        kernel = kernel_cold,\n",
        "        previous_kernel_results = kernel_args,\n",
        "        trace_fn = lambda _, pkr: unnest.get_innermost(pkr, 'step_size'),\n",
        "        return_final_kernel_results = True,\n",
        "        seed = seed + window_iteration)\n",
        "\n",
        "    current_state = result_cold[-1]\n",
        "\n",
        "    # Generate candidate samples\n",
        "    result_warm, trace = tfp.mcmc.sample_chain(\n",
        "        num_results = num_samples*num_nRhat_comp,\n",
        "        current_state = current_state,\n",
        "        kernel = kernel_warm,\n",
        "        trace_fn = lambda _, pkr: unnest.get_innermost(pkr, 'step_size'),\n",
        "        previous_kernel_results = kernel_args,\n",
        "\n",
        "        # Why are we just adding numbers to seeds like this? I get it is to randomize but is there a more principled way?\n",
        "        seed = seed + 999999)\n",
        "\n",
        "    # Check if candidate samples are acceptable\n",
        "    nRhat = jnp.zeros((index_param.shape[0], num_nRhat_comp))\n",
        "    for i in range(0, num_nRhat_comp):\n",
        "      nR, _B, _W = nested_rhat(result_warm[i:((i+1)*num_samples)],\n",
        "                                        num_super_chains = num_super_chains,\n",
        "                                        index_param = index_param,\n",
        "                                        num_samples = num_samples,\n",
        "                                        rank_normalize = rank_normalize)\n",
        "      nRhat = nRhat.at[:, i].set(nR)\n",
        "\n",
        "    nRhat_quantile = jnp.quantile(jnp.mean(nRhat, axis = 1), alpha_quantile,\n",
        "                                 interpolation = \"nearest\")\n",
        "    print(\"nRhat_quantile: (\", alpha_quantile, \")\", nRhat_quantile)\n",
        "\n",
        "    if mean_benchmark is not None:\n",
        "      mc_mean = jnp.mean(result_warm[0, :, index_param], axis = 1)\n",
        "      squared_err = jnp.square(mc_mean - mean_benchmark[index_param])\\\n",
        "      / var_benchmark[index_param]\n",
        "\n",
        "      squared_err_list = jnp.append(squared_err_list, squared_err)\n",
        "      nrhat_list = jnp.append(nrhat_list, jnp.mean(nRhat, axis = 1))\n",
        "\n",
        "    if (nRhat_quantile < target_rhat): warmup_is_acceptable = True\n",
        "\n",
        "    window_iteration += 1\n",
        "\n",
        "  return result_warm, window_iteration, squared_err_list, nrhat_list"
      ],
      "metadata": {
        "id": "RggIF9Hqmxh1"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_forge_chain(num_seed, kernel_cold, kernel_warm, initialize, num_super_chains,\n",
        "                    num_warmup, num_samples, target_rhat, max_num_steps,\n",
        "                    index_param, num_nRhat_comp = 1, rank_normalize = False,\n",
        "                    alpha_quantile = 1, mean_benchmark = None,\n",
        "                    var_benchmark = None, initial_seed = 1):\n",
        "  mc_mean_list = jnp.zeros((num_seed, index_param.shape[0]))\n",
        "  warmup_length = jnp.zeros(num_seed)\n",
        "\n",
        "  squared_err_list_all = jnp.array([])\n",
        "  nrhat_list_all = jnp.array([])\n",
        "\n",
        "  i = 0\n",
        "  for seed in jax.random.split(jax.random.PRNGKey(initial_seed), num_seed):\n",
        "    print(\"NEW SEED\")\n",
        "    initial_state = initialize((num_super_chains,), key = seed + 1954)\n",
        "    initial_state = jnp.repeat(initial_state, num_chains // num_super_chains,\n",
        "                              axis = 0)\n",
        "\n",
        "    result, window_iteration, \\\n",
        "    squared_err_list, nrhat_list = forge_chain(kernel_cold, kernel_warm,\n",
        "                                               initial_state, num_super_chains,\n",
        "                                               num_warmup, num_samples,\n",
        "                                               target_rhat, max_num_steps,\n",
        "                                               index_param, seed,\n",
        "                                               num_nRhat_comp, rank_normalize,\n",
        "                                               alpha_quantile, mean_benchmark,\n",
        "                                               var_benchmark)\n",
        "\n",
        "    warmup_length = warmup_length.at[i].set(sum(num_warmup[:window_iteration]))\n",
        "    mc_mean_list = mc_mean_list.at[i, :].set(jnp.mean(result[0, :, index_param],\n",
        "                                 axis = 1))\n",
        "\n",
        "    squared_err_list_all = jnp.append(squared_err_list_all, squared_err_list)\n",
        "    nrhat_list_all = jnp.append(nrhat_list_all, nrhat_list)\n",
        "\n",
        "    i += 1\n",
        "  return mc_mean_list, warmup_length, squared_err_list_all, nrhat_list_all"
      ],
      "metadata": {
        "id": "48aMam844B1f"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_warmup, num_samples = 1000, 5\n",
        "total_samples = num_warmup + num_samples + 1\n",
        "\n",
        "kernel = construct_kernel(target_log_prob_fn = target_log_prob_fn,\n",
        "                          init_step_size = init_step_size, num_warmup = num_warmup,\n",
        "                          transition = 'chees')\n",
        "index_param = jnp.array([0, 1])\n",
        "num_seed = 30\n",
        "rank_normalize = False"
      ],
      "metadata": {
        "id": "T25EaHnhZfmt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Rhat_list, nRhat_list, B_list, W_list, mc_mean_list = run_fits(\n",
        "           num_seed = num_seed, total_samples = total_samples,\n",
        "           initialize = bn_initialize, kernel = kernel,\n",
        "           num_super_chains = K, index_param = index_param,\n",
        "           num_samples = num_samples, num_warmup = num_warmup,\n",
        "           rank_normalize = rank_normalize)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6DS_pAKjaNEa",
        "outputId": "c64e7ecd-154e-4df0-f1bb-d3b79a80c469"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow_probability/substrates/jax/mcmc/sample.py:339: UserWarning: Tracing all kernel results by default is deprecated. Set the `trace_fn` argument to None (the future default value) or an explicit callback that traces the values you are interested in.\n",
            "  warnings.warn('Tracing all kernel results by default is deprecated. Set '\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow_probability/substrates/jax/mcmc/sample.py:339: UserWarning: Tracing all kernel results by default is deprecated. Set the `trace_fn` argument to None (the future default value) or an explicit callback that traces the values you are interested in.\n",
            "  warnings.warn('Tracing all kernel results by default is deprecated. Set '\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow_probability/substrates/jax/mcmc/sample.py:339: UserWarning: Tracing all kernel results by default is deprecated. Set the `trace_fn` argument to None (the future default value) or an explicit callback that traces the values you are interested in.\n",
            "  warnings.warn('Tracing all kernel results by default is deprecated. Set '\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow_probability/substrates/jax/mcmc/sample.py:339: UserWarning: Tracing all kernel results by default is deprecated. Set the `trace_fn` argument to None (the future default value) or an explicit callback that traces the values you are interested in.\n",
            "  warnings.warn('Tracing all kernel results by default is deprecated. Set '\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow_probability/substrates/jax/mcmc/sample.py:339: UserWarning: Tracing all kernel results by default is deprecated. Set the `trace_fn` argument to None (the future default value) or an explicit callback that traces the values you are interested in.\n",
            "  warnings.warn('Tracing all kernel results by default is deprecated. Set '\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow_probability/substrates/jax/mcmc/sample.py:339: UserWarning: Tracing all kernel results by default is deprecated. Set the `trace_fn` argument to None (the future default value) or an explicit callback that traces the values you are interested in.\n",
            "  warnings.warn('Tracing all kernel results by default is deprecated. Set '\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow_probability/substrates/jax/mcmc/sample.py:339: UserWarning: Tracing all kernel results by default is deprecated. Set the `trace_fn` argument to None (the future default value) or an explicit callback that traces the values you are interested in.\n",
            "  warnings.warn('Tracing all kernel results by default is deprecated. Set '\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow_probability/substrates/jax/mcmc/sample.py:339: UserWarning: Tracing all kernel results by default is deprecated. Set the `trace_fn` argument to None (the future default value) or an explicit callback that traces the values you are interested in.\n",
            "  warnings.warn('Tracing all kernel results by default is deprecated. Set '\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow_probability/substrates/jax/mcmc/sample.py:339: UserWarning: Tracing all kernel results by default is deprecated. Set the `trace_fn` argument to None (the future default value) or an explicit callback that traces the values you are interested in.\n",
            "  warnings.warn('Tracing all kernel results by default is deprecated. Set '\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow_probability/substrates/jax/mcmc/sample.py:339: UserWarning: Tracing all kernel results by default is deprecated. Set the `trace_fn` argument to None (the future default value) or an explicit callback that traces the values you are interested in.\n",
            "  warnings.warn('Tracing all kernel results by default is deprecated. Set '\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow_probability/substrates/jax/mcmc/sample.py:339: UserWarning: Tracing all kernel results by default is deprecated. Set the `trace_fn` argument to None (the future default value) or an explicit callback that traces the values you are interested in.\n",
            "  warnings.warn('Tracing all kernel results by default is deprecated. Set '\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow_probability/substrates/jax/mcmc/sample.py:339: UserWarning: Tracing all kernel results by default is deprecated. Set the `trace_fn` argument to None (the future default value) or an explicit callback that traces the values you are interested in.\n",
            "  warnings.warn('Tracing all kernel results by default is deprecated. Set '\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow_probability/substrates/jax/mcmc/sample.py:339: UserWarning: Tracing all kernel results by default is deprecated. Set the `trace_fn` argument to None (the future default value) or an explicit callback that traces the values you are interested in.\n",
            "  warnings.warn('Tracing all kernel results by default is deprecated. Set '\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow_probability/substrates/jax/mcmc/sample.py:339: UserWarning: Tracing all kernel results by default is deprecated. Set the `trace_fn` argument to None (the future default value) or an explicit callback that traces the values you are interested in.\n",
            "  warnings.warn('Tracing all kernel results by default is deprecated. Set '\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow_probability/substrates/jax/mcmc/sample.py:339: UserWarning: Tracing all kernel results by default is deprecated. Set the `trace_fn` argument to None (the future default value) or an explicit callback that traces the values you are interested in.\n",
            "  warnings.warn('Tracing all kernel results by default is deprecated. Set '\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow_probability/substrates/jax/mcmc/sample.py:339: UserWarning: Tracing all kernel results by default is deprecated. Set the `trace_fn` argument to None (the future default value) or an explicit callback that traces the values you are interested in.\n",
            "  warnings.warn('Tracing all kernel results by default is deprecated. Set '\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow_probability/substrates/jax/mcmc/sample.py:339: UserWarning: Tracing all kernel results by default is deprecated. Set the `trace_fn` argument to None (the future default value) or an explicit callback that traces the values you are interested in.\n",
            "  warnings.warn('Tracing all kernel results by default is deprecated. Set '\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow_probability/substrates/jax/mcmc/sample.py:339: UserWarning: Tracing all kernel results by default is deprecated. Set the `trace_fn` argument to None (the future default value) or an explicit callback that traces the values you are interested in.\n",
            "  warnings.warn('Tracing all kernel results by default is deprecated. Set '\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow_probability/substrates/jax/mcmc/sample.py:339: UserWarning: Tracing all kernel results by default is deprecated. Set the `trace_fn` argument to None (the future default value) or an explicit callback that traces the values you are interested in.\n",
            "  warnings.warn('Tracing all kernel results by default is deprecated. Set '\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow_probability/substrates/jax/mcmc/sample.py:339: UserWarning: Tracing all kernel results by default is deprecated. Set the `trace_fn` argument to None (the future default value) or an explicit callback that traces the values you are interested in.\n",
            "  warnings.warn('Tracing all kernel results by default is deprecated. Set '\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow_probability/substrates/jax/mcmc/sample.py:339: UserWarning: Tracing all kernel results by default is deprecated. Set the `trace_fn` argument to None (the future default value) or an explicit callback that traces the values you are interested in.\n",
            "  warnings.warn('Tracing all kernel results by default is deprecated. Set '\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow_probability/substrates/jax/mcmc/sample.py:339: UserWarning: Tracing all kernel results by default is deprecated. Set the `trace_fn` argument to None (the future default value) or an explicit callback that traces the values you are interested in.\n",
            "  warnings.warn('Tracing all kernel results by default is deprecated. Set '\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow_probability/substrates/jax/mcmc/sample.py:339: UserWarning: Tracing all kernel results by default is deprecated. Set the `trace_fn` argument to None (the future default value) or an explicit callback that traces the values you are interested in.\n",
            "  warnings.warn('Tracing all kernel results by default is deprecated. Set '\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow_probability/substrates/jax/mcmc/sample.py:339: UserWarning: Tracing all kernel results by default is deprecated. Set the `trace_fn` argument to None (the future default value) or an explicit callback that traces the values you are interested in.\n",
            "  warnings.warn('Tracing all kernel results by default is deprecated. Set '\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow_probability/substrates/jax/mcmc/sample.py:339: UserWarning: Tracing all kernel results by default is deprecated. Set the `trace_fn` argument to None (the future default value) or an explicit callback that traces the values you are interested in.\n",
            "  warnings.warn('Tracing all kernel results by default is deprecated. Set '\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow_probability/substrates/jax/mcmc/sample.py:339: UserWarning: Tracing all kernel results by default is deprecated. Set the `trace_fn` argument to None (the future default value) or an explicit callback that traces the values you are interested in.\n",
            "  warnings.warn('Tracing all kernel results by default is deprecated. Set '\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow_probability/substrates/jax/mcmc/sample.py:339: UserWarning: Tracing all kernel results by default is deprecated. Set the `trace_fn` argument to None (the future default value) or an explicit callback that traces the values you are interested in.\n",
            "  warnings.warn('Tracing all kernel results by default is deprecated. Set '\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow_probability/substrates/jax/mcmc/sample.py:339: UserWarning: Tracing all kernel results by default is deprecated. Set the `trace_fn` argument to None (the future default value) or an explicit callback that traces the values you are interested in.\n",
            "  warnings.warn('Tracing all kernel results by default is deprecated. Set '\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow_probability/substrates/jax/mcmc/sample.py:339: UserWarning: Tracing all kernel results by default is deprecated. Set the `trace_fn` argument to None (the future default value) or an explicit callback that traces the values you are interested in.\n",
            "  warnings.warn('Tracing all kernel results by default is deprecated. Set '\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow_probability/substrates/jax/mcmc/sample.py:339: UserWarning: Tracing all kernel results by default is deprecated. Set the `trace_fn` argument to None (the future default value) or an explicit callback that traces the values you are interested in.\n",
            "  warnings.warn('Tracing all kernel results by default is deprecated. Set '\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Parellelizing the calculations of nRhat instead of sequential running\n",
        "# This involves getting rid of the loop inside of the code for the regular run_fits(...)\n",
        "# Does this change how the seeds are calculated at all?\n",
        "# Removing the num_seed argument if this won't be run sequentially\n",
        "\n",
        "def run_fits_parallel(iterations, total_samples, initialize, kernel, num_super_chains,\n",
        "             index_param, num_samples, num_warmup, rank_normalize = False):\n",
        "\n",
        "  num_parameters = index_param.shape[0]\n",
        "\n",
        "  Rhat_list = jnp.zeros((num_seed, num_parameters))\n",
        "  nRhat_list = jnp.zeros((num_seed, num_parameters))\n",
        "  B_list = jnp.zeros((num_seed, num_parameters))\n",
        "  W_list = jnp.zeros((num_seed, num_parameters))\n",
        "  mc_mean_list = jnp.zeros((num_seed, num_parameters))\n",
        "\n",
        "  # Should this be a more explicit parameter into the method for reproducibility purposes?\n",
        "  seed = jax.random.PRNGKey(1)\n",
        "  initial_state = initialize((num_super_chains*iterations,), key = seed + 1954)\n",
        "\n",
        "  initial_state = jnp.repeat(initial_state, num_chains*iterations // num_super_chains,\n",
        "                              axis = 0)\n",
        "\n",
        "  result = tfp.mcmc.sample_chain(total_samples, initial_state, kernel = kernel, seed = seed)\n",
        "\n",
        "  # Loop over K superchains at a time in order to calculate nRhat statistics\n",
        "  # Investigate how JAX and looping may be impacting the speed of this loop\n",
        "\n",
        "  for i in range(iterations):\n",
        "    # Selecting the subset that corresponds to K superchains of size M\n",
        "    current_result = result.all_states[num_warmup:(num_warmup + num_samples), (i*num_chains):((i+1)*num_chains), index_param]\n",
        "    Rhat_list = Rhat_list.at[i, :].set(tfp.mcmc.potential_scale_reduction)\n",
        "\n",
        "    # Implementation of original R-Hat from Gelman and Rubin (1992)\n",
        "\n",
        "    Rhat_list = Rhat_list.at[i, :].set(tfp.mcmc.potential_scale_reduction(current_result))\n",
        "\n",
        "    nRhat_local, B_local, W_local = nested_rhat(current_result,\n",
        "                                                num_super_chains = num_super_chains,\n",
        "                                                index_param = index_param,\n",
        "                                                num_samples = num_samples,\n",
        "                                                warmup_length = num_warmup,\n",
        "                                                rank_normalize = rank_normalize)\n",
        "    nRhat_list = nRhat_list.at[i, :].set(nRhat_local)\n",
        "    B_list = B_list.at[i, :].set(B_local)\n",
        "    W_list = W_list.at[i, :].set(W_local)\n",
        "\n",
        "    mc_mean_list = mc_mean_list.at[i, :].set(jnp.mean(result.all_states[num_warmup + 1, (i*num_chains):((i+1)*num_chains), index_param], axis = 1))\n",
        "    i += 1\n",
        "\n",
        "  return Rhat_list, nRhat_list, B_list, W_list, mc_mean_list"
      ],
      "metadata": {
        "id": "lX3CPtM2lS0e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This yields an error; is this just because Colab doesn't have the strongest GPUs?\n",
        "run_fits_parallel(\n",
        "           iterations = num_seed, total_samples = total_samples,\n",
        "           initialize = bn_initialize, kernel = kernel,\n",
        "           num_super_chains = K, index_param = index_param,\n",
        "           num_samples = num_samples, num_warmup = num_warmup,\n",
        "           rank_normalize = rank_normalize)"
      ],
      "metadata": {
        "id": "u1EsgGMNsWBv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "601b8464-e885-4d66-d9d8-48fb792741f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow_probability/substrates/jax/mcmc/sample.py:339: UserWarning: Tracing all kernel results by default is deprecated. Set the `trace_fn` argument to None (the future default value) or an explicit callback that traces the values you are interested in.\n",
            "  warnings.warn('Tracing all kernel results by default is deprecated. Set '\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def superchain_bootstrap(seed, result_state, num_chains, num_super_chains, index_param,\n",
        "                num_samples, warmup_length = 0, rank_normalize = False):\n",
        "\n",
        "  # Resampling from the available superchains to calculate a bootstrap sample\n",
        "  sc_selections = jax.random.choice(key = seed, a = num_super_chains,\n",
        "                                      shape = (num_super_chains,),\n",
        "                                            replace = True)\n",
        "\n",
        "  M = num_chains//num_super_chains\n",
        "\n",
        "  # Assigning first resampled superchain due to JAX array immutability\n",
        "  sc_bootstrapped = jax.lax.dynamic_slice_in_dim(result_state, sc_selections[0]*M, M, axis = 1)\n",
        "  for index in sc_selections[1:]:\n",
        "    # Creating a new sample using bootstrapped superchains, and computing Nested Rhat\n",
        "    sc_bootstrapped = jnp.concatenate((sc_bootstrapped, jax.lax.dynamic_slice_in_dim(result_state, index*M, M, axis = 1)), axis = 1)\n",
        "  return nested_rhat(sc_bootstrapped, num_super_chains, index_param, num_samples, warmup_length, rank_normalize)[0]\n",
        "\n",
        "superchain_bootstrap = jax.vmap(superchain_bootstrap, in_axes = (0, None, None, None, None, None), out_axes = 0)\n"
      ],
      "metadata": {
        "id": "SuUZrfkN_tG6"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seed = jax.random.PRNGKey(17)\n",
        "keys = jax.random.split(seed, 3)\n",
        "#superchain_bootstrap(keys, result.all_states, num_chains, K, index_param, num_samples)"
      ],
      "metadata": {
        "id": "IK331mLGDMS1"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(result.all_states.shape)\n",
        "jnp.take(result.all_states, jnp.array(jnp.where(groups == 0)), axis = 1).shape"
      ],
      "metadata": {
        "id": "mViw22d-Vyic",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8193fe7f-3172-48fd-f94d-e34f3e7a2883"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1100, 128, 2)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1100, 1, 38, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = jnp.array([1, 2, 3, 4, 1])\n",
        "jnp.unique(x, return_counts = True)"
      ],
      "metadata": {
        "id": "p3kuahkwX5aM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Nested Rhat needs to be rewritten for the possibility where we resample individual chains\n",
        "def nested_rhat_1dim_bootstrap(result_state, super_chain_indices, index_param,\n",
        "                     num_samples, warmup_length = 0,\n",
        "                     rank_normalize = False):\n",
        "\n",
        "  # Selecting only samples after burn-in\n",
        "  state_param = result_state[warmup_length:(warmup_length + num_samples),\n",
        "                             :, index_param]\n",
        "\n",
        "  # Setting variables for size of stored markov chains\n",
        "  num_samples = state_param.shape[0]\n",
        "  num_chains = state_param.shape[1]\n",
        "  super_chains, chain_lengths = jnp.unique(super_chain_indices, return_counts = True)\n",
        "  total_samples = num_samples * num_chains\n",
        "\n",
        "\n",
        "  # Reshaping array to format new superchains of varying length\n",
        "  state_param = jnp.take(result_state, jnp.array(jnp.where(super_chain_indices == 0)), axis = 1)\n",
        "  for sc in super_chains[1:]:\n",
        "    new_super_chain = jnp.take(result_state, jnp.array(jnp.where(super_chain_indices == sc)), axis = 1)\n",
        "    state_param = jnp.concatenate((state_param, new_super_chain), axis = 1)\n",
        "\n",
        "\n",
        "  between_chain_var = jnp.zeros(len(super_chains))\n",
        "  mean_within_chain_var = jnp\n",
        "  start = 0\n",
        "  for super in range(len(super_chains)):\n",
        "    subchain_means = jnp.mean(state_param[:, :, start:(start+chain_lengths[super]), :], axis = (0, 1, 3))\n",
        "    between_chain_var = between_chain_var.at[super].set(jnp.var(subchain_means))\n",
        "\n",
        "\n",
        "  if (num_samples == 1):\n",
        "    mean_within_chain_var = 0\n",
        "  else:\n",
        "\n",
        "  # Equation 17 in the paper\n",
        "  # This part should remain the same\n",
        "  total_chain_var = between_chain_var + mean_within_chain_var\n",
        "\n",
        "\n",
        "  # Equation 14 in the paper\n",
        "  mean_super_chain = jnp.zeros(len(super_chains))\n",
        "  start = 0\n",
        "  for super in range(len(super_chains)):\n",
        "    # This is for creating the mean chain\n",
        "    # An axis shouldn't need to be specified here, since we are working within each superchain\n",
        "    mean_super_chain = mean_super_chain.at[super].set(jnp.mean(state_param[:, :,start:(start+chain_lengths[super]),:]))\n",
        "    start = start + chain_lengths[super]\n",
        "\n",
        "  # Equation 16 in the paper\n",
        "  between_super_chain_var = jnp.var(mean_super_chain, ddof = 1)\n",
        "\n",
        "\n",
        "  # Equation 18 in the paper\n",
        "  # This equation should be the same\n",
        "  return jnp.sqrt(1 + between_super_chain_var / jnp.mean(total_chain_var)),\\\n",
        "    between_super_chain_var, jnp.mean(total_chain_var)\n",
        "\n",
        "\n",
        "def nested_rhat_bootstrap(result_state, num_super_chains, index_param,\n",
        "                num_samples, warmup_length = 0, rank_normalize = False):\n",
        "  nRhat = jnp.array([])\n",
        "  B = jnp.array([])\n",
        "  W = jnp.array([])\n",
        "  for i in range(0, index_param.shape[0]):\n",
        "    nRhat_local, B_local, W_local = nested_rhat_1dim(result_state,\n",
        "                    num_super_chains, index_param[i], num_samples,\n",
        "                    warmup_length, rank_normalize)\n",
        "\n",
        "    nRhat = jnp.append(nRhat, nRhat_local)\n",
        "    B = jnp.append(B, B_local)\n",
        "    W = jnp.append(W, W_local)\n",
        "\n",
        "  return nRhat, B, W"
      ],
      "metadata": {
        "id": "2jx6uWD7qtKZ"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a second bootstrapped variance estimator\n",
        "# This should be \"naive\" as well, where each Markov Chain is bootstrapped\n",
        "# It is important to keep track of which superchain each chain belongs to\n",
        "# The number of chains within each superchain will not necessarily be the same size anymore\n",
        "\n",
        "def individual_bootstrap(seed, result_state, num_chains, num_super_chains, index_param,\n",
        "                num_samples, warmup_length = 0, rank_normalize = False):\n",
        "\n",
        "  M = num_chains // num_super_chains\n",
        "\n",
        "  # Selecting indices of bootstrap to compute\n",
        "  bootstraps = jax.random.choice(key = seed, a = num_chains,\n",
        "                                      shape = (num_chains,),\n",
        "                                            replace = True)\n",
        "\n",
        "  # Tracking which superchain each sample is associated with\n",
        "  superchains = bootstraps // M\n",
        "\n",
        "  bootstrapped_chains = result_state[:, bootstraps[0], :]\n",
        "  for chain in bootstraps[1:]:\n",
        "    bootstrapped_chains = jnp.concatenate((bootstrapped_chains, result_state[:, chain, :]), axis = 1)\n",
        "\n",
        "  return bootstraps, superchains"
      ],
      "metadata": {
        "id": "LSMUCFUtSWk0"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index_param = jnp.array([0,1])\n",
        "indices, groups = individual_bootstrap(seed, result.all_states, 128, 4, index_param, 100 )"
      ],
      "metadata": {
        "id": "EySyNd90vHWP"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def adaptive_initialize(target_log_prob_fn, init_step_size, num_warmup, warmup_window):\n",
        "    kernel_cold = construct_kernel(target_log_prob_fn = target_log_prob_fn,\n",
        "                                   init_step_size = init_step_size,\n",
        "                                   num_warmup = num_warmup)\n",
        "    kernel_warm = construct_kernel(target_log_prob_fn = target_log_prob_fn,\n",
        "                                   init_step_size = init_step_size,\n",
        "                                   num_warmup = num_warmup)\n",
        "    window_array = jnp.append(jnp.repeat(10, 10),\n",
        "                              jnp.repeat(warmup_window,\n",
        "                                         num_warmup // warmup_window - 1))\n",
        "    nRhat_upper = 1.05\n",
        "\n",
        "    try:\n",
        "      mean_est = target.sample_transformations['identity'].ground_truth_mean\n",
        "    except:\n",
        "      print('no ground truth mean')\n",
        "      mean_est = (result.all_states[num_warmup:, :]).mean(0).mean(0)\n",
        "    try:\n",
        "      var_est = target.sample_transformations['identity'].ground_truth_standard_deviation**2\n",
        "    except:\n",
        "      print('no ground truth std dev')\n",
        "      var_est = ((result.all_states[num_warmup:, :]**2).mean(0).mean(0) -\n",
        "                mean_est**2)\n",
        "\n",
        "    return kernel_cold, kernel_warm, window_array, nRhat_upper, mean_est, var_est"
      ],
      "metadata": {
        "id": "mOOZ-jXjfjYU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We will look into doing different runs across different GPUs to compute what nRhat should be\n",
        "# Also think about ESS and what it would look like in this scenario"
      ],
      "metadata": {
        "id": "jK39_3OTTdqB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "We will now focus on variance measurement of nested Rhat, with users having the\n",
        "possibility to choose several parameters such as the number of superchains (K),\n",
        "number of markov chains in each group of superchains (M), and number of draws in\n",
        "the sampling phase (N). We will measure this in both a brute force manner, as\n",
        "well as coming up with a notion of bootstrapping. We also can decide to run this\n",
        "variance estimate across all chains sequentially, or in parallel. Having an\n",
        "adaptive warmup length, or a fixed numbers of warmup iterations is also a\n",
        "potential parameter\n",
        "\n",
        "Using an initial seed value of 1\n",
        "\n",
        "I need to think a bit about parallelization as well as bootstrapping\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# There's 8 possibilities here that come from 2^[boostrap, adaptive, parallel]\n",
        "def variance_estimate(target_log_prob_fn, index_param, num_seed = 10, num_warmup = 1000, num_samples = 5,\n",
        "                      num_super_chains = 4, initialize = bn_initialize, num_chains = 128,\n",
        "                      bootstrap = False, adaptive = False, parallel = False,\n",
        "                      warmup_window = 100, initial_seed = 1):\n",
        "\n",
        "  if adaptive:\n",
        "\n",
        "    kernel_cold, kernel_warm, window_array, \\\n",
        "    nRhat_upper, mean_est, var_est = adaptive_initialize(target_log_prob_fn,\n",
        "                                                         init_step_size,\n",
        "                                                         num_warmup,\n",
        "                                                         warmup_window)\n",
        "\n",
        "    if bootstrap:\n",
        "      if parallel:\n",
        "        # Adpative, Bootstrapped, and Parallel\n",
        "\n",
        "        return\n",
        "\n",
        "      else:\n",
        "        # Adaptive, Bootstrapped, and Sequential\n",
        "        return\n",
        "\n",
        "    else:\n",
        "      if parallel:\n",
        "        # Adpative, Brute-Force, and Parallel\n",
        "        return\n",
        "\n",
        "      else:\n",
        "        # Adaptive, Brute-Force, and Sequential\n",
        "        mc_mean_list, warmup_length, squared_error_list, \\\n",
        "        nRhat_list = run_forge_chain(num_seed = num_seed,\n",
        "                                     kernel_cold = kernel_cold,\n",
        "                                     kernel_warm = kernel_warm,\n",
        "                                     initialize = initialize,\n",
        "                                     num_super_chains = num_super_chains,\n",
        "                                     num_warmup = window_array,\n",
        "                                     num_samples = num_samples,\n",
        "                                     target_rhat = nRhat_upper,\n",
        "                                     max_num_steps = window_array.shape[0],\n",
        "                                     index_param = index_param,\n",
        "                                     rank_normalize = False,\n",
        "                                     alpha_quantile = 1.,\n",
        "                                     mean_benchmark = mean_est,\n",
        "                                     var_benchmark = var_est)\n",
        "\n",
        "  else:\n",
        "\n",
        "    kernel = construct_kernel(target_log_prob_fn = target_log_prob_fn,\n",
        "                              init_step_size = init_step_size,\n",
        "                              num_warmup = num_warmup)\n",
        "    if bootstrap:\n",
        "\n",
        "      if parallel:\n",
        "        # Fixed, Bootstrapped, and Parallel\n",
        "        return\n",
        "\n",
        "      else:\n",
        "        # Fixed, Bootstrapped, and Sequential\n",
        "        return\n",
        "\n",
        "    else:\n",
        "      if parallel:\n",
        "        # Fixed, Brute-Force, and Parallel\n",
        "        return\n",
        "\n",
        "      else:\n",
        "        # Fixed, Brute-Force, and Sequential\n",
        "        # Adress apparent discrepancy in definition of total_samples\n",
        "        Rhat_list, nRhat_list, B_list, W_list, mc_mean_list = run_fits(\n",
        "            num_seed = num_seed, total_samples = num_warmup + num_samples + 1,\n",
        "            initialize = initialize, kernel = kernel,\n",
        "            num_super_chains = num_super_chains,\n",
        "            index_param = index_param, num_samples = num_samples,\n",
        "            num_warmup = num_warmup)\n",
        "\n",
        "  return nRhat_list"
      ],
      "metadata": {
        "id": "33hWczNl4Tmj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}